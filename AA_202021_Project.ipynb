{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning / Aprendizagem Automática\n",
    "\n",
    "## Diogo Soares, André Falcão and Sara C. Madeira, 2020/21\n",
    "\n",
    "# ML Project  - Learning about Donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics \n",
    "  \n",
    "**Students are encouraged to work in teams of 3 people**. \n",
    "\n",
    "Projects with smaller teams are allowed, in exceptional cases, but will not have better grades for this reason. \n",
    "\n",
    "The quality of the project will dictate its grade, not the number of people working.\n",
    "\n",
    "**The project's solution should be uploaded in Moodle before the end of December, 18th (last day before Christmas holidays).** \n",
    "\n",
    "Students should **upload a `.zip` file** containing all the files necessary for project evaluation. \n",
    "\n",
    "**It is mandatory to produce a Jupyter notebook containing code and text/images/tables/etc describing the solution and the results. The notebook is both the solution and the report.**\n",
    "\n",
    "**Decisions should be fundamented and results should be critically discussed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The team should use [Python 3](https://www.python.org) and [Jupyter Notebook](http://jupyter.org), together with **[Scikit-learn](http://scikit-learn.org/stable/)**, **[Orange3](https://orange.biolab.si)**, or **both**.\n",
    "\n",
    "**[Orange3](https://orange.biolab.si)** can be used through its **[programmatic version](https://docs.orange.biolab.si/3/data-mining-library/)**, by importing and using its packages, or throught its **workflow version**. \n",
    "\n",
    "**It is up to the team to decide when to use Scikit-learn, Orange, or both.**\n",
    "\n",
    "In this context, your Jupyter notebook might have a mix of code, results, text explanations, workflow figures, etc. \n",
    "\n",
    "In case you use Orange/workflows for some tasks you should also deliver the workflow files and explain the options taken in each widget in your notebook.\n",
    "\n",
    "**You can use this noteboook and the sections below as template for your work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset to be analysed is **`Donors_dataset.csv`**, made available together with this project description. This dataset, downloaded from [Kaggle](https://www.kaggle.com), contains selected data from the following dataset: [Donors-Prediction](https://www.kaggle.com/momohmustapha/donorsprediction/)\n",
    "\n",
    "\n",
    "**In this project, your team is supposed to use only tabular data (not Images or Image Metadata) and see how far you can go in predicting donations and understanding the donors. You should use both supervised and unsupervised learning to tackled 2 tasks:**\n",
    "\n",
    "1. **Task 1 (Supervised Learning) - Predicting Donation and Donation Type**\n",
    "2. **Task 2 (Unsupervised Learning) - Characterizing Donors**\n",
    "\n",
    "The **`Donors_dataset.csv`** you should learn from has **19.372 instances** described by **50 data fields** that you might use as **categorical/numerical features** \n",
    "\n",
    "### File Descriptions\n",
    "\n",
    "* **Donors_dataset.csv** - Tabular/text data to be used in the machine learning tasks.\n",
    "\n",
    "\n",
    "### Data Fields\n",
    "\n",
    "* **CARD_PROM_12** - number of card promotions sent to the individual by the charitable organization in the past 12 months\n",
    "* **CLUSTER_CODE** - one of 54 possible cluster codes, which are unique in terms of socioeconomic status, urbanicity, ethnicity, and other demographic characteristics\n",
    "* **CONTROL_NUMBER** - unique identifier of each individual\n",
    "* **DONOR_AGE** - age as of last year's mail solicitation\n",
    "* **DONOR_GENDER** - actual or inferred gender\n",
    "* **FILE_AVG_GIFT** - this variable is identical to LIFETIME_AVG_GIFT_AMT\n",
    "* **FILE_CARD_GIFT** - lifetime average donation (in \\\\$) from the individual in response to all card solicitations from the charitable organization\n",
    "* **FREQUENCY_STATUS_97NK** - based on the period of recency (determined by RECENCY_STATUS_96NK), which is the past 12 months for all groups except L and E. L and E are 13–24 months ago and 25–36 months ago, respectively: 1 if one donation in this period, 2 if two donations in this period, 3 if three donations in this period, and 4 if four or more donations in this period.\n",
    "* **HOME_OWNER** - H if the individual is a homeowner, U if this information is unknown\n",
    "* **INCOME_GROUP** - one of 7 possible income level groups based on a number of demographic characteristics\n",
    "* **IN_HOUSE** - 1 if the individual has ever donated to the charitable organization's In House program, 0 if not\n",
    "* **LAST_GIFT_AMT** - amount of the most recent donation from the individual to the charitable organization\n",
    "* **LIFETIME_AVG_GIFT_AMT** - lifetime average donation (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_CARD_PROM** - total number of card promotions sent to the individual by the charitable organization\n",
    "* **LIFETIME_GIFT_AMOUNT** - total lifetime donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_COUNT** - total number of donations from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_RANGE** - maximum donation amount from the individual minus minimum donation amount from the individual\n",
    "* **LIFETIME_MAX_GIFT_AMT** - maximum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_MIN_GIFT_AMT** - minimum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_PROM** - total number of promotions sent to the individual by the charitable organization\n",
    "* **MEDIAN_HOME_VALUE** - median home value (in 100\\\\$) as determined by other input variables\n",
    "* **MEDIAN_HOUSEHOLD_INCOME** - median household income (in 100\\\\$) as determined by other input variables\n",
    "* **MONTHS_SINCE_FIRST_GIFT** - number of months since the first donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_GIFT** - number of months since the most recent donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_PROM_RESP** - number of months since the individual has responded to a promotion by the charitable organization\n",
    "* **MONTHS_SINCE_ORIGIN** - number of months that the individual has been in the charitable organization's database\n",
    "* **MOR_HIT_RATE** - total number of known times the donor has responded to a mailed solicitation from a group other than the charitable organization\n",
    "* **NUMBER_PROM_12** - number of promotions (card or other) sent to the individual by the charitable organization in the past 12 months\n",
    "* **OVERLAY_SOURCE** - the data source against which the individual was matched: M if Metromail, P if Polk, B if both\n",
    "* **PCT_ATTRIBUTE1** - percent of residents in the neighborhood in which the individual lives that are males and active military\n",
    "* **PCT_ATTRIBUTE2** - percent of residents in the neighborhood in which the individual lives that are males and veterans\n",
    "* **PCT_ATTRIBUTE3** - percent of residents in the neighborhood in which the individual lives that are Vietnam veterans\n",
    "* **PCT_ATTRIBUTE4** - percent of residents in the neighborhood in which the individual lives that are WWII veterans\n",
    "* **PCT_OWNER_OCCUPIED** - percent of owner-occupied housing in the neighborhood in which the individual lives\n",
    "* **PEP_STAR** - 1 if individual has ever achieved STAR donor status, 0 if not\n",
    "* **PER_CAPITA_INCOME** - per capita income (in \\\\$) of the neighborhood in which the individual lives\n",
    "* **PUBLISHED_PHONE** - 1 if the individual's telephone number is published, 0 if not\n",
    "* **RECENCY_STATUS_96NK** - recency status as of two years ago: A if active donor, S if star donor, N if new donor, E if inactive donor, F if first time donor, L if lapsing donor\n",
    "* **RECENT_AVG_CARD_GIFT_AMT** - average donation from the individual in response to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_AVG_GIFT_AMT** - average donation (in \\\\$) from the individual to the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_COUNT** - number of times the individual has responded to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_PROP** - proportion of responses to the individual to the number of card solicitations from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_COUNT** - number of times the individual has responded to a promotion (card or other) from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_PROP** - proportion of responses to the individual to the number of (card or other) solicitations from the charitable organization since four years ago\n",
    "* **RECENT_STAR_STATUS** - 1 if individual has achieved star donor status since four years ago, 0 if not\n",
    "* **SES** - one of 5 possible socioeconomic codes classifying the neighborhood in which the individual lives\n",
    "* **TARGET_B** - 1 if individual donated in response to last year's 97NK mail solicitation from the charitable organization, 0 if individual did not\n",
    "* **TARGET_D** - amount of donation (in \\\\$) from the individual in response to last year's 97NK mail solicitation from the charitable organization\n",
    "* **URBANICITY** - classification of the neighborhood in which the individual lives: U if urban, C if city, S if suburban, T if town, R if rural, ? if missing\n",
    "* **WEALTH_RATING** - one of 10 possible wealth rating groups based on a number of demographic characteristics\n",
    "\n",
    "\n",
    "### Donation TYPE\n",
    "\n",
    "You are supposed to create a new column/feature named `DONATION_TYPE`, whose values describe ranges of the donation amount (DA) reported in feature `TARGET_D`:\n",
    "* `A` - DA >= 50\n",
    "* `B` - 20 <= DA < 50 \n",
    "* `C` - 13 <= DA < 20\n",
    "* `D` - 10 <= DA < 13\n",
    "* `E` - DA < 10\n",
    "\n",
    "\n",
    "### **Important Notes on Data Cleaning and Preprocessing**\n",
    "\n",
    "   1. Data can contain **errors/typos**, whose correction might improve the analysis.\n",
    "   2. Some features can contain **many values**, whose grouping in categories (aggregation into bins) might improve the analysis.\n",
    "   3. Data can contain **missing values**, that you might decide to fill. You might also decide to eliminate instances/features with high percentages of missing values.\n",
    "   4. **Not all features are necessarily important** for the analysis.\n",
    "   5. Depending on the analysis, **some features might have to be excluded**.\n",
    "   6. Class distribution is an important characteristic of the dataset that should be checked. **Class imbalance** might impair machine learning. \n",
    "  \n",
    "Some potentially useful links:\n",
    "\n",
    "* Data Cleaning and Preprocessing in Scikit-learn: https://scikit-learn.org/stable/modules/preprocessing.html#\n",
    "* Data Cleaning and Preprocessing in Orange: https://docs.biolab.si//3/visual-programming/widgets/data/preprocess.html\n",
    "* Dealing with imbalance datasets: https://pypi.org/project/imbalanced-learn/ and https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0 (Know your Data) - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"Donors_dataset.csv\")\n",
    "raw_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **understand better the features**, their distribution of values, potential errors, etc and plan/describe what data preprocessing steps should be performed next. Very important also is to check the distribution of values in the target (class distribution). \n",
    "\n",
    "Here you can find a notebook with some examples of what you can do in **Exploratory Data Analysis**: https://www.kaggle.com/artgor/exploration-of-data-step-by-step/notebook. You can also use Orange widgets for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will print and plot different tables and visualisations to get a feeling and better overview of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot the histograms to check if there are numerical features with a high number of values, that can possibly be binned to be more convenient for the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Plot for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.hist(bins=30, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort features in different categories for plotting:\n",
    "all_features = list(raw_data.columns[2:])\n",
    "pscontinuous_features = ['CONTROL_NUMBER', 'MONTHS_SINCE_ORIGIN', 'DONOR_AGE', 'PER_CAPITA_INCOME', \\\n",
    "                              'WEALTH_RATING', 'MEDIAN_HOME_VALUE', 'MEDIAN_HOUSEHOLD_INCOME', \\\n",
    "                             'PCT_OWNER_OCCUPIED', 'PCT_ATTRIBUTE2', 'PCT_ATTRIBUTE3', 'PCT_ATTRIBUTE4', \\\n",
    "                              'RECENT_RESPONSE_PROP', 'RECENT_AVG_GIFT_AMT', 'RECENT_CARD_RESPONSE_PROP', \\\n",
    "                              'RECENT_AVG_CARD_GIFT_AMT', 'RECENT_RESPONSE_COUNT', 'RECENT_CARD_RESPONSE_COUNT', \\\n",
    "                              'MONTHS_SINCE_LAST_PROM_RESP', 'LIFETIME_CARD_PROM', 'LIFETIME_PROM', \\\n",
    "                              'LIFETIME_GIFT_COUNT', 'LAST_GIFT_AMT', 'NUMBER_PROM_12', 'MONTHS_SINCE_LAST_GIFT', \\\n",
    "                              'MONTHS_SINCE_FIRST_GIFT', 'FILE_CARD_GIFT','CARD_PROM_12']\n",
    "categorical_features = ['IN_HOUSE', 'URBANICITY', 'SES', 'HOME_OWNER', 'DONOR_GENDER', 'INCOME_GROUP', \\\n",
    "                        'PUBLISHED_PHONE', 'OVERLAY_SOURCE', 'PEP_STAR', 'RECENCY_STATUS_96NK', \\\n",
    "                        'FREQUENCY_STATUS_97NK']\n",
    "other_features = ['CLUSTER_CODE', 'MOR_HIT_RATE', 'PCT_ATTRIBUTE1', 'RECENT_STAR_STATUS', 'LIFETIME_GIFT_AMOUNT', \\\n",
    "                  'LIFETIME_AVG_GIFT_AMT', 'LIFETIME_GIFT_RANGE', 'LIFETIME_MAX_GIFT_AMT', 'LIFETIME_MIN_GIFT_AMT', \\\n",
    "                  'FILE_AVG_GIFT']\n",
    "\n",
    "# check, if all are included and not couble counts:\n",
    "feature_lists = pscontinuous_features+categorical_features+other_features\n",
    "print('All features included and no doubles: ', \\\n",
    "      len(all_features)==len(feature_lists) and set(feature_lists)==set(all_features))\n",
    "\n",
    "def create_plots(features_to_plot, plottype='violin'):\n",
    "    '''Creates plots for given features. Plottypes: 'violin', 'count' . We can add more if necessary.\n",
    "    carful: if number of values per feature is high when 'count' is chosen, running time goes up. '''\n",
    "    print(f'{len(features_to_plot)} plots:')\n",
    "    ncols = 3\n",
    "    nrows = int(len(features_to_plot)/ncols)+1\n",
    "    newplots = plt.figure(figsize=(ncols*5,nrows*5))\n",
    "    for ind, feature in enumerate(features_to_plot):\n",
    "        plt.subplot(nrows, ncols, ind+1)\n",
    "        if plottype=='violin':\n",
    "            sns.violinplot(x=\"TARGET_B\", y=feature, data=raw_data, fontsize=8)\n",
    "            plt.title(f'TARGET_B by {feature}', fontsize=8)\n",
    "        if plottype!='violin':\n",
    "            sns.countplot(x='TARGET_B', data=raw_data, hue=feature);\n",
    "            plt.title(f'{feature} in TARGET_B', fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Violin Plots for numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(pscontinuous_features, 'violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countplots for categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(categorical_features, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = raw_data['TARGET_B'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('TARGET_B classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violin plots for other features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(other_features, 'violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Result of the exploratory analysis: the error for this feature is that one value is a typo ( = \"A\"). That row can be deleted. \n",
    "\n",
    "----\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw_data[raw_data.DONOR_GENDER == \"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.drop(14977, inplace = True )\n",
    "raw_data = raw_data.reset_index(drop=True)\n",
    "display(raw_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = raw_data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 14))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Result of the exploratory analysis: Highly correlated features (red = positive, blue = negative correlated) can be reduntant because they dont produce no additional information and can be useless for the model. \n",
    "\n",
    "TODO: maybe deleted redundant data. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming donation amount in classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transformed_data.drop(columns = [\"CONTROL_NUMBER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_donation_type(row):\n",
    "    if row['TARGET_D'] >= 50:\n",
    "        return 'A'\n",
    "    if row['TARGET_D'] >= 20 and row['TARGET_D'] < 50:\n",
    "        return 'B'\n",
    "    if row['TARGET_D'] >= 13 and row['TARGET_D'] < 20:\n",
    "        return 'C'\n",
    "    if row['TARGET_D'] >= 10 and row['TARGET_D'] < 13:\n",
    "        return 'D'\n",
    "    if row['TARGET_D'] < 10:\n",
    "        return 'E'\n",
    "    return '?'\n",
    "\n",
    "transformed_data['DONATION_TYPE'] = transformed_data.apply (lambda row: label_donation_type(row), axis=1)\n",
    "transformed_data = transformed_data.drop(columns = ('TARGET_D'))\n",
    "\n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['WEALTH_RATING'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 (Supervised Learning) - Predicting Donation and Donation Type\n",
    "\n",
    "In this task you should target 3 classification tasks:\n",
    "1. **Predicting  Donation (binary classification task)**; \n",
    "2. **Predicting Donation TYPE (multiclass classification)**; and\n",
    "3. **Train specialized models for SES (socioeconomic classification)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should:**\n",
    "\n",
    "* Choose **one classifier in each category**: Tree models, Rule models, Linear models, Distance-based models, and Probabilistic models.\n",
    "* Use cross-validation to evaluate the results. \n",
    "* Present and discuss the results for different evaluation measures, present confusion matrices. Remember that not only overall results are important. Check what happens when learning to predict each class.\n",
    "* Describe the parameters used for each classifier and how their choice impacted or not the results.\n",
    "* Choose the best classifier and fundament you choice.\n",
    "* **Discuss critically your choices and the results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning numerical data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of Histogram Analysis: \n",
    "\n",
    "Attributes worth binning (because they have a high number of values): \n",
    "\n",
    "- DONOR_AGE\n",
    "- LIFETIME_CARD_FROM\n",
    "- LIFETIME_GIFT_COUNT\n",
    "- LIFETIME_PROM\n",
    "- MEDIAN_HOME_VALUE\n",
    "- MEDIAN HOUSEHOLD_INCOME\n",
    "- MONTHS_SINCE_LAST_GIFT\n",
    "- MONTHS_SINCE_FIRST_GIFT\n",
    "- PCT_ATTRIBUTE1\n",
    "- PCT_ATTRIBUTE2\n",
    "- PCT_ATTRIBUTE3\n",
    "- PCT_ATTRIBUTE4\n",
    "- PCT_OWNER_OCCUPIED\n",
    "- PER_CAPITA_INCOME\n",
    "- RECENT_RESPONSE_PROP\n",
    "- MONTHS_SINCE_LAST_PROM_RESP\n",
    "\n",
    "TODO: create bins \n",
    "\n",
    "- either quantile binning (our first approach)\n",
    "- or Log transform \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['DONATION_TYPE'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('DONATION_TYPE classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('WEALTH_RATING classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "The dataset contains NaN values in some columns. As the training of the models cant happen with NaN values there are two possibilities. Either drop the values which will lead to a very small dataset, or we try to replace NaN values with other values (with different techniques) in order to maintain a big dataset and dont loose information.\n",
    "\n",
    "Features with missing values, that need to be replaced are: \n",
    "\n",
    "- 'WEALTH_RATING': 8810\n",
    "- 'DONOR_AGE_label': 4795\n",
    "- 'INCOME_GROUP': 4392\n",
    "- 'MONTHS_SINCE_LAST_PROM_RESP': 246\n",
    "\n",
    "- 'URBANICITY'\n",
    "- 'SES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('WEALTH_RATING classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = transformed_data['DONOR_AGE_label'].value_counts().sort_index().plot(kind = 'barh')\n",
    "#plot.set_title('DONOR_AGE_label classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['INCOME_GROUP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('INCOME_GROUP classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['MONTHS_SINCE_LAST_PROM_RESP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('MONTHS_SINCE_LAST_PROM_RESP classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['INCOME_GROUP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('INCOME_GROUP classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['SES'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('SES classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace false values (outliers) with mean of column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO : How did we recognize the outliers ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.MOR_HIT_RATE.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Result: MOR_HIT_RATE : time of answers on other mailings. Seem to high in some cases, will be replaced by column mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Result: MONTHS_SINCE_LAST_PROM_RESP : months since last answer. This value cant be negative and will be replaced by column mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOR_HIT_RATE : time of answers on other mailings. seems to high, will be replaced by column mean. \n",
    "transformed_data.MOR_HIT_RATE = transformed_data.MOR_HIT_RATE.apply(lambda x: (transformed_data.MOR_HIT_RATE.mode()[0]) if x > 100 else x)\n",
    "\n",
    "# MONTHS_SINCE_LAST_PROM_RESP : months since last answer cant be negative,will be replaced by column mean. \n",
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP = transformed_data.MONTHS_SINCE_LAST_PROM_RESP.apply(lambda x: (transformed_data.MONTHS_SINCE_LAST_PROM_RESP.mode()[0]) if x < 0.0 else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show Columns that are of the type \"object\" and need to be transformed to numerical values\n",
    "\n",
    "obj_df = transformed_data.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to clean the data, especially the categorical data, we are encoding the features with the LabelEncoder()** <br>\n",
    "LabelEncoder(): <br>\n",
    "Encode categorical features as a one-hot numeric array. LabelEncoder is used to transform non-numerical labels to numerical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "\n",
    "\n",
    "transformed_data[\"URBANICITY\"] = lb_make.fit_transform(transformed_data[\"URBANICITY\"])\n",
    "URB_classes = lb_make.classes_.copy() \n",
    "transformed_data[\"SES\"] = lb_make.fit_transform(transformed_data[\"SES\"])\n",
    "transformed_data[\"CLUSTER_CODE\"] = lb_make.fit_transform(transformed_data[\"CLUSTER_CODE\"])\n",
    "transformed_data[\"HOME_OWNER\"] = lb_make.fit_transform(transformed_data[\"HOME_OWNER\"])\n",
    "transformed_data[\"DONOR_GENDER\"] = lb_make.fit_transform(transformed_data[\"DONOR_GENDER\"])\n",
    "DGE_classes = lb_make.classes_.copy()\n",
    "transformed_data[\"OVERLAY_SOURCE\"] = lb_make.fit_transform(transformed_data[\"OVERLAY_SOURCE\"])\n",
    "OLS_classes = lb_make.classes_.copy()\n",
    "transformed_data[\"RECENCY_STATUS_96NK\"] = lb_make.fit_transform(transformed_data[\"RECENCY_STATUS_96NK\"])\n",
    "transformed_data[\"DONATION_TYPE\"] = lb_make.fit_transform(transformed_data[\"DONATION_TYPE\"])\n",
    "\n",
    "DT_LaEnc = lb_make #For unsupervized learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot = transformed_data['URBANICITY'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('URBANICITY classes counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data Cleaning\n",
    "\n",
    "1. **add rule based model**\n",
    "2. **oneHot Encoding Feature for all categorical features ? (?)**\n",
    "\n",
    "\n",
    "model training : \n",
    "\n",
    "3. **redo multiclass classification with onehot encoded data**\n",
    "\n",
    "5. **Importance analysis of features = package ?**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- todo: (optional)\n",
    "    * Outlier Detection with Standard Deviation\n",
    "    * https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "- todo: feature engineering:  (parallel zum model training)\n",
    "    * You might also decide to eliminate instances/features with high percentages of missing values. \n",
    "    * Not all features are necessarily important for the analysis.\n",
    "    * Depending on the analysis, some features might have to be excluded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing Data (NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n",
    "raw_data.MOR_HIT_RATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LabelEncoder set all NaN values to 0. URBANICITY, SES and CLUSTER_CODE didn't have any category 0. So it is an identifier for NaN.\n",
    "In order to impute the data correctly, these 0 values have to be set to NaN again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.loc[transformed_data['URBANICITY'] == 0,'URBANICITY'] = np.nan\n",
    "transformed_data.loc[transformed_data['SES'] == 0,'SES'] = np.nan\n",
    "transformed_data.loc[transformed_data['CLUSTER_CODE'] == 0,'CLUSTER_CODE'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = ['URBANICITY', 'SES', 'CLUSTER_CODE', 'INCOME_GROUP', 'WEALTH_RATING']\n",
    "impute_mean = ['MONTHS_SINCE_LAST_PROM_RESP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NaNs with mode()/most frequent: <br>\n",
    "    - ['URBANICITY', 'SES', 'CLUSTER_CODE', 'INCOME_GROUP', 'WEALTH_RATING']\n",
    "   \n",
    "Replace NaNs with mean(): <br>\n",
    "    - ['MONTHS_SINCE_LAST_PROM_RESP']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in impute_mode:\n",
    "    print(transformed_data[feature].mode()[0])\n",
    "    transformed_data[feature].fillna(transformed_data[feature].mode()[0], inplace=True)\n",
    "\n",
    "for feature in impute_mean:\n",
    "    print(transformed_data[feature].mean())\n",
    "    transformed_data[feature].fillna(transformed_data[feature].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rest of NaN values will be replaced with the KNNImputer, with neighbors=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "transformed_data = pd.DataFrame(imputer.fit_transform(transformed_data), columns=transformed_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test, if all NaNs are replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = df_filled['URBANICITY'].value_counts().sort_index().plot(kind = 'barh')\n",
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['MOR_HIT_RATE'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_data = transformed_data.copy() #This data should not be binned, but encoded --> clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_data = transformed_data.copy() # This data should not be binned, but encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_binning =  [\"DONOR_AGE\", \"LIFETIME_CARD_PROM\", \"LIFETIME_GIFT_COUNT\", \"LIFETIME_PROM\", \"MONTHS_SINCE_ORIGIN\", \"MEDIAN_HOME_VALUE\", \"MEDIAN_HOUSEHOLD_INCOME\", \"MONTHS_SINCE_FIRST_GIFT\", \"PCT_ATTRIBUTE2\", \"PCT_ATTRIBUTE3\", \"PCT_ATTRIBUTE4\", \"PCT_OWNER_OCCUPIED\", \"PER_CAPITA_INCOME\", \"RECENT_RESPONSE_PROP\"]\n",
    "quantile_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "quantile_labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for feature in features_for_binning:\n",
    "    print(feature)\n",
    "    if feature==\"MONTHS_SINCE_ORIGIN\": # less bins for this features because of high number of zeros\n",
    "        quantile_list = np.linspace(0, 1.0, 7)\n",
    "        quantile_labels = np.arange(0,len(quantile_list)-1)\n",
    "        \n",
    "    quantiles = transformed_data[feature].quantile(quantile_list)\n",
    "    \n",
    "    \n",
    "    #binned_dataframe[f'{feature}_range'] = pd.qcut(binned_dataframe[feature],q=quantile_list)\n",
    "    transformed_data[f'{feature}_label'] = pd.qcut(transformed_data[feature],q=quantile_list,labels=quantile_labels, duplicates='drop')\n",
    "\n",
    "    \n",
    "transformed_data = transformed_data.drop(columns = features_for_binning)    \n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data will be used in Rule Mining\n",
    "RM_data = transformed_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert float64 to int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting for better performance\n",
    "no difference to float values, because decimal number is not used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transformed_data.select_dtypes(include=['float64'])\n",
    "#tf.drop(columns=['RECENT_CARD_RESPONSE_PROP','RECENT_AVG_GIFT_AMT', 'RECENT_AVG_CARD_GIFT_AMT', \n",
    "#                 'LIFETIME_AVG_GIFT_AMT', 'LIFETIME_GIFT_RANGE', 'LIFETIME_MAX_GIFT_AMT', 'LIFETIME_MIN_GIFT_AMT', 'FILE_AVG_GIFT'])\n",
    "transformed_data[tf.columns] = transformed_data[tf.columns].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tried to use OrdinalEncoder to replace NaNs, but decided to use LabelEncoder and manually replace NaN, by choosing the correct function (mean/mode/KNN)** <br>\n",
    "**Code:** <br>\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from fancyimpute import KNN\n",
    "#instantiate both packages to use\n",
    "encoder = OrdinalEncoder()\n",
    "imputer = KNN()\n",
    "**create a list of categorical columns to iterate over** <br>\n",
    "to_encode = ['WEALTH_RATING','DONOR_AGE_label','INCOME_GROUP', 'URBANICITY','SES' ]\n",
    "\n",
    "\n",
    "def encode(data):\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "    '''function to encode non-null data and replace it in the original data'''\n",
    "    #retains only non-null values\n",
    "    nonulls = np.array(data.dropna())\n",
    "    #reshapes the data for encoding\n",
    "    impute_reshape = nonulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Assign back encoded values to non-null values\n",
    "    tdata = data.copy()\n",
    "    tdata.is_copy = None\n",
    "    tdata.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "  \n",
    "    return tdata\n",
    "\n",
    "#create a for loop to iterate through each column in the data\n",
    "for columns in to_encode:\n",
    "    encode(transformed_data[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the Data: Resampling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['DONATION_TYPE'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balancing the Data:** <br>\n",
    "Class distribution is an important characteristic of the dataset that should be checked. **Class imbalance** might impair machine learning.\n",
    "\n",
    "After cleaning up the dataset, we still have imbalanced features. The focus is on the feature 'TARGET_B'. As you can see in the plot above, we have nearly 3 times more \"not donated\" (0) than \"donated\" (1).\n",
    "\n",
    "In order to fix it, we decided to random under- and over-sample the dataset. In the end, after optimising, we decided to go with over-sampling. After analysing, we guess that we lose too many information through under-fitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random under-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> under-sample \"0\" to the count of \"1\". In the end we should have a balanced TARGET_B, where count(0) = count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = transformed_data.copy()\n",
    "count_class_0, count_class_1 = resampled_data['TARGET_B'].value_counts()\n",
    "print(count_class_0,count_class_1)\n",
    "\n",
    "#Divide\n",
    "td_class_0 = resampled_data[resampled_data['TARGET_B'] == 0]\n",
    "td_class_1 = resampled_data[resampled_data['TARGET_B'] == 1]\n",
    "\n",
    "td_class_0_under = td_class_0.sample(count_class_1)\n",
    "td_under = pd.concat([td_class_0_under, td_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(td_under['TARGET_B'].value_counts())\n",
    "\n",
    "td_under['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');\n",
    "\n",
    "td_under = td_under.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> over-sample \"1\" to the count of \"0\". In the end we should have a balanced TARGET_B, where count(0) = count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_class_1_over = td_class_1.sample(count_class_0, replace=True)\n",
    "td_over = pd.concat([td_class_0, td_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(td_over['TARGET_B'].value_counts())\n",
    "\n",
    "td_over['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');\n",
    "\n",
    "td_over = td_over.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling DONATION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data_dt = transformed_data.copy()\n",
    "count_class_0, count_class_1, count_class_2, count_class_3, count_class_4, count_class_5 = resampled_data_dt['DONATION_TYPE'].value_counts()\n",
    "print(count_class_0,count_class_1)\n",
    "\n",
    "#Divide\n",
    "td_class_0_dt = resampled_data[resampled_data['DONATION_TYPE'] == 0]\n",
    "td_class_1_dt = resampled_data[resampled_data['DONATION_TYPE'] == 1]\n",
    "td_class_2_dt = resampled_data[resampled_data['DONATION_TYPE'] == 2]\n",
    "td_class_3_dt = resampled_data[resampled_data['DONATION_TYPE'] == 3]\n",
    "td_class_4_dt = resampled_data[resampled_data['DONATION_TYPE'] == 4]\n",
    "td_class_5_dt = resampled_data[resampled_data['DONATION_TYPE'] == 5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "td_class_1_over_dt = td_class_1_dt.sample(count_class_0, replace=True)\n",
    "td_class_2_over_dt = td_class_2_dt.sample(count_class_0, replace=True)\n",
    "td_class_3_over_dt = td_class_3_dt.sample(count_class_0, replace=True)\n",
    "td_class_4_over_dt = td_class_4_dt.sample(count_class_0, replace=True)\n",
    "td_class_5_over_dt = td_class_5_dt.sample(count_class_0, replace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "td_over_dt = pd.concat([td_class_0_dt, td_class_1_over_dt, td_class_2_over_dt, td_class_3_over_dt, td_class_4_over_dt, td_class_5_over_dt], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(td_over_dt['DONATION_TYPE'].value_counts())\n",
    "\n",
    "td_over_dt['DONATION_TYPE'].value_counts().plot(kind='bar', title='Count (DONATION_TYPE)');\n",
    "\n",
    "td_over_dt = td_over_dt.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot encoding DONATION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_over['DONATION_TYPE'].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = td_over_dt.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "one_hot = pd.get_dummies(transformed_data['DONATION_TYPE'], prefix= 'DONATION_TYPE')\n",
    "transformed_data = transformed_data.drop('DONATION_TYPE', axis=1)\n",
    "transformed_data = transformed_data.join(one_hot)\n",
    "transformed_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imbalanced learn module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip3 install imblearn\n",
    "import imblearn\n",
    "\n",
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    colors = ['#1F77B4', '#FF7F0E']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            X[y==l, 1],\n",
    "            c=c, label=l, marker=m\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_rus, y_rus, id_rus = rus.fit_sample(resampled_data.['TARGET_B'])\n",
    "\n",
    "print('Removed indexes:', id_rus)\n",
    "\n",
    "plot_2d_space(X_rus, y_rus, 'Random under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resampling the training set pushed the accurency to 0.51\n",
    "Conclusion: no resampling of the trainingset**\n",
    "\n",
    "Code: <br>\n",
    "count_class_0, count_class_1 = train_dataset['TARGET_B'].value_counts()\n",
    "print(count_class_0,count_class_1)\n",
    "\n",
    "#Divide\n",
    "td_class_0 = train_dataset[train_dataset['TARGET_B'] == 0]\n",
    "td_class_1 = train_dataset[train_dataset['TARGET_B'] == 1]\n",
    "\n",
    "td_class_0_under = td_class_0.sample(count_class_1)\n",
    "td_under = pd.concat([td_class_0_under, td_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(td_under['TARGET_B'].value_counts())\n",
    "\n",
    "td_under['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');\n",
    "\n",
    "train_dataset = td_under\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Class imbalance for DONATE_TYPE\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test data (Splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for normal classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train and evaluate the models we need to split them into training- and testsets. \n",
    "As a basis for the split we can use three of base-datasets we created before:\n",
    "\n",
    "- transformed_data (cleaned dataset but no balancing of classes = imbalanced class (donates / not donating))\n",
    "- td_under (cleaned dataset with balancing of the class (donates / not donating) with random under sampling)\n",
    "- td_over (cleaned dataset with balancing of the class (donates / not donating) with random over sampling)\n",
    "\n",
    "To use the datasets copy one of the following datasets in the following cell: \n",
    "\n",
    "- transformed_data \n",
    "- td_under\n",
    "- td_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_data = transformed_data.copy()\n",
    "#transformed_data = td_under.copy()\n",
    "transformed_data = td_over_dt.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For splitting the data we drop the two target columns [\"TARGET_B\", \"DONATION_TYPE\"] out of the training(X) and testdataset (X) and assign them to the target-feature (y) also for training and test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dt_columns = [\"DONATION_TYPE_0\", \"DONATION_TYPE_1\", \"DONATION_TYPE_2\",\"DONATION_TYPE_3\", \"DONATION_TYPE_4\", \"DONATION_TYPE_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = transformed_data.sample(frac=0.8,random_state=87)\n",
    "test_dataset = transformed_data.drop(train_dataset.index)\n",
    "\n",
    "X_train = train_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\" ])\n",
    "X_test = test_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "\n",
    "y_train_target_b = train_dataset.pop(\"TARGET_B\")\n",
    "y_test_target_b = test_dataset.pop('TARGET_B')\n",
    "\n",
    "#y_train_donation_type = train_dataset[\"DONATION_TYPE\"].values\n",
    "#y_test_donation_type = test_dataset[\"DONATION_TYPE\"].values\n",
    "\n",
    "y_train_donation_type = train_dataset[\"DONATION_TYPE\"]\n",
    "y_test_donation_type = test_dataset[\"DONATION_TYPE\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_donation_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for classification task for the specific SES classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we want to train and evaluate models for the specific socioeconomic classes. \n",
    "In order to create different datasets for each class we split them in the following and create respective training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_donation_type_array = y_train_donation_type.to_numpy()\n",
    "y_test_donation_type_array = y_test_donation_type.to_numpy()\n",
    "print(y_train_donation_type_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SES_1 = transformed_data[transformed_data.SES == 0]\n",
    "SES_2 = transformed_data[transformed_data.SES == 1]\n",
    "SES_3 = transformed_data[transformed_data.SES == 2]\n",
    "SES_4 = transformed_data[transformed_data.SES == 3]\n",
    "SES_nan = transformed_data[transformed_data.SES == 4]\n",
    "\n",
    "def split_sets(df):\n",
    "\n",
    "    train_dataset = df.sample(frac=0.8,random_state=0)\n",
    "    test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "    X_train = train_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "    X_test = test_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "\n",
    "    y_train_target_b = train_dataset.pop(\"TARGET_B\")\n",
    "    y_test_target_b = test_dataset.pop('TARGET_B')\n",
    "\n",
    "    #y_train_donation_type = train_dataset[\"DONATION_TYPE\"].values\n",
    "    #y_test_donation_type = test_dataset[\"DONATION_TYPE\"].values\n",
    "\n",
    "    y_train_donation_type = train_dataset.pop(\"DONATION_TYPE\")\n",
    "    y_test_donation_type = test_dataset.pop('DONATION_TYPE')\n",
    "    \n",
    "    return X_train, X_test, y_train_target_b, y_test_target_b, y_train_donation_type, y_test_donation_type\n",
    "\n",
    "\n",
    "X_train_SES_1, X_test_SES_1, y_train_target_b_SES_1, y_test_target_b_SES_1, y_train_donation_type_SES_1, y_test_donation_type_SES_1 = split_sets(SES_1)\n",
    "X_train_SES_2, X_test_SES_2, y_train_target_b_SES_2, y_test_target_b_SES_2, y_train_donation_type_SES_2, y_test_donation_type_SES_2 = split_sets(SES_2)\n",
    "X_train_SES_3, X_test_SES_3, y_train_target_b_SES_3, y_test_target_b_SES_3, y_train_donation_type_SES_3, y_test_donation_type_SES_3 = split_sets(SES_3)\n",
    "X_train_SES_4, X_test_SES_4, y_train_target_b_SES_4, y_test_target_b_SES_4, y_train_donation_type_SES_4, y_test_donation_type_SES_4 = split_sets(SES_4)\n",
    "X_train_SES_nan, X_test_SES_nan, y_train_target_b_SES_nan, y_test_target_b_SES_nan, y_train_donation_type_SES_nan, y_test_donation_type_SES_nan = split_sets(SES_4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation of the Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will introduce five classifiers in order to train Models for the three given classificaiton tasks. \n",
    "\n",
    "- Predicting Donation (binary classification task);\n",
    "- Predicting Donation TYPE (multiclass classification); and\n",
    "- Train specialized models for SES (socioeconomic classification).\n",
    "\n",
    "We choose the following classifiers for each category: \n",
    "\n",
    "- Tree models: RandomForestClassifier\n",
    "- Distance-based models: KNeighborsClassifier\n",
    "- Linear models: Support Vector Machine\n",
    "- Probabilistic models: Gaussian Naive Bayes\n",
    "- Rule models: todo\n",
    "\n",
    "For Evalutation we use a 5-fold cross validation to evaluate the results.\n",
    "\n",
    "TODO: \n",
    "\n",
    "1. describe different measures \n",
    "2. explain results\n",
    "3. check not only overall accuracy but also precision and recall for each class !!\n",
    "4. Describe the parameters used for each classifier and how their choice impacted or not the results.\n",
    "5. Choose the best classifier and fundament you choice.\n",
    "6. Discuss critically your choices and the results!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "The **Metrics** we are evaluating: \n",
    "\n",
    "Precision: What proportion of positive identifications was actually correct?\n",
    "\n",
    "Recall: What proportion of actual positives was identified correctly?\n",
    "\n",
    "f1-score: The harmonic mean of precision and recall.\n",
    "\n",
    "Accuracy: The fraction of all predictions the model got right. \n",
    "\n",
    "To fully evaluate the effectiveness of a model, we must examine both precision and recall. Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa. So the f1-score as the harmonic mean of precision and recall is a good metric to look at. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_names, models ) -> pd.DataFrame:\n",
    "    '''\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = [\"precision\" , \"recall\" , \"f1\", 'accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "    target_names = target_names\n",
    "    \n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        #print(y_pred)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names, zero_division = 0))\n",
    "        # Generate confusion matrix\n",
    "        #matrix = plot_confusion_matrix(model, X_test, y_test)#, normalize='true')\n",
    "        #matrix.plot()\n",
    "        #plt.rcParams[\"axes.grid\"] = False\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametertuning for all binary classification models  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The untuned models will perform very poorly. Based on the different datasets we use for training we need to choose the right hyperparameters of the models. \n",
    "\n",
    "In the following each of the tunable models (Gaussian NB is not tunable) will be trained with different hyperparameters in order to find the best combination of parameters to increase the metrics we specified. \n",
    "\n",
    "We specified to score on recall (the proportion of the actual values the model predicted right), precision (the proportion of the predicted values that truly are that class) and on overall model accuracy. \n",
    "\n",
    "After evaluating the best parameters for each model we can use the models with the best parameters to create a model comparision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 7 min \n",
    "\n",
    "rand_forest = RandomForestClassifier(n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_target_b)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': [40, 50, 60],\n",
    "          'max_features': ['auto'],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'n_estimators': [400, 600, 800]}\n",
    "\n",
    "#scoring = ['recall' , 'precision', 'accuracy']\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    rand_forest,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=5,\n",
    "    n_jobs= -1, \n",
    "    scoring=\"f1\" \n",
    "    #refit='recall'\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_target_b)\n",
    "\n",
    "print(\"Best params for Rand Forest : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for Rand Forest : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for Rand Forest : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Hyperparametertuning showed we use the following parameters: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(bootstrap=False, max_depth=60, n_estimators=800,n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_target_b)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train, y_train_target_b)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n",
    "\n",
    "params = {'n_neighbors':[50,60,70],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    knn,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_target_b)\n",
    "\n",
    "print(\"Best params for knn : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for knn : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for knn : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Hyperparametertuning showed we use the following parameters: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=70)\n",
    "knn = knn.fit(X_train, y_train_target_b)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_target_b) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "print(classification_report(y_test_target_b, svm_predictions))\n",
    "\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train_target_b)\n",
    "\n",
    "\n",
    "print(\"Best params for SVM : \" +  str(grid.best_params_))\n",
    "\n",
    "print(\"Best estimator for SVM : \" + str(grid.best_estimator_))\n",
    "\n",
    "print(\"Best score for SVM : \" + str(grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Hyperparametertuning showed we use the following parameters: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc = SVC(C=0.1, gamma=0.01)\n",
    "svc = svc.fit(X_train, y_train_target_b)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature significance based on the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rand_forest.feature_importances_\n",
    "std = np.std([rand_forest.feature_importances_ for tree in rand_forest.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d : %s (%f)\" % (f + 1, indices[f] ,X_train.columns[indices[f]] ,importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure( figsize=(20,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: As the analysis showed, there are features that are more and less relevant for the model. \n",
    "As a next step for speeding up model training we could drop the less relevant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametertuning for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 7 min \n",
    "\n",
    "rand_forest = RandomForestClassifier(n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_donation_type)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': [10, 20, 30],\n",
    "          'max_features': ['auto'],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'n_estimators': [200, 400, 600]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    rand_forest,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_donation_type)\n",
    "\n",
    "print(\"Best params for Rand Forest : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for Rand Forest : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for Rand Forest : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_donation_type)\n",
    "y_pred = rand_forest.predict(X_test) \n",
    "print(classification_report(y_test_donation_type, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_donation_type)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "knn = knn.fit(X_train, y_train_donation_type)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n",
    "\n",
    "params = {'n_neighbors':[50,60,70],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    knn,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_donation_type)\n",
    "\n",
    "print(\"Best params for knn : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for knn : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for knn : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=5, n_jobs=-1, n_neighbors=60)\n",
    "knn = knn.fit(X_train, y_train_donation_type)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_donation_type) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "print(classification_report(y_test_donation_type, svm_predictions))\n",
    "\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train_donation_type)\n",
    "\n",
    "\n",
    "print(\"Best params for SVM : \" +  str(grid.best_params_))\n",
    "\n",
    "print(\"Best estimator for SVM : \" + str(grid.best_estimator_))\n",
    "\n",
    "print(\"Best score for SVM : \" + str(grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc = SVC()\n",
    "svc = svc.fit(X_train, y_train_target_b)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Classifiers: \n",
    "\n",
    "## Binary Classification \n",
    "\n",
    "### Without Sampling\n",
    "- RF : RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=400,n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=60)\n",
    "- SVM : \n",
    "\n",
    "### Oversampling \n",
    "- RF : RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=70)\n",
    "- SVM : SVC(C=0.1, gamma=0.01)\n",
    "\n",
    "### Undersampling \n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n",
    "\n",
    "\n",
    "## Multiclass Classification \n",
    "\n",
    "### Without Sampling\n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n",
    "### Oversampling \n",
    "- RF : RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=5, n_jobs=-1, n_neighbors=60)\n",
    "- SVM : \n",
    "### Undersampling \n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models for binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(\n",
    "    X_train, \n",
    "    y_train_target_b, \n",
    "    X_test, \n",
    "    y_test_target_b, \n",
    "    ['wont donate', 'donates'],\n",
    "    [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1)),\n",
    "     ('Distance Based Model: KNN', KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=70)),\n",
    "     ('Probabilistic Model: GNB', GaussianNB()),\n",
    "     ('Linear Model: SVM', SVC(C=0.1, gamma=0.01))\n",
    "        # Rule Based model: \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.set(font_scale=1)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating the best parameters for each model we can use the models with the best parameters to create a model comparision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(\n",
    "    X_train, \n",
    "    y_train_donation_type_array, \n",
    "    X_test, \n",
    "    y_test_donation_type_array, \n",
    "    ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "    [\n",
    "        ('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1)),\n",
    "        ('Distance Based Model: KNN', KNeighborsClassifier(leaf_size=5, n_jobs=-1, n_neighbors=60)),\n",
    "        ('Probabilistic Model: GNB', GaussianNB()),\n",
    "        ('Linear Model: SVM', SVC())\n",
    "        # Rule Based model: \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.set(font_scale=1)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classifier for SES - classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models for each SES class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "TODO: we just have to train the best classifier (ONE !!!) from the previous experiments to predict donation and donation type for each SES class = 2 models for 5 SES = experiments \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(X_train_SES_1, \n",
    "                 y_train_target_b_SES_1, \n",
    "                 X_test_SES_1 , \n",
    "                 y_test_target_b_SES_1, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_2, \n",
    "                 y_train_target_b_SES_2, \n",
    "                 X_test_SES_2, \n",
    "                 y_test_target_b_SES_2, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_3, \n",
    "                 y_train_target_b_SES_3, \n",
    "                 X_test_SES_3 , \n",
    "                 y_test_target_b_SES_3, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_4, \n",
    "                 y_train_target_b_SES_4, \n",
    "                 X_test_SES_4 , \n",
    "                 y_test_target_b_SES_4, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_nan, \n",
    "                 y_train_target_b_SES_nan, \n",
    "                 X_test_SES_nan, \n",
    "                 y_test_target_b_SES_nan, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classifier for SES - classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(X_train_SES_1, \n",
    "                 y_train_target_b_SES_1, \n",
    "                 X_test_SES_1 , \n",
    "                 y_test_target_b_SES_1, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_2, \n",
    "                 y_train_target_b_SES_2, \n",
    "                 X_test_SES_2, \n",
    "                 y_test_target_b_SES_2, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_3, \n",
    "                 y_train_target_b_SES_3, \n",
    "                 X_test_SES_3 , \n",
    "                 y_test_target_b_SES_3, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_4, \n",
    "                 y_train_target_b_SES_4, \n",
    "                 X_test_SES_4 , \n",
    "                 y_test_target_b_SES_4, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_nan, \n",
    "                 y_train_target_b_SES_nan, \n",
    "                 X_test_SES_nan, \n",
    "                 y_test_target_b_SES_nan, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: \n",
    "\n",
    "# todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logical Models: Rule models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after complete processing, all columns should be used\n",
    "interesting_features = ['TARGET_B', 'HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE'] \n",
    "\n",
    "# data used for Rule Mining:\n",
    "RM_transformed_data = transformed_data[interesting_features]\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources:\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html  -   6.3.4. Encoding categorical features\n",
    "# TP05: 2.2\n",
    "\n",
    "# def ohe_encode moved to 3.1\n",
    "\n",
    "cols_not_binary = ['HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE']\n",
    "RM_binary_data = ohe_encode(cols_not_binary)\n",
    "RM_binary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Binning for all interesting features (first preprocessing section)\n",
    "- put the OneHotEncoding in first preprocessing section?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ????? Finding Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate frequent patterns:\n",
    "freq_patterns = apriori(RM_binary_data, min_support=0.05, use_colnames=True) # maybe choose different min_support..\n",
    "#freq_patterns['size'] = freq_patterns['itemsets'].apply(lambda x: len(x))\n",
    "#freq_patterns = freq_patterns[freq_patterns['size']>1]\n",
    "#freq_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# careful here, if we change '?' again maybe...\n",
    "def check_if_interesting(x):\n",
    "    # Interesting (maybe different criteria..):\n",
    "    # - consequents==(TARGET_B or DONATION_TYPE)\n",
    "    # - TARGET_B, B, D, E not in antecedents\n",
    "    targets = ['TARGET_B', 'DONATION_TYPE:A', 'DONATION_TYPE:B', 'DONATION_TYPE:C', \n",
    "               'DONATION_TYPE:D', 'DONATION_TYPE:E', 'DONATION_TYPE:?']\n",
    "    target_is_only_consequents = any(item in targets for item in x[1]) and len(x[1])==1\n",
    "    target_not_in_ancedents = not any(item in targets for item in x[0])\n",
    "    return target_is_only_consequents and target_not_in_ancedents\n",
    "\n",
    "# generate assiciation rules:\n",
    "as_rules = association_rules(freq_patterns, metric=\"confidence\", min_threshold=0.2)\n",
    "# filter out uninteresting rules:\n",
    "as_rules['interesting?'] = as_rules[['antecedents', 'consequents']].apply(check_if_interesting, axis=1)\n",
    "as_rules = as_rules[ as_rules['interesting?']==True]\n",
    "as_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Models: Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Donation (binary classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: linear regression or SVM ? \n",
    "# first we try SVM classifier\n",
    "  \n",
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_target_b) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test, y_test_target_b) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test_target_b, svm_predictions) \n",
    "matrix = plot_confusion_matrix(svm_model_linear, X_test, y_test_target_b)#, normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: linear regression or SVM ? \n",
    "# first we try SVM classifier\n",
    "  \n",
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_target_b) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test, y_test_target_b) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test_target_b, svm_predictions) \n",
    "matrix = plot_confusion_matrix(svm_model_linear, X_test, y_test_target_b)#, normalize='true')\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "#grid.fit(X_train, y_train_target_b)\n",
    "\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) \n",
    "\n",
    "grid_predictions = grid.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Models: Distance-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: knn\n",
    "\n",
    "# training a KNN classifier \n",
    "\n",
    "knn = KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=4).fit(X_train, y_train_target_b) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test, y_test_target_b) \n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test)  \n",
    "cm = confusion_matrix(y_test_target_b, knn_predictions) \n",
    "\n",
    "matrix = plot_confusion_matrix(knn, X_test, y_test_target_b, normalize='true')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "#define the model and parameters\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':[4,5,6,7],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "#Fit the model\n",
    "model = GridSearchCV(knn, param_grid=parameters)\n",
    "model.fit(X_train,y_train_target_b)\n",
    "\n",
    "#predictions on test data\n",
    "prediction=model.predict(X_test)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(model.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(model.best_estimator_) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test, y_test_target_b) \n",
    "print(accuracy)\n",
    "  \n",
    "cm = confusion_matrix(y_test_target_b, knn_predictions) \n",
    "\n",
    "\n",
    "\n",
    "grid_predictions = model.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test_target_b, grid_predictions)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(as_rules[as_rules['consequents']==frozenset({'DONATION_TYPE:High'})].head)# example: naive bayes \n",
    "\n",
    "# see above. \n",
    "\n",
    "# no grid search needed for naive bayes, because no parameters to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the f1-Score....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 (Unsupervised Learning) - Characterizing Donors and Donation Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **use unsupervised learning algorithms and try to characterize donors (people who really did a donation) and their donation type**. You can use:\n",
    "* **Association rule mining** to find **associations between the features and the target Donation/DonationTYPE**.\n",
    "* **Clustering algorithms to find similar groups of donors**. Is it possible to find groups of donors with the same/similar DonationTYPE?\n",
    "* **Be creative and define your own unsupervised analysis!** What would it be interesting to find out ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics.cluster import contingency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better visualization and suppression of warnings:\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will use the apriori algorithm to calculate frequent patterns in the data. From these patterns we can draw the association rules we look for. \n",
    "\n",
    "We can use a large part of the preprocessing from the supervised learning. NaN-replacement is of course very usefull. Binning as well, as for features with a wide range of values, no meaningfull rules can be learned. However, not all of the data in this dataset is already binned.\n",
    "\n",
    "We will check first for correlations between the features and drop most of the ones that are correlated. The reason: After the necessary OneHotEncoding, we will have to deal with a significantly larger number of columns. That together with the already large number of rows leads to high assignment of memory space while calculating the frequent patterns, which can cause a crash of the program.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, extract the data from Task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_transformed_data = RM_data.copy().astype(float)\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the features are already in place for checking for correlations. However, the features URBANICITY and DONOR_GENDER receive more accurate encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order URBANICITY from rural (0) to city (4): \n",
    "# 0(=?,suburban)->2 ; 1(=C,city)->4 ; 2(=R,rural)->0 ; 3(=S, suburban)->2 ; \n",
    "# 4(=T, town)->1 ; 5(=T,urban)->3\n",
    "def newEnc_URB(x):\n",
    "    if x==0 or x==3: return 2\n",
    "    if x==1: return 4\n",
    "    if x==2: return 0\n",
    "    if x==4: return 1\n",
    "    if x==5: return 3\n",
    "RM_transformed_data['URB_newEnc'] = RM_transformed_data['URBANICITY'].apply(newEnc_URB)\n",
    "\n",
    "# Order DONOR_GENDER. Take the average for unknown:\n",
    "def newEnc_DGE(x):\n",
    "    if x==0: return 1    # female\n",
    "    if x==1: return 0    # male\n",
    "    if x==2: return 0.5  # unknown\n",
    "RM_transformed_data['DGE_newEnc'] = RM_transformed_data['DONOR_GENDER'].apply(newEnc_DGE)\n",
    "    \n",
    "new_enc_features = ['URBANICITY', 'DONOR_GENDER', 'OVERLAY_SOURCE']\n",
    "RM_transformed_data = RM_transformed_data.drop(new_enc_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can search for correlations between the features: The function `find_correlations` returns a list with the correlated features. It also finds groups with strong correlations within them. \n",
    "\n",
    "In order to achieve this, the algorithm creates a correlation matrix between all features and looks for the highest value in the matrix. One of the two features belonging to this value will be added to the list of correlated features. This feature will be dropped from the matrix. This will be done over and over again until there is no value in the correlation matrix that is above the given correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corr_groups(corrs):\n",
    "    '''\n",
    "    From the given correlating tuples, checks which of them share a common features and merges them.\n",
    "    :param corrs: set containing tuples with correlating features\n",
    "    :return new_corrs: set with merged tuples, if they shared features\n",
    "    :return found_new_corr: True if the function found a new correlation between features in two tuples\n",
    "    '''\n",
    "    found_new_corr = False\n",
    "    new_corrs = set()\n",
    "    for corr1_list in corrs.copy():\n",
    "        corr1_is_closed = False\n",
    "        if corr1_list in corrs:\n",
    "            corr1 = set(corr1_list)\n",
    "            corrs.remove(corr1_list)\n",
    "            for corr2_list in corrs.copy():\n",
    "                corr2 = set(corr2_list)\n",
    "                if corr1!=corr2 and corr1&corr2 != set():\n",
    "                    new_corrs.add(tuple(corr1.union(corr2)))\n",
    "                    corrs.remove(corr2_list)\n",
    "                    corr1_is_closed = True\n",
    "                    found_new_corr = True\n",
    "            if corr1_is_closed==False:\n",
    "                new_corrs.add(corr1_list)\n",
    "    return new_corrs, found_new_corr\n",
    "\n",
    "def find_correlations(data, corr_threshold=0.6, targets=['TARGET_B', 'DONATION_TYPE'], show_hist=False):\n",
    "    '''\n",
    "    :param data: dataset whose features shall be checked for correlations\n",
    "    :param corr_threshold: threshold from which correlating features should be dropped\n",
    "    :return correlated_features: features that are envolved in strong correlations. Should be dropped.\n",
    "    :return correlations: set containing tuples with correlating features\n",
    "    :return corr_mat: correlation matrix.\n",
    "    :return corr_hist: Histogram with distribution of all correlations.\n",
    "    :return lowest_corr: lowest correlation value. Usually negative. \n",
    "    '''\n",
    "    corr_mat = data.drop(targets, axis=1).corr()\n",
    "    corr_hist = False\n",
    "    if show_hist:\n",
    "        corr_hist = plt.hist(corr_mat.to_numpy().flatten());\n",
    "        plt.show()\n",
    "    \n",
    "    lowest_corr = np.amin(corr_mat.to_numpy().flatten())\n",
    "    highest_corr_val = corr_threshold\n",
    "    correlated_features = set() # list with all features with correlations  \n",
    "    correlation_groups = set() # list with pairs of correlating features\n",
    "\n",
    "    initiation = True\n",
    "    while abs(highest_corr_val)>corr_threshold or initiation:\n",
    "        highest_corr_val = corr_threshold\n",
    "        highest_corr_name = None\n",
    "        for col in range(len(corr_mat.columns)):\n",
    "            for row in range(col):\n",
    "                if corr_mat.iloc[col, row] > highest_corr_val:\n",
    "                    highest_corr_val = abs(corr_mat.iloc[col, row])\n",
    "                    highest_corr_name = corr_mat.columns[row]\n",
    "                    correlation_groups.add((highest_corr_name, corr_mat.index[col]))\n",
    "        if highest_corr_name == None:\n",
    "            break\n",
    "        corr_mat = corr_mat.drop(highest_corr_name, axis=1).drop(highest_corr_name, axis=0)\n",
    "\n",
    "    correlation_groups = list(correlation_groups)\n",
    "    # create list with all correlated features:\n",
    "    correlated_features = set()\n",
    "    for group in correlation_groups:\n",
    "        for member in group:\n",
    "            correlated_features.add(member)\n",
    "    found_new = True\n",
    "    j = 0\n",
    "    while found_new==True and j<20:\n",
    "        temp = correlation_groups.copy()\n",
    "        correlation_groups, found_new = create_corr_groups(temp)\n",
    "        j += 1\n",
    "    print('Cor. Features found:', len(correlated_features))\n",
    "    return correlated_features, list(correlation_groups), corr_mat, corr_hist, lowest_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_corr_features, RM_corr_groups,corr_mat,_,_= find_correlations(RM_transformed_data, corr_threshold=0.25) #0.25 ist gut\n",
    "\n",
    "print('\\nRM_corr_groups:')\n",
    "for ind, group in enumerate(RM_corr_groups):\n",
    "    print('\\n', ind, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newly found correlation groups seem accurate in most cases, although there are two groups that contain a range of features around the topic recent and general donation activity. Further analysis could improve the accuracy of the feature groups.\n",
    "\n",
    "However, with this knowledgege, we can drop all features with correlations, but keep one feature from each group (inc_features) that will represend the group from know:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_features = ['RECENT_RESPONSE_COUNT', 'INCOME_GROUP', 'PCT_ATTRIBUTE2_label', 'MONTHS_SINCE_LAST_GIFT', \\\n",
    "                'PUBLISHED_PHONE', 'LIFETIME_AVG_GIFT_AMT']\n",
    "# out of interest: keep DONOR_AGE_label as well:\n",
    "inc_features = inc_features + ['DONOR_AGE_label']\n",
    "\n",
    "RM_features = list(set(RM_transformed_data.columns)-set(RM_corr_features))+inc_features \n",
    "RM_transformed_data = RM_transformed_data[RM_features]\n",
    "display(RM_transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced the number of columns already significanty. However, the already performed binning is not sufficient. After some trials, we saw that binning features in ten bins is still too high for the apriori algorithm. Therefore, check in the data, for which features, further binning is necessary. Other features need further processing as well. This, we will perform now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devide in binning and seperate transformation:\n",
    "features_not_to_bin = ['TARGET_B', 'DONATION_TYPE', 'HOME_OWNER', 'DONOR_GENDER_RM', 'PUBLISHED_PHONE']\n",
    "features_seperate = ['SES',  'OVERLAY_SOURCE', 'PCT_ATTRIBUTE1', 'DGE_newEnc'\\\n",
    "                         ]#'RECENCY_STATUS_96NK', 'RECENT_STAR_STATUS', 'WEALTH_RATING', 'MOR_HIT_RATE', 'PUBLISHED_PHONE']\n",
    "features_to_bin = list(set(RM_features)-set(features_not_to_bin)-set(features_seperate))\n",
    "\n",
    "# Backtransform DONATION_TYPE and create new compressed target:\n",
    "RM_transformed_data[\"DONATION_TYPE\"] = DT_LaEnc.inverse_transform(RM_transformed_data[\"DONATION_TYPE\"].astype('int32'))\n",
    "def convert_DT(x):\n",
    "    if x=='?':\n",
    "        return 'None'\n",
    "    if x=='A' or x=='B':\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Low'\n",
    "RM_transformed_data.DONATION_TYPE = RM_transformed_data[\"DONATION_TYPE\"].apply(convert_DT)\n",
    "\n",
    "# Deal with extraordinaly features:\n",
    "RM_transformed_data[\"DONOR_GENDER_RM\"] = RM_transformed_data[\"DGE_newEnc\"].apply(lambda x: 'F' if x==1 else ('M' if x==0 else 'U'))\n",
    "RM_transformed_data[\"SES_RM\"] = RM_transformed_data[\"SES\"].apply(lambda x: 'low' if x==0 else 'high')\n",
    "RM_transformed_data[\"PCT_ATTRIBUTE1_RM\"] = RM_transformed_data[\"PCT_ATTRIBUTE1\"].apply(lambda x: 'low' if x==0 else 'high')\n",
    "RM_transformed_data = RM_transformed_data.drop([  \"PCT_ATTRIBUTE1\", \"SES\", \"DGE_newEnc\"], axis=1)\n",
    "\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform binning into three bins: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_quantiles_list = [0, 1./3., 2./3., 1.0]\n",
    "RM_quantile_labels = [0, 1, 2]\n",
    "for feature in features_to_bin:\n",
    "    quantiles = RM_transformed_data[feature].quantile(RM_quantiles_list)\n",
    "    RM_transformed_data[f'{feature}_RM'] = pd.qcut(RM_transformed_data[feature],q=RM_quantiles_list, \\\n",
    "                                                   labels=RM_quantile_labels, duplicates='drop')\n",
    "\n",
    "RM_transformed_data = RM_transformed_data.drop(columns = features_to_bin)    \n",
    "#display(RM_transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function does the OneHotEncoding. After applying it to the data, we receive one column for each different value in each column. \n",
    "\n",
    "We can save columns here as well: In the function, for features that we recently binnend in three bins, the middle bin is deleted. The reason is that we are not so much interested in this information (only if a value of a feature is very high or low). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_encode(col_names, X=RM_transformed_data):\n",
    "    '''Takes  and DataFrame X with all columns. \n",
    "    Encodes features and replaces old columns in X. \n",
    "    Deletes middle bin for features ending in \"RM\" (are divided in three bins).\n",
    "    :param col_names: columns to encode (format: ['colum1', 'column2', ...])\n",
    "    :param X: Dataframe with all columns\n",
    "    :return: OneHotEncoded dataframe\n",
    "    '''\n",
    "    enc = OneHotEncoder()\n",
    "    matrix = X[col_names].to_numpy()\n",
    "    enc.fit(matrix)\n",
    "    matrix = enc.transform(matrix).toarray()\n",
    "    \n",
    "    categories_new = np.array(enc.categories_)\n",
    "    features_new = np.array([])\n",
    "    for ind1, cat in enumerate(categories_new):\n",
    "        for ind2, cat_new in enumerate(cat):\n",
    "            if ind2==1 and (col_names[ind1][-2:]=='RM'): # We do not need these Categories here and will drop them\n",
    "                features_new = np.append(features_new, 'Drop')\n",
    "            else:\n",
    "                features_new = np.append(features_new, col_names[ind1]+':'+str(cat_new))\n",
    "                \n",
    "    new_df = pd.DataFrame(matrix)\n",
    "    new_df.columns = features_new.tolist()\n",
    "\n",
    "    updated_df = pd.concat([X, new_df], axis=1)\n",
    "    updated_df = updated_df.drop(col_names, axis=1)\n",
    "    updated_df = updated_df.drop('Drop', axis=1)\n",
    "    \n",
    "    return(updated_df)\n",
    "\n",
    "columns_to_ohenc = list(RM_transformed_data.columns)\n",
    "columns_to_ohenc.remove('TARGET_B')\n",
    "RM_binary_data = ohe_encode(columns_to_ohenc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns achieve higher meaning by giving them new encoding. Some have low meaning, so we can drop them here.\n",
    "Furthermore, to get apriori to run, we use only the first 10000 rows (about half of the dataset). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_binary_data = RM_binary_data.rename(columns={'PUBLISHED_PHONE:1.0': 'PUBLISHED_PHONE:0', 'PUBLISHED_PHONE:0.0': 'PUBLISHED_PHONE:1'})\n",
    "RM_binary_data = RM_binary_data.rename(columns={'HOME_OWNER:1.0': 'HOME_OWNER:0', 'HOME_OWNER:0.0': 'HOME_OWNER:1'})\n",
    "RM_binary_data = RM_binary_data.rename(columns={'PEP_STAR:1.0': 'PEP_STAR:0', 'PEP_STAR:0.0': 'PEP_STAR:1'})\n",
    "RM_binary_data = RM_binary_data.drop('DONATION_TYPE:Low', axis=1)\n",
    "RM_binary_data = RM_binary_data.drop('DONOR_GENDER_RM:U', axis=1) \n",
    "\n",
    "drop_rows = np.arange(10000, RM_binary_data.shape[0],1)\n",
    "RM_binary_data = RM_binary_data.drop(drop_rows)\n",
    "RM_binary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Associations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run apriori, we calculate the minimum support we want to use. It should be significantly smaller than the smallest class-support, but still high enough to get the algorithm to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_class_support = RM_transformed_data[\"DONATION_TYPE\"].value_counts()[2] \\\n",
    "                       / RM_transformed_data[\"DONATION_TYPE\"].value_counts().sum()\n",
    "minimum_support = lowest_class_support / 5\n",
    "print('minimum_support: ', minimum_support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply apriori and use itemsets smaller three. This way, we receive rules in the end, where we can draw conclusions from one feature to a target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_patterns = apriori(RM_binary_data, min_support=minimum_support, use_colnames=True) \n",
    "freq_patterns['length'] = freq_patterns['itemsets'].apply(lambda x: len(x))\n",
    "freq_patterns = freq_patterns[ freq_patterns['length'] < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the association rules from the frequent patterns. Therefore, we have to choose a metric, how to determine, which rules are interesting for us. We pick the metric \"leverage\". It gives us the observed support of consequents (A) and antecents (B) divided by the expected support, if they were independent:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\text{leverage} = \\text{support}(A \\rightarrow B) - \\text{support}(A) \\cdot \\text{support}(B) \\in [-1,1]\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "The measurement tells us, if there is a correlation without being biased by a high antecent or consequent support.\n",
    "Otherwise the set of rules, we would receive would contain lots of features with high support.\n",
    "-1 corresponds to high anti-correlation, 0 for no correlation and 1 for high correlation.\n",
    "\n",
    "The minimum threshold is chosen to be 0.001 to look for correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"leverage\"\n",
    "as_rules_raw = association_rules(freq_patterns, metric=metric, min_threshold=0.001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, only rules are important for as, that are related to characteristics we are interested in. We choose to look for rules that indicate:\n",
    "- high probability to donate (TARGET_B)\n",
    "- low probability to donate (DONATION_TYPE:None)\n",
    "- high probability to donate a lot, in case of a donation (DONATION_TYPE:High)\n",
    "\n",
    "Consequently, we sort out these rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_interesting(x):\n",
    "    '''\n",
    "    :param x: [antecends, consequents] \n",
    "    :return: True, if rule is interesting, else False\n",
    "    '''\n",
    "    # Interesting:\n",
    "    # - consequents==(TARGET_B or DONATION_TYPE:High or DONATION_TYPE:None)\n",
    "    # - target not in antecedents\n",
    "    \n",
    "    targets = ['TARGET_B', 'DONATION_TYPE:High', 'DONATION_TYPE:Low', 'DONATION_TYPE:None']\n",
    "    target_is_only_consequents = any(item in targets for item in x[1]) and len(x[1])==1\n",
    "    target_not_in_ancedents = not any(item in targets for item in x[0])\n",
    "    return target_is_only_consequents and target_not_in_ancedents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_rules = as_rules_raw.copy()\n",
    "# filter out uninteresting rules:\n",
    "as_rules['interesting?'] = as_rules[['antecedents', 'consequents']].apply(check_if_interesting, axis=1)\n",
    "as_rules = as_rules[ as_rules['interesting?']==True]\n",
    "as_rules = as_rules.sort_values(by=[metric], ascending=False)\n",
    "as_rules = as_rules.drop(['conviction', 'lift', 'conviction', 'interesting?', 'confidence'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rules are orderd by the type of target for easier analyzation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = as_rules[as_rules['consequents']==frozenset({'TARGET_B'})]\n",
    "df2 = as_rules[as_rules['consequents']==frozenset({'DONATION_TYPE:High'})]\n",
    "df3 = as_rules[as_rules['consequents']==frozenset({'DONATION_TYPE:None'})]\n",
    "for df in [df1, df2, df3]:\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we draw conclusions about which features lead to a person being more (*TARGET_B*) or less likely (*DONATAION_TYPE:None*) to donate. Apart from that, we can see, which features seem to have an impact on the amount that the person donates (*DONATION_TYPE:High*) in case of a donation.\n",
    "\n",
    "Most conclusions are close to what one would expect:\n",
    "For example that the features *HOME_OWNER* and *INCOME_GROUP* are an indicator for high probability to donate as they stand for general wealth, which is characterised well by the corresponding correlation group of *INCOME_GROUP*. \n",
    "A high *DONOR_AGE* indicates a high likelihood to donate. A low age indicates the opposite, although young people seem to donate a lot if they decide to do it. \n",
    "If not a lot of time has passed since the last gift (*MONTHS_SINCE_LAST_GIFT*), the person is likely to donate again and vice versa. If a person donates after a long time again, the amount is likely to be high.  \n",
    "A high *RECENT_RESPONSE_COUNT* leads to a person being likely to donate, while a low value is an indicator for a person being less likely to donate. It is not surprising that persons who frequently respond to solicitations are likely to donate. \n",
    "An interesting observation is the fact that a person who does not frequently respond is likely to donate a high amount, if he or she donates eventually. From the derivation of correlated features, we can see that *RECENT_RESPONSE_COUNT* correlates with other features such as a general number of donation activity during the lifetime. This allows the conclusion, that a person who has never really been in touch with the thought of making a donation, is actually likely to donate a lot, if you get him to decide to donate. This interpretations is closely related to the one for *MONTHS_SINCE_LAST_GIFT*.\n",
    "\n",
    "Some features appearing in rules are not easy to interpret:\n",
    "A high *CLUSTER_CODE* is a good indicator for a rarely donating person, a low one indicates frequent and high donations. We have no information about the ordering of the cluster code though and how it is calculated. \n",
    "The features *PCT_ATTRIBUTE2* (high percentage of male veterans in the neighborhood) and *PCT_ATTRIBUTE3* (high number of Vietnam veterans) indicate the opposite behavior. However, there is no trivial explanation for this. A closer analysis of the attributes of the neighborhoods with high (low) number of veterans could help to explain this. \n",
    "\n",
    "To conclude, the expecation is matched that persons with higher wealth donate more. Persons who always have been donating will donate again. A person that has not donated in a long time or never donated is less likely to donate, but donates more, if he or she does so eventually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we are looking for clusters in the data via kmeans- and agglomerative clustering. Subsequently, we can sort out the clusters with interesting values of the targets.\n",
    "\n",
    "Just like in rule mining, we can use parts of the preprocessing from other parts of the project. Here, we use data with already replaced NaN-values. We do not need to worry about the running time and storage usage of the algorithm as in apriori. However, we need to sort out correlated features to increase clarity of the results. Furthermore, it would give inappropriate weights to some groups of features in the clustering algorithms. For example, features that indicate the recent activity. Of these we have a lot in the dataset. They would have a significantly higher weight than other features, just because the number of features is higher.\n",
    "\n",
    "Lastly, it is important to standardise the features (subtract mean and devide by standard deviation). This avoids that features with high values receive larger weights in the clustering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_data = CL_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take encoding back for classes where classes can not be ordered:\n",
    "# Order Urbanicity and Gender again: \n",
    "clustering_data['URB_newEnc'] = clustering_data['URBANICITY'].apply(newEnc_URB)\n",
    "clustering_data['DGE_newEnc'] = clustering_data['DONOR_GENDER'].apply(newEnc_DGE)\n",
    "    \n",
    "new_enc_features = ['URBANICITY', 'DONOR_GENDER', 'OVERLAY_SOURCE']\n",
    "clustering_data = clustering_data.drop(new_enc_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We search for correlated features with the function that we already used in rule mining. As already mentioned, the clustering algorithms do not demand a very low number of features, so we can choose a higher correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_corr_features, CL_corr_groups, CL_corr_mat,_,_= find_correlations(clustering_data, corr_threshold=0.5)\n",
    "\n",
    "print('RM_corr_features: \\n', CL_corr_features)\n",
    "print('\\nRM_corr_groups:')\n",
    "for ind, group in enumerate(CL_corr_groups):\n",
    "    print('\\n', ind, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation groups here are similar to the ones found in rule mining. It is sometimes hard to assign one common attribute to a whole group. Again, this works quite well in most cases.\n",
    "\n",
    "We will drop again all but one feature from each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_features_CL = ['MEDIAN_HOUSEHOLD_INCOME', 'NUMBER_PROM_12', 'LIFETIME_AVG_GIFT_AMT', \\\n",
    "                   'RECENT_RESPONSE_COUNT', 'MONTHS_SINCE_LAST_GIFT']\n",
    "CL_features = list(set(clustering_data.columns)-set(CL_corr_features))+inc_features_CL \n",
    "clustering_data= clustering_data[CL_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, we can standardise the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data will be standardized (otherwise features with higher values will have higher weights in clustering):\n",
    "clustering_data_X = clustering_data.drop(['TARGET_B', 'DONATION_TYPE'], axis=1)\n",
    "scaler = preprocessing.StandardScaler().fit(clustering_data_X)\n",
    "clustering_data_X = scaler.transform(clustering_data_X)\n",
    "\n",
    "clustering_data_y = RM_transformed_data[\"DONATION_TYPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering by k-means partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In k-means clustering, the algorithm chooses randomly n cluster centers in the vector room of all features. The distance from the cluster centers to all points is calculated and each point is chosen to be in the class of the closest cluster center. After that, the cluster centers a moved to the average of all points being part of its class. This is repeated a lot of times, but usually converges quickly. We choose 300 iterations, which gives accurate results while avoiding long running times.\n",
    "\n",
    "The number of clusters is chosen to be 12, which is a good amount of clusters to avoid a lot of small clusters. In the end, we would like to give more general statements about the donation behavior, not only about a small number of donors. Furthermore, with small clusters it becomes possible that statistical fluctuations result in false conclusions. 12 is still high enough though, to be able to characterize the clusters.\n",
    "\n",
    "After these inicial thoughts, we can create the classifier, fit and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClusters = 12 \n",
    "kmeans_classifier = KMeans(n_clusters=nClusters, random_state=0) \n",
    "kmeans_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_classifier = kmeans_classifier.fit(clustering_data_X)\n",
    "clustering_data['kmeans_Cluster'] = kmeans_classifier.predict(clustering_data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hierarchical clustering, the algorithm starts with all data points being their own cluster, always merges two clusters that are closest to each other, untilthe chosen number of clusters (n) remains. We choose n to be 12 as well, with the same reasons as in k-means clustering. \n",
    "Another crucial parameter here is the selected type of linkage, which indicates, how the distance between two clusters should be measured. We pick ward's method. It is the increase in the sum of the squared errors when the two clusters are merged. It is more robust to outliers then single, complete and average linkage. These methods do not give reasonable results in this study.\n",
    "\n",
    "Again, we create the classicier, fit and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agg_classifier = AgglomerativeClustering(linkage =\"ward\", n_clusters=nClusters)\n",
    "Agg_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Agg_classifier = Agg_classifier.fit(clustering_data_X)\n",
    "clustering_data['Agg_Cluster'] = Agg_classifier.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Agglomerative and kMeans Clustering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before taking a closer look at each cluster, we compare the clusters received by k-means and agglomerative clustering in a contingency matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contingency_matrix(targets, classifier_labels): \n",
    "    '''\n",
    "    :param targets: list with gargets\n",
    "    :param classifier_labels: list with targets determinded by classifier\n",
    "    :return: dataframe with contingency matrix\n",
    "    '''\n",
    "    contmat = contingency_matrix(targets, classifier_labels)\n",
    "    df_contmat = pd.DataFrame(contmat)\n",
    "    targets_list = list(set(targets))\n",
    "    targets_list.sort()\n",
    "    df_contmat.index = targets_list\n",
    "    return df_contmat\n",
    "\n",
    "cm = make_contingency_matrix(clustering_data.kmeans_Cluster, clustering_data.Agg_Cluster,)\n",
    "\n",
    "# format the matrix and give names to clusters:\n",
    "for ind in cm.columns:\n",
    "    cm = cm.rename(columns={ind: 'agg_'+str(ind)}, index={ind: 'kms_'+str(ind)})\n",
    "cm['agreement'] = cm.max(axis=1) / cm.sum(axis=1)\n",
    "cm.loc['agreement'] = cm.max(axis=0) / cm.sum(axis=0)\n",
    "cm['most similar'] = cm.idxmax(axis=1)\n",
    "cm = cm.round(2)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some clusters in k-means clustering have high agreement with clusters in agglomerative clustering. We can drop those, as it will not give us more information about the donors to consider a cluster twice: If clusters have an agreement greater than 80%, we drop the agg.-cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm[\"drop?\"] = cm['agreement'].apply(lambda x: True if x>0.8 else False)\n",
    "to_drop = cm[cm['agreement']>0.8]['most similar']\n",
    "print(\"Clusters dropped:\")\n",
    "display(to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the unstandardized data to receive meaningful values for the cluster means in each feature.\n",
    "\n",
    "At first, we create for the k-means and the agglomerative clusters a dataframe that contains the average value of the targets as well as the cluster-size. This helps, to see which clusters are actually interesting for us. The dataframes are merged to work with one single set of clusters from that point. After sorting out the interesting clusters, we can check, which features characterise each cluster. For example, which features are extraordinary for a cluster that has a very high number of people donating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agg.-clustering:\n",
    "\n",
    "# Use the unstandardized data for further analysis:\n",
    "cluster_attributes_Agg = clustering_data.groupby(['Agg_Cluster']).mean()\n",
    "cluster_attributes_Agg['Cluster size'] = clustering_data['Agg_Cluster'].value_counts()\n",
    "\n",
    "# DONATION_TYPE is repleaced by new column here!\n",
    "# Use conditional probability here:\n",
    "cluster_attributes_Agg['DONATION_TYPE if TB=1'] = \\\n",
    "                    cluster_attributes_Agg['DONATION_TYPE'] / cluster_attributes_Agg['TARGET_B']\n",
    "cluster_attributes_Agg = cluster_attributes_Agg.drop('DONATION_TYPE', axis=1)\n",
    "\n",
    "# Divide in attributes (Target, size of Cluster) and features:\n",
    "attributes_Agg = ['TARGET_B', 'DONATION_TYPE if TB=1', 'Cluster size']\n",
    "cluster_features_Agg = cluster_attributes_Agg[cluster_attributes_Agg.columns.difference(attributes_Agg)]\n",
    "cluster_features_Agg = cluster_features_Agg.drop('kmeans_Cluster', axis=1)\n",
    "cluster_attributes_Agg = cluster_attributes_Agg.drop(cluster_attributes_Agg.columns.difference(attributes_Agg), axis=1)\n",
    "\n",
    "# give proper cluster_names:\n",
    "for ind in cluster_attributes_Agg.index:\n",
    "    cluster_attributes_Agg = cluster_attributes_Agg.rename(index={ind: 'agg_'+str(ind)})\n",
    "    cluster_features_Agg = cluster_features_Agg.rename(index={ind: 'agg_'+str(ind)})\n",
    "cluster_attributes_Agg.index.name = 'Cluster'\n",
    "cluster_features_Agg.index.name = 'Cluster'\n",
    "\n",
    "#drop clusters that match one from kmeans:\n",
    "cluster_attributes_Agg = cluster_attributes_Agg.drop(to_drop, axis=0) \n",
    "cluster_features_Agg = cluster_features_Agg.drop(to_drop, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans (do the same as for agg.-clustering):\n",
    "\n",
    "cluster_attributes_kmeans = clustering_data.groupby(['kmeans_Cluster']).mean()\n",
    "cluster_attributes_kmeans['Cluster size'] = clustering_data['kmeans_Cluster'].value_counts()\n",
    "\n",
    "cluster_attributes_kmeans['DONATION_TYPE if TB=1'] = \\\n",
    "                cluster_attributes_kmeans['DONATION_TYPE'] / cluster_attributes_kmeans['TARGET_B']\n",
    "cluster_attributes_kmeans = cluster_attributes_kmeans.drop('DONATION_TYPE', axis=1)\n",
    "\n",
    "attributes = ['TARGET_B', 'DONATION_TYPE if TB=1', 'Cluster size']\n",
    "cluster_features_kmeans = cluster_attributes_kmeans[cluster_attributes_kmeans.columns.difference(attributes)]\n",
    "cluster_features_kmeans = cluster_features_kmeans.drop('Agg_Cluster', axis=1)\n",
    "cluster_attributes_kmeans = cluster_attributes_kmeans.\\\n",
    "                        drop(cluster_attributes_kmeans.columns.difference(attributes), axis=1)\n",
    "\n",
    "for ind in cluster_attributes_kmeans.index:\n",
    "    cluster_attributes_kmeans = cluster_attributes_kmeans.rename(index={ind: 'kms_'+str(ind)})\n",
    "    cluster_features_kmeans = cluster_features_kmeans.rename(index={ind: 'kms_'+str(ind)})\n",
    "cluster_attributes_kmeans.index.name = 'Cluster'\n",
    "cluster_features_kmeans.index.name = 'Cluster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes attributes and features for Agg and kmeans:\n",
    "cluster_attributes = cluster_attributes_kmeans.append(cluster_attributes_Agg)\n",
    "cluster_features = cluster_features_kmeans.append(cluster_features_Agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average value of TARGET_B and DONATION_TYPE in the whole dataset:\n",
    "# (important, to check if a cluster differs)\n",
    "avg_TB = (cluster_attributes['TARGET_B']*cluster_attributes['Cluster size']).sum() \\\n",
    "         /cluster_attributes['Cluster size'].sum()\n",
    "avg_DT_ifTB1 = (cluster_attributes['DONATION_TYPE if TB=1']*cluster_attributes['DONATION_TYPE if TB=1']).sum() \\\n",
    "         /cluster_attributes['DONATION_TYPE if TB=1'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter out the clusters that are interesting for us. At least one of the target variable averages should be significantly different than the one for the whole dataset. The cluster should not be very small to exclude statistical fluctuations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interesting_clusters(attributes):\n",
    "    '''\n",
    "    :param attributes: list with attribute names \n",
    "    :return: True if interesting, else False\n",
    "    '''\n",
    "    differing_TB = False\n",
    "    differing_DT = False\n",
    "    too_small = False\n",
    "    if abs(attributes[0]-avg_TB)>0.04: # TARGET_B\n",
    "        differing_TB = True\n",
    "    if abs(attributes[2]-avg_DT_ifTB1)>0.6: # DONATION_TYPE\n",
    "        differing_DT = True\n",
    "    if attributes[1]<100:\n",
    "        too_small = True\n",
    "    return (differing_TB or differing_DT) and not too_small\n",
    "\n",
    "cluster_attributes['interesting?'] = cluster_attributes[['TARGET_B', 'Cluster size', 'DONATION_TYPE if TB=1']] \\\n",
    "                                    .apply(find_interesting_clusters, axis=1)\n",
    "\n",
    "# drop uninteresting columns and transpose for better visualization:\n",
    "cluster_features = cluster_features[cluster_attributes['interesting?']==True] \n",
    "cluster_attributes = cluster_attributes[cluster_attributes['interesting?']==True]\n",
    "cluster_attributes = cluster_attributes.transpose()\n",
    "cluster_features = cluster_features.transpose()\n",
    "\n",
    "print(f'Interesting clusters: {cluster_attributes.shape[1]}/{2*nClusters}')\n",
    "\n",
    "display(cluster_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not include all features in our analysis as this wouldbe too much for this project. Therefore, we try to concentrate on the most important ones: We need to filter out the features which characterise each cluster.\n",
    "\n",
    "We use the difference between the cluster average and the dataset average devided by the cluster average as indicator. A threshold is chosen for this variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Dataset-averages of all features:\n",
    "cluster_features[\"Dataset AVG\"] = 1\n",
    "for feature in cluster_features.index:\n",
    "    cluster_features.loc[feature, 'Dataset AVG'] = clustering_data[feature].mean()\n",
    "\n",
    "for cluster in cluster_attributes.columns:\n",
    "    cluster_features['deviation '+str(cluster)] = (cluster_features[cluster]-cluster_features['Dataset AVG']) \\\n",
    "                                                            / cluster_features['Dataset AVG']\n",
    "cluster_feature_dev = cluster_features.drop(cluster_attributes.columns, axis=1)\n",
    "cluster_feature_dev = cluster_feature_dev.drop('Dataset AVG', axis=1)\n",
    "\n",
    "# Choose a threshold for the deviation from which a feature shall be considered:\n",
    "high_dev_threshold = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make the cut and print out the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset average for TARGET_B:\\t', np.round(avg_TB,2))\n",
    "print('Dataset average for DONATION_TYPE, if TARGET_B==1:\\t', np.round(avg_DT_ifTB1,2))\n",
    "display(cluster_attributes)\n",
    "for cluster in cluster_feature_dev:\n",
    "    no = cluster[10:]\n",
    "    print('Cluster: ', no)\n",
    "    deviating_features = cluster_features[ abs(cluster_feature_dev[cluster]) > high_dev_threshold ]\n",
    "    display(deviating_features[ [no, 'Dataset AVG']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will know examine the clusters found and relate (if applicable) the behavior to the rules found in the previous section: \n",
    "\n",
    "*kms_0* is a cluster with a high fraction of donors, that do not necessarily donate higher amounts than the dataset average though. Usually, not a lot of time has passed since the person's last gift. This behavior is very simliar to the rules we found in the previous section regarding *MONTHS_SINCE_LAST_GIFT*. Additionally, the people in this cluster have received a lot of donation-commercials recently. You can draw the conclusion from this cluster that people donate frequently when receiving lots of commercials, while not giving high amounts.\n",
    "\n",
    "In *kms_2* we find a low number of donors. The average donation type is not very low, though. The *PCT_ATTRIBUTE1* (high percentage of military members in the area) is rather low. People in this cluster have not been very active recently, but quite some people have had star donorship. This behavior is closely related to the rules concerning the attribute *RECENT_RESPONSE_COUNT*.\n",
    "\n",
    "We can find a large fraction of donors that donate large amounts in cluster *kms_4*: Very intersting is the fact that although the lifetime average is low, people are very active recently and donate a lot. These are people that started donating recently. An interesting group, that would be interesting to look further into.\n",
    "\n",
    "Cluster *kms_5* is a large group with few donors and small donation amounts. It can be characterised by lots of features. Interesting is the very high cluster code, that is hard to interpret though. In general, these people do neither donate to other groups (*MOR_HIT_RATE*), are inactive in general and live in rather rural areas.\n",
    "\n",
    "Another very large cluster is *agg_0*. The fraction of donors is high and they donate large amounts. It is also characterized by a rather low number of military servants. What stands out, is that they were very active recently.\n",
    "\n",
    "Cluster *agg_4* is rather small, but stands out in the fact that people donate very low amounts. However, they have donated high amounts in their lifetimes, but are obviously inactive now (low *RECENT_RESPONSE_COUNT*, low *RECENT_STAR_STATUS*).\n",
    "\n",
    "In the last cluster (*agg_8*), a large fraction donates large amounts. They also donate to other organisations (*MOR_HIT_RATE*). An interesting fact is that they do not usually seem to own a house. The number of military servants is high in the area and they publish their phone with a higher probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to show the different clusters in 2D plots here. This is made very hard though by the large amount of features. The clusters are not necessarily distinguishable from each other in two or three dimensions. Categorical features neither serve for this kind of graphical display. \n",
    "\n",
    "We exemplarily show the clusters in the case for *MEDIAN_HOUSEHOLD_INCOME* and *DONOR_AGE* in clusters *kms_5* and *kms_9*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clusterplot_2D(feature1, feature2, cluster_no1, cluster_no2, cluster_no3=None, n=1000):\n",
    "    '''\n",
    "    :params feature: featurename\n",
    "    :params cluster_no: number of the cluster to compare\n",
    "    :param n: number of sample data points. All data point would result in a mess.\n",
    "    '''\n",
    "    plotting_data = clustering_data.sample(n=1000).copy()\n",
    "    X1 = plotting_data[plotting_data[\"kmeans_Cluster\"]==5][feature1]\n",
    "    Y1 = plotting_data[plotting_data[\"kmeans_Cluster\"]==5][feature2]\n",
    "    X2 = plotting_data[plotting_data[\"kmeans_Cluster\"]==9][feature1]\n",
    "    Y2 = plotting_data[plotting_data[\"kmeans_Cluster\"]==9][feature2]\n",
    "    X3 = plotting_data[plotting_data[\"kmeans_Cluster\"]==9][feature1]\n",
    "    Y3 = plotting_data[plotting_data[\"kmeans_Cluster\"]==9][feature2]\n",
    "    cluster_plot, cluster_ax = plt.subplots(nrows=1, ncols=1)\n",
    "    cluster_ax.scatter(X1, Y1, c='red', label=f'kms_{cluster_no1}')\n",
    "    cluster_ax.scatter(X2, Y2, c='blue', label=f'kms_{cluster_no2}')\n",
    "    if cluster_no3 != None:\n",
    "        cluster_ax.scatter(X3, Y3, c='green', label=f'kms_{cluster_no3}')\n",
    "    cluster_ax.set_xlabel(feature1)\n",
    "    cluster_ax.set_ylabel(feature2)\n",
    "    cluster_ax.legend()\n",
    "    cluster_ax.set_title('Two clusters displayed in two features')\n",
    "    plt.show()\n",
    "\n",
    "f1 = 'MEDIAN_HOUSEHOLD_INCOME'\n",
    "f2 = 'DONOR_AGE'\n",
    "f3 = 'LIFETIME_AVG_GIFT_AMT'\n",
    "clusterplot_2D(f1, f2, 5, 9, n=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is exactly what one would expect from the summary above: Higher values of income for cluster 9, no or very low difference in age. There is no visible line that devides the two clusters from each other, as the hyperplane that distinguishes between the clusters exists in higher dimensions. The clusters seem to be overlapping in this kind of graphical display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comments and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarise, association rules between features and targets could be found with the apriori algorithm and clusters of donors were determined via k-means and agglomerative clustering. The analysis could still be improved by taking a closer look into the correlations between the features during pre-processing. The analysis was strongly limited due to the fact that the apriori algorithm needs a high amount of memory space. Therefore, a lot of information about the donors was lost during binning and sorting out features.\n",
    "The two ways of analysis yielded different aspects, but overall leave some main conclusions:\n",
    "\n",
    "- A short time since the last gift results in a high probability that the person will donate again, although the amount is not necessarily high.\n",
    "- When a person did not respond a lot recently, he or she will probably not donate. In case of a donation, the donation has high likelihood to be high.\n",
    "- Higher wealth leads in general to more and larger donations.\n",
    "- People in urban areas donate more money than in rural areas.\n",
    "- People with higher age donate more often.\n",
    "- In areas with a low percentage of male military servants, people donate more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
