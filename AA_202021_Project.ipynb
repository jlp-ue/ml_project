{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning / Aprendizagem Automática\n",
    "\n",
    "## Diogo Soares, André Falcão and Sara C. Madeira, 2020/21\n",
    "\n",
    "# ML Project  - Learning about Donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics\n",
    "\n",
    "**Students are encouraged to work in teams of 3 people**. \n",
    "\n",
    "Projects with smaller teams are allowed, in exceptional cases, but will not have better grades for this reason. \n",
    "\n",
    "The quality of the project will dictate its grade, not the number of people working.\n",
    "\n",
    "**The project's solution should be uploaded in Moodle before the end of December, 18th (last day before Christmas holidays).** \n",
    "\n",
    "Students should **upload a `.zip` file** containing all the files necessary for project evaluation. \n",
    "\n",
    "**It is mandatory to produce a Jupyter notebook containing code and text/images/tables/etc describing the solution and the results. The notebook is both the solution and the report.**\n",
    "\n",
    "**Decisions should be fundamented and results should be critically discussed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The team should use [Python 3](https://www.python.org) and [Jupyter Notebook](http://jupyter.org), together with **[Scikit-learn](http://scikit-learn.org/stable/)**, **[Orange3](https://orange.biolab.si)**, or **both**.\n",
    "\n",
    "**[Orange3](https://orange.biolab.si)** can be used through its **[programmatic version](https://docs.orange.biolab.si/3/data-mining-library/)**, by importing and using its packages, or throught its **workflow version**. \n",
    "\n",
    "**It is up to the team to decide when to use Scikit-learn, Orange, or both.**\n",
    "\n",
    "In this context, your Jupyter notebook might have a mix of code, results, text explanations, workflow figures, etc. \n",
    "\n",
    "In case you use Orange/workflows for some tasks you should also deliver the workflow files and explain the options taken in each widget in your notebook.\n",
    "\n",
    "**You can use this noteboook and the sections below as template for your work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset to be analysed is **`Donors_dataset.csv`**, made available together with this project description. This dataset, downloaded from [Kaggle](https://www.kaggle.com), contains selected data from the following dataset: [Donors-Prediction](https://www.kaggle.com/momohmustapha/donorsprediction/). \n",
    "\n",
    "\n",
    "**In this project, your team is supposed to use only tabular data (not Images or Image Metadata) and see how far you can go in predicting donations and understanding the donors. You should use both supervised and unsupervised learning to tackled 2 tasks:**\n",
    "\n",
    "1. **Task 1 (Supervised Learning) - Predicting Donation and Donation Type**\n",
    "2. **Task 2 (Unsupervised Learning) - Characterizing Donors**\n",
    "\n",
    "The **`Donors_dataset.csv`** you should learn from has **19.372 instances** described by **50 data fields** that you might use as **categorical/numerical features** \n",
    "\n",
    "### File Descriptions\n",
    "\n",
    "* **Donors_dataset.csv** - Tabular/text data to be used in the machine learning tasks.\n",
    "\n",
    "\n",
    "### Data Fields\n",
    "\n",
    "* **CARD_PROM_12** - number of card promotions sent to the individual by the charitable organization in the past 12 months\n",
    "* **CLUSTER_CODE** - one of 54 possible cluster codes, which are unique in terms of socioeconomic status, urbanicity, ethnicity, and other demographic characteristics\n",
    "* **CONTROL_NUMBER** - unique identifier of each individual\n",
    "* **DONOR_AGE** - age as of last year's mail solicitation\n",
    "* **DONOR_GENDER** - actual or inferred gender\n",
    "* **FILE_AVG_GIFT** - this variable is identical to LIFETIME_AVG_GIFT_AMT\n",
    "* **FILE_CARD_GIFT** - lifetime average donation (in \\\\$) from the individual in response to all card solicitations from the charitable organization\n",
    "* **FREQUENCY_STATUS_97NK** - based on the period of recency (determined by RECENCY_STATUS_96NK), which is the past 12 months for all groups except L and E. L and E are 13–24 months ago and 25–36 months ago, respectively: 1 if one donation in this period, 2 if two donations in this period, 3 if three donations in this period, and 4 if four or more donations in this period.\n",
    "* **HOME_OWNER** - H if the individual is a homeowner, U if this information is unknown\n",
    "* **INCOME_GROUP** - one of 7 possible income level groups based on a number of demographic characteristics\n",
    "* **IN_HOUSE** - 1 if the individual has ever donated to the charitable organization's In House program, 0 if not\n",
    "* **LAST_GIFT_AMT** - amount of the most recent donation from the individual to the charitable organization\n",
    "* **LIFETIME_AVG_GIFT_AMT** - lifetime average donation (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_CARD_PROM** - total number of card promotions sent to the individual by the charitable organization\n",
    "* **LIFETIME_GIFT_AMOUNT** - total lifetime donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_COUNT** - total number of donations from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_RANGE** - maximum donation amount from the individual minus minimum donation amount from the individual\n",
    "* **LIFETIME_MAX_GIFT_AMT** - maximum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_MIN_GIFT_AMT** - minimum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_PROM** - total number of promotions sent to the individual by the charitable organization\n",
    "* **MEDIAN_HOME_VALUE** - median home value (in 100\\\\$) as determined by other input variables\n",
    "* **MEDIAN_HOUSEHOLD_INCOME** - median household income (in 100\\\\$) as determined by other input variables\n",
    "* **MONTHS_SINCE_FIRST_GIFT** - number of months since the first donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_GIFT** - number of months since the most recent donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_PROM_RESP** - number of months since the individual has responded to a promotion by the charitable organization\n",
    "* **MONTHS_SINCE_ORIGIN** - number of months that the individual has been in the charitable organization's database\n",
    "* **MOR_HIT_RATE** - total number of known times the donor has responded to a mailed solicitation from a group other than the charitable organization\n",
    "* **NUMBER_PROM_12** - number of promotions (card or other) sent to the individual by the charitable organization in the past 12 months\n",
    "* **OVERLAY_SOURCE** - the data source against which the individual was matched: M if Metromail, P if Polk, B if both\n",
    "* **PCT_ATTRIBUTE1** - percent of residents in the neighborhood in which the individual lives that are males and active military\n",
    "* **PCT_ATTRIBUTE2** - percent of residents in the neighborhood in which the individual lives that are males and veterans\n",
    "* **PCT_ATTRIBUTE3** - percent of residents in the neighborhood in which the individual lives that are Vietnam veterans\n",
    "* **PCT_ATTRIBUTE4** - percent of residents in the neighborhood in which the individual lives that are WWII veterans\n",
    "* **PCT_OWNER_OCCUPIED** - percent of owner-occupied housing in the neighborhood in which the individual lives\n",
    "* **PEP_STAR** - 1 if individual has ever achieved STAR donor status, 0 if not\n",
    "* **PER_CAPITA_INCOME** - per capita income (in \\\\$) of the neighborhood in which the individual lives\n",
    "* **PUBLISHED_PHONE** - 1 if the individual's telephone number is published, 0 if not\n",
    "* **RECENCY_STATUS_96NK** - recency status as of two years ago: A if active donor, S if star donor, N if new donor, E if inactive donor, F if first time donor, L if lapsing donor\n",
    "* **RECENT_AVG_CARD_GIFT_AMT** - average donation from the individual in response to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_AVG_GIFT_AMT** - average donation (in \\\\$) from the individual to the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_COUNT** - number of times the individual has responded to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_PROP** - proportion of responses to the individual to the number of card solicitations from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_COUNT** - number of times the individual has responded to a promotion (card or other) from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_PROP** - proportion of responses to the individual to the number of (card or other) solicitations from the charitable organization since four years ago\n",
    "* **RECENT_STAR_STATUS** - 1 if individual has achieved star donor status since four years ago, 0 if not\n",
    "* **SES** - one of 5 possible socioeconomic codes classifying the neighborhood in which the individual lives\n",
    "* **TARGET_B** - 1 if individual donated in response to last year's 97NK mail solicitation from the charitable organization, 0 if individual did not\n",
    "* **TARGET_D** - amount of donation (in \\\\$) from the individual in response to last year's 97NK mail solicitation from the charitable organization\n",
    "* **URBANICITY** - classification of the neighborhood in which the individual lives: U if urban, C if city, S if suburban, T if town, R if rural, ? if missing\n",
    "* **WEALTH_RATING** - one of 10 possible wealth rating groups based on a number of demographic characteristics\n",
    "\n",
    "\n",
    "### Donation TYPE\n",
    "\n",
    "You are supposed to create a new column/feature named `DONATION_TYPE`, whose values describe ranges of the donation amount (DA) reported in feature `TARGET_D`:\n",
    "* `A` - DA >= 50\n",
    "* `B` - 20 <= DA < 50 \n",
    "* `C` - 13 <= DA < 20\n",
    "* `D` - 10 <= DA < 13\n",
    "* `E` - DA < 10\n",
    "\n",
    "\n",
    "### **Important Notes on Data Cleaning and Preprocessing**\n",
    "\n",
    "   1. Data can contain **errors/typos**, whose correction might improve the analysis.\n",
    "   2. Some features can contain **many values**, whose grouping in categories (aggregation into bins) might improve the analysis.\n",
    "   3. Data can contain **missing values**, that you might decide to fill. You might also decide to eliminate instances/features with high percentages of missing values.\n",
    "   4. **Not all features are necessarily important** for the analysis.\n",
    "   5. Depending on the analysis, **some features might have to be excluded**.\n",
    "   6. Class distribution is an important characteristic of the dataset that should be checked. **Class imbalance** might impair machine learning. \n",
    "  \n",
    "Some potentially useful links:\n",
    "\n",
    "* Data Cleaning and Preprocessing in Scikit-learn: https://scikit-learn.org/stable/modules/preprocessing.html#\n",
    "* Data Cleaning and Preprocessing in Orange: https://docs.biolab.si//3/visual-programming/widgets/data/preprocess.html\n",
    "* Dealing with imbalance datasets: https://pypi.org/project/imbalanced-learn/ and https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0 (Know your Data) - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"Donors_dataset.csv\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: weiter inspizieren,ob es ausreisser gibt. \n",
    "\n",
    "raw_data.WEALTH_RATING[:].plot()\n",
    "raw_data.WEALTH_RATING[:].describe()\n",
    "\n",
    "#raw_data.URBANICITY.plot(kind=\"hist\", bins =10 )\n",
    "#raw_data.MONTHS_SINCE_LAST_PROM_RESP[raw_data.MONTHS_SINCE_LAST_PROM_RESP < 0]\n",
    "#raw_data.DONOR_AGE[raw_data.DONOR_AGE == 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **understand better the features**, their distribution of values, potential errors, etc and plan/describe what data preprocessing steps should be performed next. Very important also is to check the distribution of values in the target (class distribution). \n",
    "\n",
    "Here you can find a notebook with some examples of what you can do in **Exploratory Data Analysis**: https://www.kaggle.com/artgor/exploration-of-data-step-by-step/notebook. You can also use Orange widgets for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = raw_data['DONOR_GENDER'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plt.set_title('DONOR_GENDER classes counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = raw_data['TARGET_B'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plt.set_title('TARGET_B classes counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = raw_data['HOME_OWNER'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plt.set_title('HOME_OWNER classes counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = raw_data['URBANICITY'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plt.set_title('URBANICITY classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot(x=\"TARGET_B\", y=\"DONOR_AGE\", data=raw_data)\n",
    "#plt.set_title('TARGET_B by DONOR_AGE and DONOR_GENDER')\n",
    "\n",
    "plt2 = raw_data['DONOR_AGE'].value_counts().sort_index().plot()\n",
    "plt2.set_title('AA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot(x=\"TARGET_B\", y=\"DONOR_AGE\", hue=\"DONOR_GENDER\", data=raw_data)\n",
    "#plt.set_title('TARGET_B by DONOR_AGE and DONOR_GENDER')\n",
    "\n",
    "sns.violinplot(x=\"DONOR_AGE\", y=\"TARGET_D\", data=raw_data)\n",
    "plt.set_title('TARGET_B by DONOR_AGE and DONOR_GENDER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"TARGET_B\", y=\"DONOR_AGE\", hue=\"HOME_OWNER\", data=raw_data)\n",
    "plt.set_title('TARGET_B by DONOR_AGE and HOME_OWNER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.violinplot(x=\"TARGET_B\", y=\"PER_CAPITA_INCOME\", hue=\"DONOR_GENDER\", data=raw_data)\n",
    "plt.set_title('TARGET_B by PER_CAPITA_INCOME and DONOR_GENDER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.violinplot(x=\"TARGET_B\", y=\"PER_CAPITA_INCOME\", data=raw_data)\n",
    "plt.set_title('TARGET_B by PER_CAPITA_INCOME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots added by Flo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as mpt #other name because plt is already used otherwise\n",
    "import numpy as np\n",
    "\n",
    "# sort features in different categories for plotting:\n",
    "all_features = list(raw_data.columns[2:])\n",
    "pscontinuous_features = ['CONTROL_NUMBER', 'MONTHS_SINCE_ORIGIN', 'DONOR_AGE', 'PER_CAPITA_INCOME', \\\n",
    "                              'WEALTH_RATING', 'MEDIAN_HOME_VALUE', 'MEDIAN_HOUSEHOLD_INCOME', \\\n",
    "                             'PCT_OWNER_OCCUPIED', 'PCT_ATTRIBUTE2', 'PCT_ATTRIBUTE3', 'PCT_ATTRIBUTE4', \\\n",
    "                              'RECENT_RESPONSE_PROP', 'RECENT_AVG_GIFT_AMT', 'RECENT_CARD_RESPONSE_PROP', \\\n",
    "                              'RECENT_AVG_CARD_GIFT_AMT', 'RECENT_RESPONSE_COUNT', 'RECENT_CARD_RESPONSE_COUNT', \\\n",
    "                              'MONTHS_SINCE_LAST_PROM_RESP', 'LIFETIME_CARD_PROM', 'LIFETIME_PROM', \\\n",
    "                              'LIFETIME_GIFT_COUNT', 'LAST_GIFT_AMT', 'NUMBER_PROM_12', 'MONTHS_SINCE_LAST_GIFT', \\\n",
    "                              'MONTHS_SINCE_FIRST_GIFT', 'FILE_CARD_GIFT']\n",
    "categorical_features = ['IN_HOUSE', 'URBANICITY', 'SES', 'HOME_OWNER', 'DONOR_GENDER', 'INCOME_GROUP', \\\n",
    "                        'PUBLISHED_PHONE', 'OVERLAY_SOURCE', 'PEP_STAR', 'RECENCY_STATUS_96NK', \\\n",
    "                        'FREQUENCY_STATUS_97NK', 'CARD_PROM_12']\n",
    "other_features = ['CLUSTER_CODE', 'MOR_HIT_RATE', 'PCT_ATTRIBUTE1', 'RECENT_STAR_STATUS', 'LIFETIME_GIFT_AMOUNT', \\\n",
    "                  'LIFETIME_AVG_GIFT_AMT', 'LIFETIME_GIFT_RANGE', 'LIFETIME_MAX_GIFT_AMT', 'LIFETIME_MIN_GIFT_AMT', \\\n",
    "                  'FILE_AVG_GIFT']\n",
    "\n",
    "# check, if all are included and not couble counts:\n",
    "feature_lists = pscontinuous_features+categorical_features+other_features\n",
    "print('All features included and no doubles: ', \\\n",
    "      len(all_features)==len(feature_lists) and set(feature_lists)==set(all_features))\n",
    "\n",
    "def create_plots(features_to_plot, plottype='violin'):\n",
    "    '''Creates plots for given features. Plottypes: 'violin', 'count' . We can add more if necessary.\n",
    "    carful: if number of values per feature is high when 'count' is chosen, running time goes up. '''\n",
    "    print(f'{len(features_to_plot)} plots:')\n",
    "    ncols = 3\n",
    "    nrows = int(len(features_to_plot)/ncols)+1\n",
    "    newplots = mpt.figure(figsize=(ncols*6,nrows*6))\n",
    "    for ind, feature in enumerate(features_to_plot):\n",
    "        mpt.subplot(nrows, ncols, ind+1)\n",
    "        if plottype=='violin':\n",
    "            sns.violinplot(x=\"TARGET_B\", y=feature, data=raw_data)\n",
    "            mpt.title(f'TARGET_B by {feature}')\n",
    "        if plottype!='violin':\n",
    "            sns.countplot(x='TARGET_B', data=raw_data, hue=feature);\n",
    "            mpt.title(f'{feature} in TARGET_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(pscontinuous_features, 'violin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_plots(categorical_features, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(other_features, 'violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 (Supervised Learning) - Predicting Donation and Donation Type\n",
    "\n",
    "In this task you should target 3 classification tasks:\n",
    "1. **Predicting  Donation (binary classification task)**; \n",
    "2. **Predicting Donation TYPE (multiclass classification)**; and\n",
    "3. **Train specialized models for SES (socioeconomic classification)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should:**\n",
    "\n",
    "* Choose **one classifier in each category**: Tree models, Rule models, Linear models, Distance-based models, and Probabilistic models.\n",
    "* Use cross-validation to evaluate the results. \n",
    "* Present and discuss the results for different evaluation measures, present confusion matrices. Remember that not only overall results are important. Check what happens when learning to predict each class.\n",
    "* Describe the parameters used for each classifier and how their choice impacted or not the results.\n",
    "* Choose the best classifier and fundament you choice.\n",
    "* **Discuss critically your choices and the results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming donation amount in classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_donation_type (row):\n",
    "    if row['TARGET_D'] >= 50:\n",
    "        return 'A'\n",
    "    if row['TARGET_D'] >= 20 and row['TARGET_D'] < 50:\n",
    "        return 'B'\n",
    "    if row['TARGET_D'] >= 13 and row['TARGET_D'] < 20:\n",
    "        return 'C'\n",
    "    if row['TARGET_D'] >= 10 and row['TARGET_D'] < 13:\n",
    "        return 'D'\n",
    "    if row['TARGET_D'] < 10:\n",
    "        return 'E'\n",
    "    return '?'\n",
    "\n",
    "#transformed_data = raw_data.copy()\n",
    "#transformed_data['DONATION_TYPE'] = transformed_data.apply (lambda row: label_donation_type(row), axis=1)\n",
    "\n",
    "#transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming age in bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: \n",
    "#    - decide if age < 20 not relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def donor_age (row):\n",
    "    if row['DONOR_AGE'] <= 20:\n",
    "        return 10\n",
    "    return row['DONOR_AGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = raw_data.copy()\n",
    "transformed_data['DONATION_TYPE'] = transformed_data.apply (lambda row: label_donation_type(row), axis=1)\n",
    "#transformed_data['DONOR_AGE_BIN'] = transformed_data.apply (lambda row: donor_age(row), axis=1)\n",
    "transformed_data['DONOR_AGE_BIN'] = pd.cut(transformed_data['DONOR_AGE'], bins=[-25000,0,10,20,30,40,50,60,70,80,90,100], \n",
    "                                           labels=[\"Z\",\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"])\n",
    "\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot(x=\"DONOR_AGE_BIN\", y=\"DONATION_TYPE\", data=transformed_data)\n",
    "#plt.set_title('TARGET_B by DONOR_AGE and DONOR_GENDER')\n",
    "#plt = transformed_data['DONATION_TYPE'].value_counts().sort_index().plot(kind = 'barh')\n",
    "#titanic = sns.load_dataset(\"titanic\")\n",
    "#sns.catplot(transformed_data['DONOR_AGE_BIN'], transformed_data['DONATION_TYPE'], data=titanic)\n",
    "#plt2 = transformed_data['DONOR_AGE_BIN'].value_counts().sort_index().plot()\n",
    "#plt2.set_title('AA')\n",
    "transformed_data.groupby([\"DONOR_AGE_BIN\"])[\"TARGET_D\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop TARGET_D because it is replaced by DONATION_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transformed_data.drop(columns = ('TARGET_D'))\n",
    "transformed_data = transformed_data.drop(columns = ('DONOR_AGE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = transformed_data['DONATION_TYPE'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plt.set_title('DONATION_TYPE classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot(x=\"TARGET_B\", y=\"DONOR_AGE_BIN\", hue=\"DONATION_TYPE\", data=transformed_data)\n",
    "#plt.set_title('TARGET_B by DONOR_AGE and DONATION_TYPE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO: \n",
    "\n",
    "#transformed_data[transformed_data.isna().any(axis=1)]\n",
    "\n",
    "\n",
    "# how to replace WEALTH_RATING ? \n",
    "# its from 0 to 9 , so missing data could be = 10 \n",
    "# or replace with a number or with mean ? \n",
    "# TODO: try out different values \n",
    "\n",
    "transformed_data.WEALTH_RATING =  transformed_data.WEALTH_RATING.fillna(10)\n",
    "\n",
    "\n",
    "# how to replace DONOR_AGE ? \n",
    "# replace with a number or with mean ? \n",
    "# first we try mean\n",
    "# TODO: try out different values : median ? \n",
    "\n",
    "#transformed_data.DONOR_AGE =  transformed_data.DONOR_AGE.fillna((transformed_data.DONOR_AGE.mean()))\n",
    "\n",
    "# how to replace INCOME_GROUP ? \n",
    "# its from 1 to 7 , so missing data could be = 8\n",
    "# or replace with a number or with mean ? \n",
    "# TODO: try out different values \n",
    "# first tried with 0 \n",
    "# replace with 8\n",
    "transformed_data.INCOME_GROUP =  transformed_data.INCOME_GROUP.fillna(8)\n",
    "\n",
    "\n",
    "# how to replace MONTHS_SINCE_LAST_PROM_RESP ? \n",
    "# its from normally : 0 to 36. \n",
    "# negative values make no sense here, a person cant respond in a negative amount of time. \n",
    "# we can replace with the maximum value (36)or replace with a number or with mean. \n",
    "# first we try the mean()\n",
    "# TODO: try out different values :  median ? \n",
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP =  transformed_data.MONTHS_SINCE_LAST_PROM_RESP.fillna(transformed_data.MONTHS_SINCE_LAST_PROM_RESP.mean())\n",
    "\n",
    "\n",
    "#DONOR_AGE_BIN \n",
    "# replace all NaN with zero\n",
    "\n",
    "transformed_data.DONOR_AGE_BIN =  transformed_data.DONOR_AGE_BIN.fillna(\"Z\")\n",
    "#transformed_data.DONOR_AGE_BIN =  transformed_data.DONOR_AGE_BIN.fillna(transformed_data.DONOR_AGE_BIN.mode())\n",
    "\n",
    "#transformed_data = transformed_data[transformed_data.DONOR_AGE_BIN != \"Z\"]\n",
    "\n",
    "\n",
    "\n",
    "transformed_data.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace false values (outliers) with mean of column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOR_HIT_RATE : time of answers on other mailings. seems to high, will be replaced by column mean. \n",
    "transformed_data.MOR_HIT_RATE = transformed_data.MOR_HIT_RATE.apply(lambda x: (transformed_data.MOR_HIT_RATE.mean()) if x > 100 else x)\n",
    "\n",
    "# MONTHS_SINCE_LAST_PROM_RESP : months since last answer cant be negative,will be replaced by column mean. \n",
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP = transformed_data.MONTHS_SINCE_LAST_PROM_RESP.apply(lambda x: (transformed_data.MONTHS_SINCE_LAST_PROM_RESP.mean()) if x < 0.0 else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show Columns that are of the type \"object\" and need to be transformed to numerical values\n",
    "\n",
    "obj_df = transformed_data.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.DONOR_AGE_BIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "\n",
    "transformed_data[\"URBANICITY\"] = lb_make.fit_transform(transformed_data[\"URBANICITY\"])\n",
    "transformed_data[\"SES\"] = lb_make.fit_transform(transformed_data[\"SES\"])\n",
    "transformed_data[\"CLUSTER_CODE\"] = lb_make.fit_transform(transformed_data[\"CLUSTER_CODE\"])\n",
    "transformed_data[\"HOME_OWNER\"] = lb_make.fit_transform(transformed_data[\"HOME_OWNER\"])\n",
    "transformed_data[\"DONOR_GENDER\"] = lb_make.fit_transform(transformed_data[\"DONOR_GENDER\"])\n",
    "transformed_data[\"OVERLAY_SOURCE\"] = lb_make.fit_transform(transformed_data[\"OVERLAY_SOURCE\"])\n",
    "transformed_data[\"RECENCY_STATUS_96NK\"] = lb_make.fit_transform(transformed_data[\"RECENCY_STATUS_96NK\"])\n",
    "transformed_data[\"DONATION_TYPE\"] = lb_make.fit_transform(transformed_data[\"DONATION_TYPE\"])\n",
    "transformed_data[\"DONOR_AGE_BIN\"] = lb_make.fit_transform(transformed_data[\"DONOR_AGE_BIN\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data Cleaning\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html#\n",
    "\n",
    "- ~~visual outlier detection . (luki)~~\n",
    "- todo: (luki)\n",
    "    * Outlier Detection with Standard Deviation\n",
    "    * https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "- todo: errors / typos (verschiedene Nans-Replacing methoden probieren : mean, median, neue klasse. \n",
    "- todo: feature engineering:  (parallel zum model training)\n",
    "    * You might also decide to eliminate instances/features with high percentages of missing values. \n",
    "    * Not all features are necessarily important for the analysis.\n",
    "    * Depending on the analysis, some features might have to be excluded\n",
    "    \n",
    "\n",
    "\n",
    "### Data transformation: \n",
    "\n",
    "- todo: putting data into bins / clusters (robby)\n",
    "    * maybe DONOR_AGE ? \n",
    "    * more columns ?\n",
    "    * all columns with money values (\\\\$)\n",
    "    \n",
    "    \n",
    "- todo: Class distribution is an important characteristic of the dataset that should be checked. Class imbalance might impair machine learning.\n",
    "    * todo: Resampling strategies for imbalanced datasets (robby)\n",
    "    * https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "    * https://pypi.org/project/imbalanced-learn/\n",
    "    * or extracting same percentages of classes for training and test? \n",
    "    \n",
    "    \n",
    "- todo: oneHot Encoding Feaature for all categorical features ? (Flo)\n",
    "\n",
    "\n",
    "\n",
    "### Model Training: \n",
    "\n",
    "- Tree Models (luki)\n",
    "    * ~~Predicting Donation (binary classification task);~~\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "    * class significance ? \n",
    "    * Parameter anpassen: tree - tiefe \n",
    "- rule based (rob)\n",
    "    * Predicting Donation (binary classification task);\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "- linear based (rob)\n",
    "    * Predicting Donation (binary classification task);\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "- dist (luki)\n",
    "    * Predicting Donation (binary classification task);\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "- probabilistic (luki)\n",
    "    * Predicting Donation (binary classification task);\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "- Train specialized models for SES (socioeconomic classification)\n",
    "  \n",
    "### Unsupervised learning: \n",
    "\n",
    "- Association rule mining to find associations between the features and the target Donation/DonationTYPE. (Flo)\n",
    "- Clustering algorithms to find similar groups of donors. Is it possible to find groups of donors with the same/similar DonationTYPE? (Flo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting up the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete nans \n",
    "\n",
    "#transformed_data = transformed_data.dropna()\n",
    "#transformed_data = transformed_data.reset_index(drop=True)\n",
    "\n",
    "#transformed_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = transformed_data.sample(frac=0.8,random_state=0)\n",
    "test_dataset = transformed_data.drop(train_dataset.index)\n",
    "\n",
    "X_train = train_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\", \"CONTROL_NUMBER\"])\n",
    "X_test = test_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\", \"CONTROL_NUMBER\"])\n",
    "\n",
    "y_train_target_b = train_dataset.pop(\"TARGET_B\")\n",
    "y_test_target_b = test_dataset.pop('TARGET_B')\n",
    "\n",
    "#y_train_donation_type = train_dataset[\"DONATION_TYPE\"].values\n",
    "#y_test_donation_type = test_dataset[\"DONATION_TYPE\"].values\n",
    "\n",
    "\n",
    "y_train_donation_type = train_dataset.pop(\"DONATION_TYPE\")\n",
    "y_test_donation_type = test_dataset.pop('DONATION_TYPE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Models: Tree models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Donation (binary classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descision Trees for predicting Donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = tree.DecisionTreeClassifier(max_depth=3, max_leaf_nodes=5)\n",
    "decision_tree = decision_tree.fit(X_train, y_train_target_b)\n",
    "y_test_target_b.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree.plot_tree(decision_tree, feature_names = X_train.columns, fontsize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "#feature_cols = list(X_train.columns)\n",
    "#r = export_text(decision_tree, feature_names=feature_cols)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = decision_tree.predict(X_test)\n",
    "print(\"The Array is : \")\n",
    "for i in y_pred:\n",
    "    #if i == 1:\n",
    "        #print(i, end = ' ')\n",
    "    print(i, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_target_b, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best so far: \n",
    "\n",
    "1. 0.7663913267940113\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'max_leaf_nodes': list(range(2, 20)),\n",
    "    'min_samples_split': range(2,6),\n",
    "    \"max_depth\": range(1,6),\n",
    "    \"min_samples_leaf\": range(1,5)}\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    decision_tree,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "#grid_search_cv.fit(X_train, y_train_target_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "Best so far:\n",
    "\n",
    "\n",
    "{'criterion': 'gini',\n",
    " 'max_depth': 3,\n",
    " 'max_leaf_nodes': 5,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "Best so far: \n",
    "\n",
    "1. DecisionTreeClassifier(max_depth=3, max_leaf_nodes=5)\n",
    "2. DecisionTreeClassifier(criterion='entropy', max_depth=3, max_leaf_nodes=6)\n",
    "3. DecisionTreeClassifier(criterion='entropy', max_depth=4, max_leaf_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "Best so far: \n",
    "\n",
    "* 0.7511937024132146\n",
    "* 0.7486277836088578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Donation TYPE (multiclass classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree for multiclass classification \n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "# loading the iris dataset \n",
    "iris = datasets.load_iris() \n",
    "  \n",
    "# X -> features, y -> label \n",
    "X = iris.data \n",
    "y = iris.target \n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) \n",
    "  \n",
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_multi = tree.DecisionTreeClassifier()\n",
    "decision_tree_multi = decision_tree_multi.fit(X_train, y_train_donation_type)\n",
    "y_train_donation_type.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree.plot_tree(decision_tree_multi, feature_names = X_train.columns, fontsize = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "#feature_cols = list(X_train.columns)\n",
    "#r = export_text(decision_tree, feature_names=feature_cols)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_multi = decision_tree_multi.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"The Array is : \")\n",
    "for i in y_pred_multi:\n",
    "    if i == 0: \n",
    "        print(i, end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_donation_type, y_pred_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'criterion': [\"gini\", \"entropy\"],\n",
    "    'max_leaf_nodes': list(range(2, 20)),\n",
    "    'min_samples_split': range(2,6),\n",
    "    \"max_depth\": range(1,6),\n",
    "    \"min_samples_leaf\": range(1,5)}\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    decision_tree_multi,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "#grid_search_cv.fit(X_train, y_train_donation_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "Best so far:\n",
    "\n",
    "\n",
    "{'criterion': 'gini',\n",
    " 'max_depth': 3,\n",
    " 'max_leaf_nodes': 5,\n",
    " 'min_samples_leaf': 1,\n",
    " 'min_samples_split': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "Best so far: \n",
    "\n",
    "1. DecisionTreeClassifier(max_depth=3, max_leaf_nodes=5)\n",
    "2. DecisionTreeClassifier(criterion='entropy', max_depth=3, max_leaf_nodes=6)\n",
    "3. DecisionTreeClassifier(criterion='entropy', max_depth=4, max_leaf_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test_donation_type, y_pred_multi)\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "cm=confusion_matrix(y_test_donation_type,y_pred_multi)\n",
    "print('Confusion Matrix: \\n', cm)\n",
    "print(classification_report(y_test_donation_type, y_pred_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Models: Rule models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: http://rasbt.github.io/mlxtend/ (apriori algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Models: Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: linear regression or SVM ? \n",
    "\n",
    "\n",
    "# importing necessary libraries \n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "# loading the iris dataset \n",
    "iris = datasets.load_iris() \n",
    "  \n",
    "# X -> features, y -> label \n",
    "X = iris.data \n",
    "y = iris.target \n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) \n",
    "  \n",
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test, y_test) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Models: Distance-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: knn\n",
    "\n",
    "\n",
    "# importing necessary libraries \n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "  \n",
    "# loading the iris dataset \n",
    "iris = datasets.load_iris() \n",
    "  \n",
    "# X -> features, y -> label \n",
    "X = iris.data \n",
    "y = iris.target \n",
    "  \n",
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0) \n",
    "  \n",
    "# training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test, y_test) \n",
    "print accuracy \n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test)  \n",
    "cm = confusion_matrix(y_test, knn_predictions) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: naive bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 (Unsupervised Learning) - Characterizing Donors and Donation Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **use unsupervised learning algorithms and try to characterize donors (people who really did a donation) and their donation type**. You can use:\n",
    "* **Association rule mining** to find **associations between the features and the target Donation/DonationTYPE**.\n",
    "* **Clustering algorithms to find similar groups of donors**. Is it possible to find groups of donors with the same/similar DonationTYPE?\n",
    "* **Be creative and define your own unsupervised analysis!** What would it be interesting to find out ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after complete processing, all columns should be used\n",
    "interesting_features = ['TARGET_B', 'HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE'] \n",
    "\n",
    "# data used for Rule Mining:\n",
    "RM_transformed_data = transformed_data[interesting_features]\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources:\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html  -   6.3.4. Encoding categorical features\n",
    "# TP05: 2.2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "def ohe_encode(col_names, X=RM_transformed_data):\n",
    "    '''Takes columns to encode (format: ['colum1', 'column2', ...]) and DataFrame X with all columns. \n",
    "    Encodes features and replaces old columns in X. Returns updated X'''\n",
    "    enc = OneHotEncoder()\n",
    "    matrix = X[col_names].to_numpy()\n",
    "    enc.fit(matrix)\n",
    "    matrix = enc.transform(matrix).toarray()\n",
    "    \n",
    "    categories_new = np.array(enc.categories_)\n",
    "    for ind1, cat in enumerate(categories_new):\n",
    "        for ind2, cat_new in enumerate(cat):\n",
    "            categories_new[ind1][ind2] = col_names[ind1]+':'+cat_new\n",
    "    features_new = categories_new.reshape(categories_new.size,1)\n",
    "\n",
    "    new_df = pd.DataFrame(matrix)\n",
    "    new_df.columns = np.concatenate(features_new.ravel()).tolist()\n",
    "\n",
    "    updated_df = pd.concat([X, new_df], axis=1)\n",
    "    updated_df = updated_df.drop(col_names, axis=1)\n",
    "    \n",
    "    return(updated_df)\n",
    "\n",
    "cols_not_binary = ['HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE']\n",
    "RM_binary_data = ohe_encode(cols_not_binary)\n",
    "RM_binary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Binning for all interesting features (first preprocessing section)\n",
    "- put the OneHotEncoding in first preprocessing section?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# calculate frequent patterns:\n",
    "freq_patterns = apriori(RM_binary_data, min_support=0.05, use_colnames=True) # maybe choose different min_support..\n",
    "#freq_patterns['size'] = freq_patterns['itemsets'].apply(lambda x: len(x))\n",
    "#freq_patterns = freq_patterns[freq_patterns['size']>1]\n",
    "#freq_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# careful here, if we change '?' again maybe...\n",
    "def check_if_interesting(x):\n",
    "    # Interesting (maybe different criteria..):\n",
    "    # - consequents==(TARGET_B or DONATION_TYPE)\n",
    "    # - TARGET_B, B, D, E not in antecedents\n",
    "    targets = ['TARGET_B', 'DONATION_TYPE:A', 'DONATION_TYPE:B', 'DONATION_TYPE:C', \n",
    "               'DONATION_TYPE:D', 'DONATION_TYPE:E', 'DONATION_TYPE:?']\n",
    "    target_is_only_consequents = any(item in targets for item in x[1]) and len(x[1])==1\n",
    "    target_not_in_ancedents = not any(item in targets for item in x[0])\n",
    "    return target_is_only_consequents and target_not_in_ancedents\n",
    "\n",
    "# generate assiciation rules:\n",
    "as_rules = association_rules(freq_patterns, metric=\"confidence\", min_threshold=0.2)\n",
    "# filter out uninteresting rules:\n",
    "as_rules['interesting?'] = as_rules[['antecedents', 'consequents']].apply(check_if_interesting, axis=1)\n",
    "as_rules = as_rules[ as_rules['interesting?']==True]\n",
    "as_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Check other interesting criteria for rules\n",
    "- evaluate which metrix is the most reasonable (confidence, lift, etc..)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comments and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
