{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning / Aprendizagem Automática\n",
    "\n",
    "## Diogo Soares, André Falcão and Sara C. Madeira, 2020/21\n",
    "\n",
    "# ML Project  - Learning about Donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics\n",
    "\n",
    "**Students are encouraged to work in teams of 3 people**. \n",
    "\n",
    "Projects with smaller teams are allowed, in exceptional cases, but will not have better grades for this reason. \n",
    "\n",
    "The quality of the project will dictate its grade, not the number of people working.\n",
    "\n",
    "**The project's solution should be uploaded in Moodle before the end of December, 18th (last day before Christmas holidays).** \n",
    "\n",
    "Students should **upload a `.zip` file** containing all the files necessary for project evaluation. \n",
    "\n",
    "**It is mandatory to produce a Jupyter notebook containing code and text/images/tables/etc describing the solution and the results. The notebook is both the solution and the report.**\n",
    "\n",
    "**Decisions should be fundamented and results should be critically discussed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The team should use [Python 3](https://www.python.org) and [Jupyter Notebook](http://jupyter.org), together with **[Scikit-learn](http://scikit-learn.org/stable/)**, **[Orange3](https://orange.biolab.si)**, or **both**.\n",
    "\n",
    "**[Orange3](https://orange.biolab.si)** can be used through its **[programmatic version](https://docs.orange.biolab.si/3/data-mining-library/)**, by importing and using its packages, or throught its **workflow version**. \n",
    "\n",
    "**It is up to the team to decide when to use Scikit-learn, Orange, or both.**\n",
    "\n",
    "In this context, your Jupyter notebook might have a mix of code, results, text explanations, workflow figures, etc. \n",
    "\n",
    "In case you use Orange/workflows for some tasks you should also deliver the workflow files and explain the options taken in each widget in your notebook.\n",
    "\n",
    "**You can use this noteboook and the sections below as template for your work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset to be analysed is **`Donors_dataset.csv`**, made available together with this project description. This dataset, downloaded from [Kaggle](https://www.kaggle.com), contains selected data from the following dataset: [Donors-Prediction](https://www.kaggle.com/momohmustapha/donorsprediction/). \n",
    "\n",
    "\n",
    "**In this project, your team is supposed to use only tabular data (not Images or Image Metadata) and see how far you can go in predicting donations and understanding the donors. You should use both supervised and unsupervised learning to tackled 2 tasks:**\n",
    "\n",
    "1. **Task 1 (Supervised Learning) - Predicting Donation and Donation Type**\n",
    "2. **Task 2 (Unsupervised Learning) - Characterizing Donors**\n",
    "\n",
    "The **`Donors_dataset.csv`** you should learn from has **19.372 instances** described by **50 data fields** that you might use as **categorical/numerical features** \n",
    "\n",
    "### File Descriptions\n",
    "\n",
    "* **Donors_dataset.csv** - Tabular/text data to be used in the machine learning tasks.\n",
    "\n",
    "\n",
    "### Data Fields\n",
    "\n",
    "* **CARD_PROM_12** - number of card promotions sent to the individual by the charitable organization in the past 12 months\n",
    "* **CLUSTER_CODE** - one of 54 possible cluster codes, which are unique in terms of socioeconomic status, urbanicity, ethnicity, and other demographic characteristics\n",
    "* **CONTROL_NUMBER** - unique identifier of each individual\n",
    "* **DONOR_AGE** - age as of last year's mail solicitation\n",
    "* **DONOR_GENDER** - actual or inferred gender\n",
    "* **FILE_AVG_GIFT** - this variable is identical to LIFETIME_AVG_GIFT_AMT\n",
    "* **FILE_CARD_GIFT** - lifetime average donation (in \\\\$) from the individual in response to all card solicitations from the charitable organization\n",
    "* **FREQUENCY_STATUS_97NK** - based on the period of recency (determined by RECENCY_STATUS_96NK), which is the past 12 months for all groups except L and E. L and E are 13–24 months ago and 25–36 months ago, respectively: 1 if one donation in this period, 2 if two donations in this period, 3 if three donations in this period, and 4 if four or more donations in this period.\n",
    "* **HOME_OWNER** - H if the individual is a homeowner, U if this information is unknown\n",
    "* **INCOME_GROUP** - one of 7 possible income level groups based on a number of demographic characteristics\n",
    "* **IN_HOUSE** - 1 if the individual has ever donated to the charitable organization's In House program, 0 if not\n",
    "* **LAST_GIFT_AMT** - amount of the most recent donation from the individual to the charitable organization\n",
    "* **LIFETIME_AVG_GIFT_AMT** - lifetime average donation (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_CARD_PROM** - total number of card promotions sent to the individual by the charitable organization\n",
    "* **LIFETIME_GIFT_AMOUNT** - total lifetime donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_COUNT** - total number of donations from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_RANGE** - maximum donation amount from the individual minus minimum donation amount from the individual\n",
    "* **LIFETIME_MAX_GIFT_AMT** - maximum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_MIN_GIFT_AMT** - minimum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_PROM** - total number of promotions sent to the individual by the charitable organization\n",
    "* **MEDIAN_HOME_VALUE** - median home value (in 100\\\\$) as determined by other input variables\n",
    "* **MEDIAN_HOUSEHOLD_INCOME** - median household income (in 100\\\\$) as determined by other input variables\n",
    "* **MONTHS_SINCE_FIRST_GIFT** - number of months since the first donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_GIFT** - number of months since the most recent donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_PROM_RESP** - number of months since the individual has responded to a promotion by the charitable organization\n",
    "* **MONTHS_SINCE_ORIGIN** - number of months that the individual has been in the charitable organization's database\n",
    "* **MOR_HIT_RATE** - total number of known times the donor has responded to a mailed solicitation from a group other than the charitable organization\n",
    "* **NUMBER_PROM_12** - number of promotions (card or other) sent to the individual by the charitable organization in the past 12 months\n",
    "* **OVERLAY_SOURCE** - the data source against which the individual was matched: M if Metromail, P if Polk, B if both\n",
    "* **PCT_ATTRIBUTE1** - percent of residents in the neighborhood in which the individual lives that are males and active military\n",
    "* **PCT_ATTRIBUTE2** - percent of residents in the neighborhood in which the individual lives that are males and veterans\n",
    "* **PCT_ATTRIBUTE3** - percent of residents in the neighborhood in which the individual lives that are Vietnam veterans\n",
    "* **PCT_ATTRIBUTE4** - percent of residents in the neighborhood in which the individual lives that are WWII veterans\n",
    "* **PCT_OWNER_OCCUPIED** - percent of owner-occupied housing in the neighborhood in which the individual lives\n",
    "* **PEP_STAR** - 1 if individual has ever achieved STAR donor status, 0 if not\n",
    "* **PER_CAPITA_INCOME** - per capita income (in \\\\$) of the neighborhood in which the individual lives\n",
    "* **PUBLISHED_PHONE** - 1 if the individual's telephone number is published, 0 if not\n",
    "* **RECENCY_STATUS_96NK** - recency status as of two years ago: A if active donor, S if star donor, N if new donor, E if inactive donor, F if first time donor, L if lapsing donor\n",
    "* **RECENT_AVG_CARD_GIFT_AMT** - average donation from the individual in response to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_AVG_GIFT_AMT** - average donation (in \\\\$) from the individual to the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_COUNT** - number of times the individual has responded to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_PROP** - proportion of responses to the individual to the number of card solicitations from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_COUNT** - number of times the individual has responded to a promotion (card or other) from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_PROP** - proportion of responses to the individual to the number of (card or other) solicitations from the charitable organization since four years ago\n",
    "* **RECENT_STAR_STATUS** - 1 if individual has achieved star donor status since four years ago, 0 if not\n",
    "* **SES** - one of 5 possible socioeconomic codes classifying the neighborhood in which the individual lives\n",
    "* **TARGET_B** - 1 if individual donated in response to last year's 97NK mail solicitation from the charitable organization, 0 if individual did not\n",
    "* **TARGET_D** - amount of donation (in \\\\$) from the individual in response to last year's 97NK mail solicitation from the charitable organization\n",
    "* **URBANICITY** - classification of the neighborhood in which the individual lives: U if urban, C if city, S if suburban, T if town, R if rural, ? if missing\n",
    "* **WEALTH_RATING** - one of 10 possible wealth rating groups based on a number of demographic characteristics\n",
    "\n",
    "\n",
    "### Donation TYPE\n",
    "\n",
    "You are supposed to create a new column/feature named `DONATION_TYPE`, whose values describe ranges of the donation amount (DA) reported in feature `TARGET_D`:\n",
    "* `A` - DA >= 50\n",
    "* `B` - 20 <= DA < 50 \n",
    "* `C` - 13 <= DA < 20\n",
    "* `D` - 10 <= DA < 13\n",
    "* `E` - DA < 10\n",
    "\n",
    "\n",
    "### **Important Notes on Data Cleaning and Preprocessing**\n",
    "\n",
    "   1. Data can contain **errors/typos**, whose correction might improve the analysis.\n",
    "   2. Some features can contain **many values**, whose grouping in categories (aggregation into bins) might improve the analysis.\n",
    "   3. Data can contain **missing values**, that you might decide to fill. You might also decide to eliminate instances/features with high percentages of missing values.\n",
    "   4. **Not all features are necessarily important** for the analysis.\n",
    "   5. Depending on the analysis, **some features might have to be excluded**.\n",
    "   6. Class distribution is an important characteristic of the dataset that should be checked. **Class imbalance** might impair machine learning. \n",
    "  \n",
    "Some potentially useful links:\n",
    "\n",
    "* Data Cleaning and Preprocessing in Scikit-learn: https://scikit-learn.org/stable/modules/preprocessing.html#\n",
    "* Data Cleaning and Preprocessing in Orange: https://docs.biolab.si//3/visual-programming/widgets/data/preprocess.html\n",
    "* Dealing with imbalance datasets: https://pypi.org/project/imbalanced-learn/ and https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0 (Know your Data) - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"Donors_dataset.csv\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **understand better the features**, their distribution of values, potential errors, etc and plan/describe what data preprocessing steps should be performed next. Very important also is to check the distribution of values in the target (class distribution). \n",
    "\n",
    "Here you can find a notebook with some examples of what you can do in **Exploratory Data Analysis**: https://www.kaggle.com/artgor/exploration-of-data-step-by-step/notebook. You can also use Orange widgets for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will print and plot different tables and visualisations to get a feeling and better overview of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot the histograms to check if there are numerical features with a high number of values, that can possibly be binned to be more convenient for the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Plot for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.hist(bins=30, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort features in different categories for plotting:\n",
    "all_features = list(raw_data.columns[2:])\n",
    "pscontinuous_features = ['CONTROL_NUMBER', 'MONTHS_SINCE_ORIGIN', 'DONOR_AGE', 'PER_CAPITA_INCOME', \\\n",
    "                              'WEALTH_RATING', 'MEDIAN_HOME_VALUE', 'MEDIAN_HOUSEHOLD_INCOME', \\\n",
    "                             'PCT_OWNER_OCCUPIED', 'PCT_ATTRIBUTE2', 'PCT_ATTRIBUTE3', 'PCT_ATTRIBUTE4', \\\n",
    "                              'RECENT_RESPONSE_PROP', 'RECENT_AVG_GIFT_AMT', 'RECENT_CARD_RESPONSE_PROP', \\\n",
    "                              'RECENT_AVG_CARD_GIFT_AMT', 'RECENT_RESPONSE_COUNT', 'RECENT_CARD_RESPONSE_COUNT', \\\n",
    "                              'MONTHS_SINCE_LAST_PROM_RESP', 'LIFETIME_CARD_PROM', 'LIFETIME_PROM', \\\n",
    "                              'LIFETIME_GIFT_COUNT', 'LAST_GIFT_AMT', 'NUMBER_PROM_12', 'MONTHS_SINCE_LAST_GIFT', \\\n",
    "                              'MONTHS_SINCE_FIRST_GIFT', 'FILE_CARD_GIFT','CARD_PROM_12']\n",
    "categorical_features = ['IN_HOUSE', 'URBANICITY', 'SES', 'HOME_OWNER', 'DONOR_GENDER', 'INCOME_GROUP', \\\n",
    "                        'PUBLISHED_PHONE', 'OVERLAY_SOURCE', 'PEP_STAR', 'RECENCY_STATUS_96NK', \\\n",
    "                        'FREQUENCY_STATUS_97NK']\n",
    "other_features = ['CLUSTER_CODE', 'MOR_HIT_RATE', 'PCT_ATTRIBUTE1', 'RECENT_STAR_STATUS', 'LIFETIME_GIFT_AMOUNT', \\\n",
    "                  'LIFETIME_AVG_GIFT_AMT', 'LIFETIME_GIFT_RANGE', 'LIFETIME_MAX_GIFT_AMT', 'LIFETIME_MIN_GIFT_AMT', \\\n",
    "                  'FILE_AVG_GIFT']\n",
    "\n",
    "# check, if all are included and not couble counts:\n",
    "feature_lists = pscontinuous_features+categorical_features+other_features\n",
    "print('All features included and no doubles: ', \\\n",
    "      len(all_features)==len(feature_lists) and set(feature_lists)==set(all_features))\n",
    "\n",
    "def create_plots(features_to_plot, plottype='violin'):\n",
    "    '''Creates plots for given features. Plottypes: 'violin', 'count' . We can add more if necessary.\n",
    "    carful: if number of values per feature is high when 'count' is chosen, running time goes up. '''\n",
    "    print(f'{len(features_to_plot)} plots:')\n",
    "    ncols = 3\n",
    "    nrows = int(len(features_to_plot)/ncols)+1\n",
    "    newplots = plt.figure(figsize=(ncols*5,nrows*5))\n",
    "    for ind, feature in enumerate(features_to_plot):\n",
    "        plt.subplot(nrows, ncols, ind+1)\n",
    "        if plottype=='violin':\n",
    "            sns.violinplot(x=\"TARGET_B\", y=feature, data=raw_data, fontsize=8)\n",
    "            plt.title(f'TARGET_B by {feature}', fontsize=8)\n",
    "        if plottype!='violin':\n",
    "            sns.countplot(x='TARGET_B', data=raw_data, hue=feature);\n",
    "            plt.title(f'{feature} in TARGET_B', fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Violin Plots for numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(pscontinuous_features, 'violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countplots for categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(categorical_features, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = raw_data['TARGET_B'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('TARGET_B classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violin plots for other features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(other_features, 'violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Result of the exploratory analysis: the error for this feature is that one value is a typo ( = \"A\"). That row can be deleted. \n",
    "\n",
    "----\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw_data[raw_data.DONOR_GENDER == \"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.drop(14977, inplace = True )\n",
    "raw_data = raw_data.reset_index(drop=True)\n",
    "display(raw_data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = raw_data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 14))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Result of the exploratory analysis: Highly correlated features (red = positive, blue = negative correlated) can be reduntant because they dont produce no additional information and can be useless for the model. \n",
    "\n",
    "TODO: maybe deleted redundant data. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming donation amount in classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transformed_data.drop(columns = [\"CONTROL_NUMBER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_donation_type(row):\n",
    "    if row['TARGET_D'] >= 50:\n",
    "        return 'A'\n",
    "    if row['TARGET_D'] >= 20 and row['TARGET_D'] < 50:\n",
    "        return 'B'\n",
    "    if row['TARGET_D'] >= 13 and row['TARGET_D'] < 20:\n",
    "        return 'C'\n",
    "    if row['TARGET_D'] >= 10 and row['TARGET_D'] < 13:\n",
    "        return 'D'\n",
    "    if row['TARGET_D'] < 10:\n",
    "        return 'E'\n",
    "    return '?'\n",
    "\n",
    "transformed_data['DONATION_TYPE'] = transformed_data.apply (lambda row: label_donation_type(row), axis=1)\n",
    "transformed_data = transformed_data.drop(columns = ('TARGET_D'))\n",
    "\n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['WEALTH_RATING'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 (Supervised Learning) - Predicting Donation and Donation Type\n",
    "\n",
    "In this task you should target 3 classification tasks:\n",
    "1. **Predicting  Donation (binary classification task)**; \n",
    "2. **Predicting Donation TYPE (multiclass classification)**; and\n",
    "3. **Train specialized models for SES (socioeconomic classification)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should:**\n",
    "\n",
    "* Choose **one classifier in each category**: Tree models, Rule models, Linear models, Distance-based models, and Probabilistic models.\n",
    "* Use cross-validation to evaluate the results. \n",
    "* Present and discuss the results for different evaluation measures, present confusion matrices. Remember that not only overall results are important. Check what happens when learning to predict each class.\n",
    "* Describe the parameters used for each classifier and how their choice impacted or not the results.\n",
    "* Choose the best classifier and fundament you choice.\n",
    "* **Discuss critically your choices and the results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning numerical data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of Histogram Analysis: \n",
    "\n",
    "Attributes worth binning (because they have a high number of values): \n",
    "\n",
    "- DONOR_AGE\n",
    "- LIFETIME_CARD_FROM\n",
    "- LIFETIME_GIFT_COUNT\n",
    "- LIFETIME_PROM\n",
    "- MEDIAN_HOME_VALUE\n",
    "- MEDIAN HOUSEHOLD_INCOME\n",
    "- MONTHS_SINCE_LAST_GIFT\n",
    "- MONTHS_SINCE_FIRST_GIFT\n",
    "- PCT_ATTRIBUTE1\n",
    "- PCT_ATTRIBUTE2\n",
    "- PCT_ATTRIBUTE3\n",
    "- PCT_ATTRIBUTE4\n",
    "- PCT_OWNER_OCCUPIED\n",
    "- PER_CAPITA_INCOME\n",
    "- RECENT_RESPONSE_PROP\n",
    "- MONTHS_SINCE_LAST_PROM_RESP\n",
    "\n",
    "TODO: create bins \n",
    "\n",
    "- either quantile binning (our first approach)\n",
    "- or Log transform \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "features_for_binning =  [\"DONOR_AGE\", \"LIFETIME_CARD_PROM\", \"LIFETIME_GIFT_COUNT\", \"LIFETIME_PROM\", \"MEDIAN_HOME_VALUE\", \"MEDIAN_HOUSEHOLD_INCOME\", \"MONTHS_SINCE_FIRST_GIFT\", \"PCT_ATTRIBUTE2\", \"PCT_ATTRIBUTE3\", \"PCT_ATTRIBUTE4\", \"PCT_OWNER_OCCUPIED\", \"PER_CAPITA_INCOME\", \"RECENT_RESPONSE_PROP\"]\n",
    "quantile_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "quantile_labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for feature in features_for_binning:\n",
    "    quantiles = transformed_data[feature].quantile(quantile_list)\n",
    "\n",
    "    #binned_dataframe[f'{feature}_range'] = pd.qcut(binned_dataframe[feature],q=quantile_list)\n",
    "    transformed_data[f'{feature}_label'] = pd.qcut(transformed_data[feature],q=quantile_list,labels=quantile_labels, duplicates='drop')\n",
    "\n",
    "    \n",
    "transformed_data = transformed_data.drop(columns = features_for_binning)    \n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['DONATION_TYPE'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('DONATION_TYPE classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing Data (NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('WEALTH_RATING classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = transformed_data['DONOR_AGE_label'].value_counts().sort_index().plot(kind = 'barh')\n",
    "#plot.set_title('DONOR_AGE_label classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "The dataset contains NaN values in some columns. As the training of the models cant happen with NaN values there are two possibilities. Either drop the values which will lead to a very small dataset, or we try to replace NaN values with other values (with different techniques) in order to maintain a big dataset and dont loose information.\n",
    "\n",
    "Features with missing values, that need to be replaced are: \n",
    "\n",
    "- 'WEALTH_RATING': 8810\n",
    "- 'DONOR_AGE_label': 4795\n",
    "- 'INCOME_GROUP': 4392\n",
    "- 'MONTHS_SINCE_LAST_PROM_RESP': 246\n",
    "\n",
    "- 'URBANICITY'\n",
    "- 'SES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_encode(col_names, X):\n",
    "    '''Takes columns to encode (format: ['colum1', 'column2', ...]) and DataFrame X with all columns. \n",
    "    Encodes features and replaces old columns in X. Returns updated X'''\n",
    "    enc = OneHotEncoder()\n",
    "    matrix = X[col_names].to_numpy()\n",
    "    enc.fit(matrix)\n",
    "    matrix = enc.transform(matrix).toarray()\n",
    "    \n",
    "    categories_new = np.array(enc.categories_)\n",
    "    for ind1, cat in enumerate(categories_new):\n",
    "        for ind2, cat_new in enumerate(cat):\n",
    "            categories_new[ind1][ind2] = col_names[ind1]+':'+cat_new\n",
    "    features_new = categories_new.reshape(categories_new.size,1)\n",
    "\n",
    "    new_df = pd.DataFrame(matrix)\n",
    "    new_df.columns = np.concatenate(features_new.ravel()).tolist()\n",
    "\n",
    "    updated_df = pd.concat([X, new_df], axis=1)\n",
    "    updated_df = updated_df.drop(col_names, axis=1)\n",
    "    \n",
    "    return(updated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHot encoding of non nummeric categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_encode = ['WEALTH_RATING','DONOR_AGE_label','INCOME_GROUP', 'URBANICITY','SES' ]\n",
    "#ohe_encode(to_encode, transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encode and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install fancyimpute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from fancyimpute import KNN\n",
    "#instantiate both packages to use\n",
    "encoder = OrdinalEncoder()\n",
    "imputer = KNN()\n",
    "# create a list of categorical columns to iterate over\n",
    "to_encode = ['WEALTH_RATING','DONOR_AGE_label','INCOME_GROUP', 'URBANICITY','SES' ]\n",
    "\n",
    "def encode(data):\n",
    "    '''function to encode non-null data and replace it in the original data'''\n",
    "    #retains only non-null values\n",
    "    nonulls = np.array(data.dropna())\n",
    "    #reshapes the data for encoding\n",
    "    impute_reshape = nonulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Assign back encoded values to non-null values\n",
    "    tdata = data.copy()\n",
    "    tdata.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "    return tdata\n",
    "\n",
    "#create a for loop to iterate through each column in the data\n",
    "for columns in to_encode:\n",
    "    encode(transformed_data[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: \n",
    "#Urbancity\n",
    "#SES\n",
    "\n",
    "\n",
    "\n",
    "#possibilities:\n",
    "#1. any number, like 999 or 0\n",
    "#2. mean/median\n",
    "#3. KNN\n",
    "\n",
    "# how to replace WEALTH_RATING ? \n",
    "# its from 0 to 9 , so missing data could be = 10 \n",
    "# as it now is binned data = label = we create the label 999\n",
    "# or replace with a number or with mean ? \n",
    "# TODO: try out different values \n",
    "\n",
    "#transformed_data.WEALTH_RATING =  transformed_data.WEALTH_RATING.fillna(999)\n",
    "#2. \n",
    "#imputer = KNNImputer(n_neighbors=2)\n",
    "#transformed_data.WEALTH_RATING =  imputer.fit_transform(transformed_data.WEALTH_RATING)\n",
    "\n",
    "\n",
    "# how to replace DONOR_AGE ? \n",
    "# replace with a number or with mean ? \n",
    "# as it now is binned data = label = we create the label 999\n",
    "# first we try mean\n",
    "# TODO: try out different values : median ? \n",
    "\n",
    "#transformed_data.DONOR_AGE =  transformed_data.DONOR_AGE.fillna((transformed_data.DONOR_AGE.mean()))\n",
    "#transformed_data.DONOR_AGE_label = transformed_data.DONOR_AGE_label.cat.add_categories(999)\n",
    "#transformed_data.DONOR_AGE_label =  transformed_data.DONOR_AGE_label.fillna(999)\n",
    "\n",
    "\n",
    "# how to replace INCOME_GROUP ? \n",
    "# its from 1 to 7 , so missing data could be = 8\n",
    "# as it now is binned data = label = we create the label 999\n",
    "\n",
    "# or replace with a number or with mean ? \n",
    "# TODO: try out different values \n",
    "# first tried with 0 \n",
    "# replace with 8\n",
    "#transformed_data.INCOME_GROUP =  transformed_data.INCOME_GROUP.fillna(999)\n",
    "\n",
    "\n",
    "# how to replace MONTHS_SINCE_LAST_PROM_RESP ? \n",
    "# its from normally : 0 to 36. \n",
    "# negative values make no sense here, a person cant respond in a negative amount of time. \n",
    "# we can replace with the maximum value (36)or replace with a number or with mean. \n",
    "# first we try the mean()\n",
    "# TODO: try out different values :  median ? \n",
    "\n",
    "#transformed_data.MONTHS_SINCE_LAST_PROM_RESP =  transformed_data.MONTHS_SINCE_LAST_PROM_RESP.fillna(transformed_data.MONTHS_SINCE_LAST_PROM_RESP.mean())\n",
    "#transformed_data.MONTHS_SINCE_LAST_PROM_RESP =  transformed_data.MONTHS_SINCE_LAST_PROM_RESP.fillna(999)\n",
    "\n",
    "\n",
    "\n",
    "#X = [transformed_data['MONTHS_SINCE_LAST_PROM_RESP']]\n",
    "#print(transformed_data.pscontinuous_features)\n",
    "#for feature in pscontinuous_features:\n",
    "#   X.append(transformed_data[feature])\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "df_numeric = transformed_data.select_dtypes(include=[np.float]).values\n",
    "#no_nan = imputer.fit_transform(df_numeric)\n",
    "\n",
    "df_filled = pd.DataFrame(imputer.fit_transform(df_numeric))\n",
    "\n",
    "transformed_data.isna().sum()\n",
    "display(transformed_data.select_dtypes(include=[np.float])[30:50])\n",
    "\n",
    "\n",
    "display(df_filled[30:50])\n",
    "len(no_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df_filled[30:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('WEALTH_RATING classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = transformed_data['DONOR_AGE_label'].value_counts().sort_index().plot(kind = 'barh')\n",
    "#plot.set_title('DONOR_AGE_label classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['INCOME_GROUP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('INCOME_GROUP classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['MONTHS_SINCE_LAST_PROM_RESP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('MONTHS_SINCE_LAST_PROM_RESP classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['INCOME_GROUP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('URBANICITY classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['SES'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('SES classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace false values (outliers) with mean of column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO : How did we recognize the outliers ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.MOR_HIT_RATE.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Result: MOR_HIT_RATE : time of answers on other mailings. Seem to high in some cases, will be replaced by column mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Result: MONTHS_SINCE_LAST_PROM_RESP : months since last answer. This value cant be negative and will be replaced by column mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOR_HIT_RATE : time of answers on other mailings. seems to high, will be replaced by column mean. \n",
    "transformed_data.MOR_HIT_RATE = transformed_data.MOR_HIT_RATE.apply(lambda x: (transformed_data.MOR_HIT_RATE.mode()[0]) if x > 100 else x)\n",
    "\n",
    "# MONTHS_SINCE_LAST_PROM_RESP : months since last answer cant be negative,will be replaced by column mean. \n",
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP = transformed_data.MONTHS_SINCE_LAST_PROM_RESP.apply(lambda x: (transformed_data.MONTHS_SINCE_LAST_PROM_RESP.mode()[0]) if x < 0.0 else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show Columns that are of the type \"object\" and need to be transformed to numerical values\n",
    "\n",
    "obj_df = transformed_data.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "\n",
    "\n",
    "transformed_data[\"URBANICITY\"] = lb_make.fit_transform(transformed_data[\"URBANICITY\"])\n",
    "transformed_data[\"SES\"] = lb_make.fit_transform(transformed_data[\"SES\"])\n",
    "transformed_data[\"CLUSTER_CODE\"] = lb_make.fit_transform(transformed_data[\"CLUSTER_CODE\"])\n",
    "transformed_data[\"HOME_OWNER\"] = lb_make.fit_transform(transformed_data[\"HOME_OWNER\"])\n",
    "transformed_data[\"DONOR_GENDER\"] = lb_make.fit_transform(transformed_data[\"DONOR_GENDER\"])\n",
    "transformed_data[\"OVERLAY_SOURCE\"] = lb_make.fit_transform(transformed_data[\"OVERLAY_SOURCE\"])\n",
    "transformed_data[\"RECENCY_STATUS_96NK\"] = lb_make.fit_transform(transformed_data[\"RECENCY_STATUS_96NK\"])\n",
    "transformed_data[\"DONATION_TYPE\"] = lb_make.fit_transform(transformed_data[\"DONATION_TYPE\"])\n",
    "#transformed_data[\"DONOR_AGE_label\"] = lb_make.fit_transform(transformed_data[\"DONOR_AGE_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['URBANICITY'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('URBANICITY classes counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data Cleaning\n",
    "\n",
    "1. **add rule based model**\n",
    "2. **oneHot Encoding Feature for all categorical features ? (?)**\n",
    "\n",
    "\n",
    "model training : \n",
    "\n",
    "3. **redo multiclass classification with onehot encoded data**\n",
    "\n",
    "5. **Importance analysis of features = package ?**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- todo: (optional)\n",
    "    * Outlier Detection with Standard Deviation\n",
    "    * https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "- todo: feature engineering:  (parallel zum model training)\n",
    "    * You might also decide to eliminate instances/features with high percentages of missing values. \n",
    "    * Not all features are necessarily important for the analysis.\n",
    "    * Depending on the analysis, some features might have to be excluded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n",
    "raw_data.MOR_HIT_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.loc[transformed_data['URBANICITY'] == 0,'URBANICITY'] = np.nan\n",
    "transformed_data.loc[transformed_data['SES'] == 0,'SES'] = np.nan\n",
    "transformed_data.loc[transformed_data['CLUSTER_CODE'] == 0,'CLUSTER_CODE'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = ['URBANICITY', 'SES', 'CLUSTER_CODE', 'INCOME_GROUP', 'WEALTH_RATING']\n",
    "impute_mean = ['MONTHS_SINCE_LAST_PROM_RESP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in impute_mode:\n",
    "    print(transformed_data[feature].mode()[0])\n",
    "    transformed_data[feature].fillna(transformed_data[feature].mode()[0], inplace=True)\n",
    "\n",
    "for feature in impute_mean:\n",
    "    print(transformed_data[feature].mean())\n",
    "    transformed_data[feature].fillna(transformed_data[feature].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "transformed_data = pd.DataFrame(imputer.fit_transform(transformed_data), columns=transformed_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.isna().sum()\n",
    "display(transformed_data['URBANICITY'])\n",
    "\n",
    "# if KNN\n",
    "#display(df_filled[30:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = df_filled['URBANICITY'].value_counts().sort_index().plot(kind = 'barh')\n",
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['MOR_HIT_RATE'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_binning =  [\"DONOR_AGE\", \"LIFETIME_CARD_PROM\", \"LIFETIME_GIFT_COUNT\", \"LIFETIME_PROM\", \"MONTHS_SINCE_ORIGIN\", \"MEDIAN_HOME_VALUE\", \"MEDIAN_HOUSEHOLD_INCOME\", \"MONTHS_SINCE_FIRST_GIFT\", \"PCT_ATTRIBUTE2\", \"PCT_ATTRIBUTE3\", \"PCT_ATTRIBUTE4\", \"PCT_OWNER_OCCUPIED\", \"PER_CAPITA_INCOME\", \"RECENT_RESPONSE_PROP\"]\n",
    "quantile_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "quantile_labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for feature in features_for_binning:\n",
    "    print(feature)\n",
    "    if feature==\"MONTHS_SINCE_ORIGIN\": # less bins for this features because of high number of zeros\n",
    "        quantile_list = np.linspace(0, 1.0, 7)\n",
    "        quantile_labels = np.arange(0,len(quantile_list)-1)\n",
    "        \n",
    "    quantiles = transformed_data[feature].quantile(quantile_list)\n",
    "\n",
    "    #binned_dataframe[f'{feature}_range'] = pd.qcut(binned_dataframe[feature],q=quantile_list)\n",
    "    transformed_data[f'{feature}_label'] = pd.qcut(transformed_data[feature],q=quantile_list,labels=quantile_labels, duplicates='drop')\n",
    "\n",
    "    \n",
    "transformed_data = transformed_data.drop(columns = features_for_binning)    \n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transformed_data.select_dtypes(include=['float64'])\n",
    "#tf.drop(columns=['RECENT_CARD_RESPONSE_PROP','RECENT_AVG_GIFT_AMT', 'RECENT_AVG_CARD_GIFT_AMT', \n",
    "#                 'LIFETIME_AVG_GIFT_AMT', 'LIFETIME_GIFT_RANGE', 'LIFETIME_MAX_GIFT_AMT', 'LIFETIME_MIN_GIFT_AMT', 'FILE_AVG_GIFT'])\n",
    "transformed_data[tf.columns] = transformed_data[tf.columns].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from fancyimpute import KNN\n",
    "#instantiate both packages to use\n",
    "encoder = OrdinalEncoder()\n",
    "imputer = KNN()\n",
    "# create a list of categorical columns to iterate over\n",
    "to_encode = ['WEALTH_RATING','DONOR_AGE_label','INCOME_GROUP', 'URBANICITY','SES' ]\n",
    "\n",
    "\n",
    "def encode(data):\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "    '''function to encode non-null data and replace it in the original data'''\n",
    "    #retains only non-null values\n",
    "    nonulls = np.array(data.dropna())\n",
    "    #reshapes the data for encoding\n",
    "    impute_reshape = nonulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Assign back encoded values to non-null values\n",
    "    tdata = data.copy()\n",
    "    tdata.is_copy = None\n",
    "    tdata.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "  \n",
    "    return tdata\n",
    "\n",
    "#create a for loop to iterate through each column in the data\n",
    "for columns in to_encode:\n",
    "    encode(transformed_data[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('URBANICITY classes counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the Data: Resampling the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = transformed_data.copy()\n",
    "count_class_0, count_class_1 = resampled_data['TARGET_B'].value_counts()\n",
    "print(count_class_0,count_class_1)\n",
    "\n",
    "#Divide\n",
    "td_class_0 = resampled_data[resampled_data['TARGET_B'] == 0]\n",
    "td_class_1 = resampled_data[resampled_data['TARGET_B'] == 1]\n",
    "\n",
    "td_class_0_under = td_class_0.sample(count_class_1)\n",
    "td_under = pd.concat([td_class_0_under, td_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(td_under['TARGET_B'].value_counts())\n",
    "\n",
    "td_under['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_class_1_over = td_class_1.sample(count_class_0, replace=True)\n",
    "td_over = pd.concat([td_class_0, td_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(td_over['TARGET_B'].value_counts())\n",
    "\n",
    "td_over['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imbalanced learn module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip3 install imblearn\n",
    "import imblearn\n",
    "\n",
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    colors = ['#1F77B4', '#FF7F0E']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            X[y==l, 1],\n",
    "            c=c, label=l, marker=m\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_rus, y_rus, id_rus = rus.fit_sample(resampled_data.['TARGET_B'])\n",
    "\n",
    "print('Removed indexes:', id_rus)\n",
    "\n",
    "plot_2d_space(X_rus, y_rus, 'Random under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling the training set pushed the accurency to 0.51\n",
    "Conclusion: no resampling of the trainingset\n",
    "\n",
    "Code: <br>\n",
    "count_class_0, count_class_1 = train_dataset['TARGET_B'].value_counts()\n",
    "print(count_class_0,count_class_1)\n",
    "\n",
    "#Divide\n",
    "td_class_0 = train_dataset[train_dataset['TARGET_B'] == 0]\n",
    "td_class_1 = train_dataset[train_dataset['TARGET_B'] == 1]\n",
    "\n",
    "td_class_0_under = td_class_0.sample(count_class_1)\n",
    "td_under = pd.concat([td_class_0_under, td_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(td_under['TARGET_B'].value_counts())\n",
    "\n",
    "td_under['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');\n",
    "\n",
    "train_dataset = td_under\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Class imbalance for DONATE_TYPE\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test data (Splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for normal classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train and evaluate the models we need to split them into training- and testsets. \n",
    "As a basis for the split we can use three of base-datasets we created before:\n",
    "\n",
    "- transformed_data (cleaned dataset but no balancing of classes = imbalanced class (donates / not donating))\n",
    "- td_under (cleaned dataset with balancing of the class (donates / not donating) with random under sampling)\n",
    "- td_over (cleaned dataset with balancing of the class (donates / not donating) with random over sampling)\n",
    "\n",
    "To use the datasets copy one of the following datasets in the following cell: \n",
    "\n",
    "- transformed_data \n",
    "- td_under\n",
    "- td_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_data = transformed_data.copy()\n",
    "#transformed_data = td_under.copy()\n",
    "transformed_data = td_over.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For splitting the data we drop the two target columns [\"TARGET_B\", \"DONATION_TYPE\"] out of the training(X) and testdataset (X) and assign them to the target-feature (y) also for training and test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = transformed_data.sample(frac=0.8,random_state=87)\n",
    "test_dataset = transformed_data.drop(train_dataset.index)\n",
    "\n",
    "X_train = train_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "X_test = test_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "\n",
    "y_train_target_b = train_dataset.pop(\"TARGET_B\")\n",
    "y_test_target_b = test_dataset.pop('TARGET_B')\n",
    "\n",
    "y_train_donation_type = train_dataset.pop(\"DONATION_TYPE\")\n",
    "y_test_donation_type = test_dataset.pop('DONATION_TYPE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for classification task for the specific SES classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we want to train and evaluate models for the specific socioeconomic classes. \n",
    "In order to create different datasets for each class we split them in the following and create respective training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SES_1 = transformed_data[transformed_data.SES == 0]\n",
    "SES_2 = transformed_data[transformed_data.SES == 1]\n",
    "SES_3 = transformed_data[transformed_data.SES == 2]\n",
    "SES_4 = transformed_data[transformed_data.SES == 3]\n",
    "SES_nan = transformed_data[transformed_data.SES == 4]\n",
    "\n",
    "def split_sets(df):\n",
    "\n",
    "    train_dataset = df.sample(frac=0.8,random_state=0)\n",
    "    test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "    X_train = train_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "    X_test = test_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "\n",
    "    y_train_target_b = train_dataset.pop(\"TARGET_B\")\n",
    "    y_test_target_b = test_dataset.pop('TARGET_B')\n",
    "\n",
    "    #y_train_donation_type = train_dataset[\"DONATION_TYPE\"].values\n",
    "    #y_test_donation_type = test_dataset[\"DONATION_TYPE\"].values\n",
    "\n",
    "    y_train_donation_type = train_dataset.pop(\"DONATION_TYPE\")\n",
    "    y_test_donation_type = test_dataset.pop('DONATION_TYPE')\n",
    "    \n",
    "    return X_train, X_test, y_train_target_b, y_test_target_b, y_train_donation_type, y_test_donation_type\n",
    "\n",
    "\n",
    "X_train_SES_1, X_test_SES_1, y_train_target_b_SES_1, y_test_target_b_SES_1, y_train_donation_type_SES_1, y_test_donation_type_SES_1 = split_sets(SES_1)\n",
    "X_train_SES_2, X_test_SES_2, y_train_target_b_SES_2, y_test_target_b_SES_2, y_train_donation_type_SES_2, y_test_donation_type_SES_2 = split_sets(SES_2)\n",
    "X_train_SES_3, X_test_SES_3, y_train_target_b_SES_3, y_test_target_b_SES_3, y_train_donation_type_SES_3, y_test_donation_type_SES_3 = split_sets(SES_3)\n",
    "X_train_SES_4, X_test_SES_4, y_train_target_b_SES_4, y_test_target_b_SES_4, y_train_donation_type_SES_4, y_test_donation_type_SES_4 = split_sets(SES_4)\n",
    "X_train_SES_nan, X_test_SES_nan, y_train_target_b_SES_nan, y_test_target_b_SES_nan, y_train_donation_type_SES_nan, y_test_donation_type_SES_nan = split_sets(SES_4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation of the Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will introduce five classifiers in order to train Models for the three given classificaiton tasks. \n",
    "\n",
    "- Predicting Donation (binary classification task);\n",
    "- Predicting Donation TYPE (multiclass classification); and\n",
    "- Train specialized models for SES (socioeconomic classification).\n",
    "\n",
    "We choose the following classifiers for each category: \n",
    "\n",
    "- Tree models: RandomForestClassifier\n",
    "- Distance-based models: KNeighborsClassifier\n",
    "- Linear models: Support Vector Machine\n",
    "- Probabilistic models: Gaussian Naive Bayes\n",
    "- Rule models: todo\n",
    "\n",
    "For Evalutation we use a 5-fold cross validation to evaluate the results.\n",
    "\n",
    "TODO: \n",
    "\n",
    "1. describe different measures \n",
    "2. explain results\n",
    "3. check not only overall accuracy but also precision and recall for each class !!\n",
    "4. Describe the parameters used for each classifier and how their choice impacted or not the results.\n",
    "5. Choose the best classifier and fundament you choice.\n",
    "6. Discuss critically your choices and the results!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "The **Metrics** we are evaluating: \n",
    "\n",
    "Precision: What proportion of positive identifications was actually correct?\n",
    "\n",
    "Recall: What proportion of actual positives was identified correctly?\n",
    "\n",
    "f1-score: The harmonic mean of precision and recall.\n",
    "\n",
    "Accuracy: The fraction of all predictions the model got right. \n",
    "\n",
    "To fully evaluate the effectiveness of a model, we must examine both precision and recall. Unfortunately, precision and recall are often in tension. That is, improving precision typically reduces recall and vice versa. So the f1-score as the harmonic mean of precision and recall is a good metric to look at. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_names, models ) -> pd.DataFrame:\n",
    "    '''\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = [\"precision\" , \"recall\" , \"f1\", 'accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
    "    target_names = target_names\n",
    "    \n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        #print(y_pred)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names, zero_division = 0))\n",
    "        # Generate confusion matrix\n",
    "        #matrix = plot_confusion_matrix(model, X_test, y_test)#, normalize='true')\n",
    "        #matrix.plot()\n",
    "        #plt.rcParams[\"axes.grid\"] = False\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametertuning for all binary classification models  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The untuned models will perform very poorly. Based on the different datasets we use for training we need to choose the right hyperparameters of the models. \n",
    "\n",
    "In the following each of the tunable models (Gaussian NB is not tunable) will be trained with different hyperparameters in order to find the best combination of parameters to increase the metrics we specified. \n",
    "\n",
    "We specified to score on recall (the proportion of the actual values the model predicted right), precision (the proportion of the predicted values that truly are that class) and on overall model accuracy. \n",
    "\n",
    "After evaluating the best parameters for each model we can use the models with the best parameters to create a model comparision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 7 min \n",
    "\n",
    "rand_forest = RandomForestClassifier(n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_target_b)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': [40, 50, 60],\n",
    "          'max_features': ['auto'],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'n_estimators': [400, 600, 800]}\n",
    "\n",
    "#scoring = ['recall' , 'precision', 'accuracy']\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    rand_forest,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=5,\n",
    "    n_jobs= -1, \n",
    "    scoring=\"f1\" \n",
    "    #refit='recall'\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_target_b)\n",
    "\n",
    "print(\"Best params for Rand Forest : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for Rand Forest : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for Rand Forest : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Hyperparametertuning showed we use the following parameters: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(bootstrap=False, max_depth=60, n_estimators=800,n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_target_b)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train, y_train_target_b)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n",
    "\n",
    "params = {'n_neighbors':[50,60,70],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    knn,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1, \n",
    "    scoring=\"f1\"\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_target_b)\n",
    "\n",
    "print(\"Best params for knn : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for knn : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for knn : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Hyperparametertuning showed we use the following parameters: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=70)\n",
    "knn = knn.fit(X_train, y_train_target_b)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_target_b) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "print(classification_report(y_test_target_b, svm_predictions))\n",
    "\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train_target_b)\n",
    "\n",
    "\n",
    "print(\"Best params for SVM : \" +  str(grid.best_params_))\n",
    "\n",
    "print(\"Best estimator for SVM : \" + str(grid.best_estimator_))\n",
    "\n",
    "print(\"Best score for SVM : \" + str(grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Hyperparametertuning showed we use the following parameters: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc = SVC(C=0.1, gamma=0.01)\n",
    "svc = svc.fit(X_train, y_train_target_b)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature significance based on the Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rand_forest.feature_importances_\n",
    "std = np.std([rand_forest.feature_importances_ for tree in rand_forest.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d : %s (%f)\" % (f + 1, indices[f] ,X_train.columns[indices[f]] ,importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure( figsize=(20,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: As the analysis showed, there are features that are more and less relevant for the model. \n",
    "As a next step for speeding up model training we could drop the less relevant features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparametertuning for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 7 min \n",
    "\n",
    "rand_forest = RandomForestClassifier(n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_donation_type)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': [10, 20, 30],\n",
    "          'max_features': ['auto'],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'n_estimators': [200, 400, 600]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    rand_forest,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_donation_type)\n",
    "\n",
    "print(\"Best params for Rand Forest : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for Rand Forest : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for Rand Forest : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_donation_type)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "knn = knn.fit(X_train, y_train_donation_type)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n",
    "\n",
    "params = {'n_neighbors':[50,60,70],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    knn,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_donation_type)\n",
    "\n",
    "print(\"Best params for knn : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for knn : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for knn : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=5, n_jobs=-1, n_neighbors=60)\n",
    "knn = knn.fit(X_train, y_train_donation_type)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_donation_type) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "print(classification_report(y_test_donation_type, svm_predictions))\n",
    "\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train_donation_type)\n",
    "\n",
    "\n",
    "print(\"Best params for SVM : \" +  str(grid.best_params_))\n",
    "\n",
    "print(\"Best estimator for SVM : \" + str(grid.best_estimator_))\n",
    "\n",
    "print(\"Best score for SVM : \" + str(grid.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc = SVC()\n",
    "svc = svc.fit(X_train, y_train_target_b)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Classifiers: \n",
    "\n",
    "## Binary Classification \n",
    "\n",
    "### Without Sampling\n",
    "- RF : RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=400,n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=60)\n",
    "- SVM : \n",
    "\n",
    "### Oversampling \n",
    "- RF : RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=70)\n",
    "- SVM : SVC(C=0.1, gamma=0.01)\n",
    "\n",
    "### Undersampling \n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n",
    "\n",
    "\n",
    "## Multiclass Classification \n",
    "\n",
    "### Without Sampling\n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n",
    "### Oversampling \n",
    "- RF : RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=5, n_jobs=-1, n_neighbors=60)\n",
    "- SVM : \n",
    "### Undersampling \n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models for binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(\n",
    "    X_train, \n",
    "    y_train_target_b, \n",
    "    X_test, \n",
    "    y_test_target_b, \n",
    "    ['wont donate', 'donates'],\n",
    "    [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1)),\n",
    "     ('Distance Based Model: KNN', KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=70)),\n",
    "     ('Probabilistic Model: GNB', GaussianNB()),\n",
    "     ('Linear Model: SVM', SVC(C=0.1, gamma=0.01))\n",
    "        # Rule Based model: \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.set(font_scale=1)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluating the best parameters for each model we can use the models with the best parameters to create a model comparision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(\n",
    "    X_train, \n",
    "    y_train_donation_type, \n",
    "    X_test, \n",
    "    y_test_donation_type, \n",
    "    ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "    [\n",
    "        ('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1)),\n",
    "        ('Distance Based Model: KNN', KNeighborsClassifier(leaf_size=5, n_jobs=-1, n_neighbors=60)),\n",
    "        ('Probabilistic Model: GNB', GaussianNB()),\n",
    "        ('Linear Model: SVM', SVC())\n",
    "        # Rule Based model: \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.set(font_scale=1)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classifier for SES - classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models for each SES class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "TODO: we just have to train the best classifier (ONE !!!) from the previous experiments to predict donation and donation type for each SES class = 2 models for 5 SES = experiments \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(X_train_SES_1, \n",
    "                 y_train_target_b_SES_1, \n",
    "                 X_test_SES_1 , \n",
    "                 y_test_target_b_SES_1, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_2, \n",
    "                 y_train_target_b_SES_2, \n",
    "                 X_test_SES_2, \n",
    "                 y_test_target_b_SES_2, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_3, \n",
    "                 y_train_target_b_SES_3, \n",
    "                 X_test_SES_3 , \n",
    "                 y_test_target_b_SES_3, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_4, \n",
    "                 y_train_target_b_SES_4, \n",
    "                 X_test_SES_4 , \n",
    "                 y_test_target_b_SES_4, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_nan, \n",
    "                 y_train_target_b_SES_nan, \n",
    "                 X_test_SES_nan, \n",
    "                 y_test_target_b_SES_nan, \n",
    "                 ['wont donate', 'donates'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=600,n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass classifier for SES - classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(X_train_SES_1, \n",
    "                 y_train_target_b_SES_1, \n",
    "                 X_test_SES_1 , \n",
    "                 y_test_target_b_SES_1, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_2, \n",
    "                 y_train_target_b_SES_2, \n",
    "                 X_test_SES_2, \n",
    "                 y_test_target_b_SES_2, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_3, \n",
    "                 y_train_target_b_SES_3, \n",
    "                 X_test_SES_3 , \n",
    "                 y_test_target_b_SES_3, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_4, \n",
    "                 y_train_target_b_SES_4, \n",
    "                 X_test_SES_4 , \n",
    "                 y_test_target_b_SES_4, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])\n",
    "\n",
    "final = run_exps(X_train_SES_nan, \n",
    "                 y_train_target_b_SES_nan, \n",
    "                 X_test_SES_nan, \n",
    "                 y_test_target_b_SES_nan, \n",
    "                 ['wont donate', 'A', 'B', 'C', 'D', 'E'],\n",
    "                 [('Tree based Model: RF', RandomForestClassifier(bootstrap=False, max_depth=30, n_estimators=600,\n",
    "                       n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: \n",
    "\n",
    "# todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logical Models: Rule models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after complete processing, all columns should be used\n",
    "interesting_features = ['TARGET_B', 'HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE'] \n",
    "\n",
    "# data used for Rule Mining:\n",
    "RM_transformed_data = transformed_data[interesting_features]\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources:\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html  -   6.3.4. Encoding categorical features\n",
    "# TP05: 2.2\n",
    "\n",
    "# def ohe_encode moved to 3.1\n",
    "\n",
    "cols_not_binary = ['HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE']\n",
    "RM_binary_data = ohe_encode(cols_not_binary)\n",
    "RM_binary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Binning for all interesting features (first preprocessing section)\n",
    "- put the OneHotEncoding in first preprocessing section?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ????? Finding Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate frequent patterns:\n",
    "freq_patterns = apriori(RM_binary_data, min_support=0.05, use_colnames=True) # maybe choose different min_support..\n",
    "#freq_patterns['size'] = freq_patterns['itemsets'].apply(lambda x: len(x))\n",
    "#freq_patterns = freq_patterns[freq_patterns['size']>1]\n",
    "#freq_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# careful here, if we change '?' again maybe...\n",
    "def check_if_interesting(x):\n",
    "    # Interesting (maybe different criteria..):\n",
    "    # - consequents==(TARGET_B or DONATION_TYPE)\n",
    "    # - TARGET_B, B, D, E not in antecedents\n",
    "    targets = ['TARGET_B', 'DONATION_TYPE:A', 'DONATION_TYPE:B', 'DONATION_TYPE:C', \n",
    "               'DONATION_TYPE:D', 'DONATION_TYPE:E', 'DONATION_TYPE:?']\n",
    "    target_is_only_consequents = any(item in targets for item in x[1]) and len(x[1])==1\n",
    "    target_not_in_ancedents = not any(item in targets for item in x[0])\n",
    "    return target_is_only_consequents and target_not_in_ancedents\n",
    "\n",
    "# generate assiciation rules:\n",
    "as_rules = association_rules(freq_patterns, metric=\"confidence\", min_threshold=0.2)\n",
    "# filter out uninteresting rules:\n",
    "as_rules['interesting?'] = as_rules[['antecedents', 'consequents']].apply(check_if_interesting, axis=1)\n",
    "as_rules = as_rules[ as_rules['interesting?']==True]\n",
    "as_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the f1-Score....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 (Unsupervised Learning) - Characterizing Donors and Donation Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **use unsupervised learning algorithms and try to characterize donors (people who really did a donation) and their donation type**. You can use:\n",
    "* **Association rule mining** to find **associations between the features and the target Donation/DonationTYPE**.\n",
    "* **Clustering algorithms to find similar groups of donors**. Is it possible to find groups of donors with the same/similar DonationTYPE?\n",
    "* **Be creative and define your own unsupervised analysis!** What would it be interesting to find out ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Association Rule Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after complete processing, all columns should be used\n",
    "interesting_features = ['TARGET_B', 'HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE'] \n",
    "\n",
    "# data used for Rule Mining:\n",
    "RM_transformed_data = transformed_data[interesting_features]\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources:\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html  -   6.3.4. Encoding categorical features\n",
    "# TP05: 2.2\n",
    "\n",
    "def ohe_encode(col_names, X=RM_transformed_data):\n",
    "    '''Takes columns to encode (format: ['colum1', 'column2', ...]) and DataFrame X with all columns. \n",
    "    Encodes features and replaces old columns in X. Returns updated X'''\n",
    "    enc = OneHotEncoder()\n",
    "    matrix = X[col_names].to_numpy()\n",
    "    enc.fit(matrix)\n",
    "    matrix = enc.transform(matrix).toarray()\n",
    "    \n",
    "    categories_new = np.array(enc.categories_)\n",
    "    for ind1, cat in enumerate(categories_new):\n",
    "        for ind2, cat_new in enumerate(cat):\n",
    "            categories_new[ind1][ind2] = col_names[ind1]+':'+cat_new\n",
    "    features_new = categories_new.reshape(categories_new.size,1)\n",
    "\n",
    "    new_df = pd.DataFrame(matrix)\n",
    "    new_df.columns = np.concatenate(features_new.ravel()).tolist()\n",
    "\n",
    "    updated_df = pd.concat([X, new_df], axis=1)\n",
    "    updated_df = updated_df.drop(col_names, axis=1)\n",
    "    \n",
    "    return(updated_df)\n",
    "\n",
    "cols_not_binary = ['HOME_OWNER', 'DONOR_GENDER', 'DONATION_TYPE']\n",
    "RM_binary_data = ohe_encode(cols_not_binary)\n",
    "RM_binary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "- Binning for all interesting features (first preprocessing section)\n",
    "- put the OneHotEncoding in first preprocessing section?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate frequent patterns:\n",
    "freq_patterns = apriori(RM_binary_data, min_support=0.05, use_colnames=True) # maybe choose different min_support..\n",
    "#freq_patterns['size'] = freq_patterns['itemsets'].apply(lambda x: len(x))\n",
    "#freq_patterns = freq_patterns[freq_patterns['size']>1]\n",
    "#freq_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# careful here, if we change '?' again maybe...\n",
    "def check_if_interesting(x):\n",
    "    # Interesting (maybe different criteria..):\n",
    "    # - consequents==(TARGET_B or DONATION_TYPE)\n",
    "    # - TARGET_B, B, D, E not in antecedents\n",
    "    targets = ['TARGET_B', 'DONATION_TYPE:A', 'DONATION_TYPE:B', 'DONATION_TYPE:C', \n",
    "               'DONATION_TYPE:D', 'DONATION_TYPE:E', 'DONATION_TYPE:?']\n",
    "    target_is_only_consequents = any(item in targets for item in x[1]) and len(x[1])==1\n",
    "    target_not_in_ancedents = not any(item in targets for item in x[0])\n",
    "    return target_is_only_consequents and target_not_in_ancedents\n",
    "\n",
    "# generate assiciation rules:\n",
    "as_rules = association_rules(freq_patterns, metric=\"confidence\", min_threshold=0.2)\n",
    "# filter out uninteresting rules:\n",
    "as_rules['interesting?'] = as_rules[['antecedents', 'consequents']].apply(check_if_interesting, axis=1)\n",
    "as_rules = as_rules[ as_rules['interesting?']==True]\n",
    "as_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Check other interesting criteria for rules\n",
    "- evaluate which metrix is the most reasonable (confidence, lift, etc..)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comments and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
