{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning / Aprendizagem Automática\n",
    "\n",
    "## Diogo Soares, André Falcão and Sara C. Madeira, 2020/21\n",
    "\n",
    "# ML Project  - Learning about Donations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics\n",
    "\n",
    "**Students are encouraged to work in teams of 3 people**. \n",
    "\n",
    "Projects with smaller teams are allowed, in exceptional cases, but will not have better grades for this reason. \n",
    "\n",
    "The quality of the project will dictate its grade, not the number of people working.\n",
    "\n",
    "**The project's solution should be uploaded in Moodle before the end of December, 18th (last day before Christmas holidays).** \n",
    "\n",
    "Students should **upload a `.zip` file** containing all the files necessary for project evaluation. \n",
    "\n",
    "**It is mandatory to produce a Jupyter notebook containing code and text/images/tables/etc describing the solution and the results. The notebook is both the solution and the report.**\n",
    "\n",
    "**Decisions should be fundamented and results should be critically discussed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "The team should use [Python 3](https://www.python.org) and [Jupyter Notebook](http://jupyter.org), together with **[Scikit-learn](http://scikit-learn.org/stable/)**, **[Orange3](https://orange.biolab.si)**, or **both**.\n",
    "\n",
    "**[Orange3](https://orange.biolab.si)** can be used through its **[programmatic version](https://docs.orange.biolab.si/3/data-mining-library/)**, by importing and using its packages, or throught its **workflow version**. \n",
    "\n",
    "**It is up to the team to decide when to use Scikit-learn, Orange, or both.**\n",
    "\n",
    "In this context, your Jupyter notebook might have a mix of code, results, text explanations, workflow figures, etc. \n",
    "\n",
    "In case you use Orange/workflows for some tasks you should also deliver the workflow files and explain the options taken in each widget in your notebook.\n",
    "\n",
    "**You can use this noteboook and the sections below as template for your work.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset to be analysed is **`Donors_dataset.csv`**, made available together with this project description. This dataset, downloaded from [Kaggle](https://www.kaggle.com), contains selected data from the following dataset: [Donors-Prediction](https://www.kaggle.com/momohmustapha/donorsprediction/). \n",
    "\n",
    "\n",
    "**In this project, your team is supposed to use only tabular data (not Images or Image Metadata) and see how far you can go in predicting donations and understanding the donors. You should use both supervised and unsupervised learning to tackled 2 tasks:**\n",
    "\n",
    "1. **Task 1 (Supervised Learning) - Predicting Donation and Donation Type**\n",
    "2. **Task 2 (Unsupervised Learning) - Characterizing Donors**\n",
    "\n",
    "The **`Donors_dataset.csv`** you should learn from has **19.372 instances** described by **50 data fields** that you might use as **categorical/numerical features** \n",
    "\n",
    "### File Descriptions\n",
    "\n",
    "* **Donors_dataset.csv** - Tabular/text data to be used in the machine learning tasks.\n",
    "\n",
    "\n",
    "### Data Fields\n",
    "\n",
    "* **CARD_PROM_12** - number of card promotions sent to the individual by the charitable organization in the past 12 months\n",
    "* **CLUSTER_CODE** - one of 54 possible cluster codes, which are unique in terms of socioeconomic status, urbanicity, ethnicity, and other demographic characteristics\n",
    "* **CONTROL_NUMBER** - unique identifier of each individual\n",
    "* **DONOR_AGE** - age as of last year's mail solicitation\n",
    "* **DONOR_GENDER** - actual or inferred gender\n",
    "* **FILE_AVG_GIFT** - this variable is identical to LIFETIME_AVG_GIFT_AMT\n",
    "* **FILE_CARD_GIFT** - lifetime average donation (in \\\\$) from the individual in response to all card solicitations from the charitable organization\n",
    "* **FREQUENCY_STATUS_97NK** - based on the period of recency (determined by RECENCY_STATUS_96NK), which is the past 12 months for all groups except L and E. L and E are 13–24 months ago and 25–36 months ago, respectively: 1 if one donation in this period, 2 if two donations in this period, 3 if three donations in this period, and 4 if four or more donations in this period.\n",
    "* **HOME_OWNER** - H if the individual is a homeowner, U if this information is unknown\n",
    "* **INCOME_GROUP** - one of 7 possible income level groups based on a number of demographic characteristics\n",
    "* **IN_HOUSE** - 1 if the individual has ever donated to the charitable organization's In House program, 0 if not\n",
    "* **LAST_GIFT_AMT** - amount of the most recent donation from the individual to the charitable organization\n",
    "* **LIFETIME_AVG_GIFT_AMT** - lifetime average donation (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_CARD_PROM** - total number of card promotions sent to the individual by the charitable organization\n",
    "* **LIFETIME_GIFT_AMOUNT** - total lifetime donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_COUNT** - total number of donations from the individual to the charitable organization\n",
    "* **LIFETIME_GIFT_RANGE** - maximum donation amount from the individual minus minimum donation amount from the individual\n",
    "* **LIFETIME_MAX_GIFT_AMT** - maximum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_MIN_GIFT_AMT** - minimum donation amount (in \\\\$) from the individual to the charitable organization\n",
    "* **LIFETIME_PROM** - total number of promotions sent to the individual by the charitable organization\n",
    "* **MEDIAN_HOME_VALUE** - median home value (in 100\\\\$) as determined by other input variables\n",
    "* **MEDIAN_HOUSEHOLD_INCOME** - median household income (in 100\\\\$) as determined by other input variables\n",
    "* **MONTHS_SINCE_FIRST_GIFT** - number of months since the first donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_GIFT** - number of months since the most recent donation from the individual to the charitable organization\n",
    "* **MONTHS_SINCE_LAST_PROM_RESP** - number of months since the individual has responded to a promotion by the charitable organization\n",
    "* **MONTHS_SINCE_ORIGIN** - number of months that the individual has been in the charitable organization's database\n",
    "* **MOR_HIT_RATE** - total number of known times the donor has responded to a mailed solicitation from a group other than the charitable organization\n",
    "* **NUMBER_PROM_12** - number of promotions (card or other) sent to the individual by the charitable organization in the past 12 months\n",
    "* **OVERLAY_SOURCE** - the data source against which the individual was matched: M if Metromail, P if Polk, B if both\n",
    "* **PCT_ATTRIBUTE1** - percent of residents in the neighborhood in which the individual lives that are males and active military\n",
    "* **PCT_ATTRIBUTE2** - percent of residents in the neighborhood in which the individual lives that are males and veterans\n",
    "* **PCT_ATTRIBUTE3** - percent of residents in the neighborhood in which the individual lives that are Vietnam veterans\n",
    "* **PCT_ATTRIBUTE4** - percent of residents in the neighborhood in which the individual lives that are WWII veterans\n",
    "* **PCT_OWNER_OCCUPIED** - percent of owner-occupied housing in the neighborhood in which the individual lives\n",
    "* **PEP_STAR** - 1 if individual has ever achieved STAR donor status, 0 if not\n",
    "* **PER_CAPITA_INCOME** - per capita income (in \\\\$) of the neighborhood in which the individual lives\n",
    "* **PUBLISHED_PHONE** - 1 if the individual's telephone number is published, 0 if not\n",
    "* **RECENCY_STATUS_96NK** - recency status as of two years ago: A if active donor, S if star donor, N if new donor, E if inactive donor, F if first time donor, L if lapsing donor\n",
    "* **RECENT_AVG_CARD_GIFT_AMT** - average donation from the individual in response to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_AVG_GIFT_AMT** - average donation (in \\\\$) from the individual to the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_COUNT** - number of times the individual has responded to a card solicitation from the charitable organization since four years ago\n",
    "* **RECENT_CARD_RESPONSE_PROP** - proportion of responses to the individual to the number of card solicitations from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_COUNT** - number of times the individual has responded to a promotion (card or other) from the charitable organization since four years ago\n",
    "* **RECENT_RESPONSE_PROP** - proportion of responses to the individual to the number of (card or other) solicitations from the charitable organization since four years ago\n",
    "* **RECENT_STAR_STATUS** - 1 if individual has achieved star donor status since four years ago, 0 if not\n",
    "* **SES** - one of 5 possible socioeconomic codes classifying the neighborhood in which the individual lives\n",
    "* **TARGET_B** - 1 if individual donated in response to last year's 97NK mail solicitation from the charitable organization, 0 if individual did not\n",
    "* **TARGET_D** - amount of donation (in \\\\$) from the individual in response to last year's 97NK mail solicitation from the charitable organization\n",
    "* **URBANICITY** - classification of the neighborhood in which the individual lives: U if urban, C if city, S if suburban, T if town, R if rural, ? if missing\n",
    "* **WEALTH_RATING** - one of 10 possible wealth rating groups based on a number of demographic characteristics\n",
    "\n",
    "\n",
    "### Donation TYPE\n",
    "\n",
    "You are supposed to create a new column/feature named `DONATION_TYPE`, whose values describe ranges of the donation amount (DA) reported in feature `TARGET_D`:\n",
    "* `A` - DA >= 50\n",
    "* `B` - 20 <= DA < 50 \n",
    "* `C` - 13 <= DA < 20\n",
    "* `D` - 10 <= DA < 13\n",
    "* `E` - DA < 10\n",
    "\n",
    "\n",
    "### **Important Notes on Data Cleaning and Preprocessing**\n",
    "\n",
    "   1. Data can contain **errors/typos**, whose correction might improve the analysis.\n",
    "   2. Some features can contain **many values**, whose grouping in categories (aggregation into bins) might improve the analysis.\n",
    "   3. Data can contain **missing values**, that you might decide to fill. You might also decide to eliminate instances/features with high percentages of missing values.\n",
    "   4. **Not all features are necessarily important** for the analysis.\n",
    "   5. Depending on the analysis, **some features might have to be excluded**.\n",
    "   6. Class distribution is an important characteristic of the dataset that should be checked. **Class imbalance** might impair machine learning. \n",
    "  \n",
    "Some potentially useful links:\n",
    "\n",
    "* Data Cleaning and Preprocessing in Scikit-learn: https://scikit-learn.org/stable/modules/preprocessing.html#\n",
    "* Data Cleaning and Preprocessing in Orange: https://docs.biolab.si//3/visual-programming/widgets/data/preprocess.html\n",
    "* Dealing with imbalance datasets: https://pypi.org/project/imbalanced-learn/ and https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets#t7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0 (Know your Data) - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"Donors_dataset.csv\")\n",
    "raw_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **understand better the features**, their distribution of values, potential errors, etc and plan/describe what data preprocessing steps should be performed next. Very important also is to check the distribution of values in the target (class distribution). \n",
    "\n",
    "Here you can find a notebook with some examples of what you can do in **Exploratory Data Analysis**: https://www.kaggle.com/artgor/exploration-of-data-step-by-step/notebook. You can also use Orange widgets for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will print and plot different tables and visualisations to get a feeling and better overview of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will plot the histograms to check if there are numerical features with a high number of values, that can possibly be binned to be more convenient for the models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Plot for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.hist(bins=30, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort features in different categories for plotting:\n",
    "all_features = list(raw_data.columns[2:])\n",
    "pscontinuous_features = ['CONTROL_NUMBER', 'MONTHS_SINCE_ORIGIN', 'DONOR_AGE', 'PER_CAPITA_INCOME', \\\n",
    "                              'WEALTH_RATING', 'MEDIAN_HOME_VALUE', 'MEDIAN_HOUSEHOLD_INCOME', \\\n",
    "                             'PCT_OWNER_OCCUPIED', 'PCT_ATTRIBUTE2', 'PCT_ATTRIBUTE3', 'PCT_ATTRIBUTE4', \\\n",
    "                              'RECENT_RESPONSE_PROP', 'RECENT_AVG_GIFT_AMT', 'RECENT_CARD_RESPONSE_PROP', \\\n",
    "                              'RECENT_AVG_CARD_GIFT_AMT', 'RECENT_RESPONSE_COUNT', 'RECENT_CARD_RESPONSE_COUNT', \\\n",
    "                              'MONTHS_SINCE_LAST_PROM_RESP', 'LIFETIME_CARD_PROM', 'LIFETIME_PROM', \\\n",
    "                              'LIFETIME_GIFT_COUNT', 'LAST_GIFT_AMT', 'NUMBER_PROM_12', 'MONTHS_SINCE_LAST_GIFT', \\\n",
    "                              'MONTHS_SINCE_FIRST_GIFT', 'FILE_CARD_GIFT','CARD_PROM_12']\n",
    "categorical_features = ['IN_HOUSE', 'URBANICITY', 'SES', 'HOME_OWNER', 'DONOR_GENDER', 'INCOME_GROUP', \\\n",
    "                        'PUBLISHED_PHONE', 'OVERLAY_SOURCE', 'PEP_STAR', 'RECENCY_STATUS_96NK', \\\n",
    "                        'FREQUENCY_STATUS_97NK']\n",
    "other_features = ['CLUSTER_CODE', 'MOR_HIT_RATE', 'PCT_ATTRIBUTE1', 'RECENT_STAR_STATUS', 'LIFETIME_GIFT_AMOUNT', \\\n",
    "                  'LIFETIME_AVG_GIFT_AMT', 'LIFETIME_GIFT_RANGE', 'LIFETIME_MAX_GIFT_AMT', 'LIFETIME_MIN_GIFT_AMT', \\\n",
    "                  'FILE_AVG_GIFT']\n",
    "\n",
    "# check, if all are included and not couble counts:\n",
    "feature_lists = pscontinuous_features+categorical_features+other_features\n",
    "print('All features included and no doubles: ', \\\n",
    "      len(all_features)==len(feature_lists) and set(feature_lists)==set(all_features))\n",
    "\n",
    "def create_plots(features_to_plot, plottype='violin'):\n",
    "    '''Creates plots for given features. Plottypes: 'violin', 'count' . We can add more if necessary.\n",
    "    carful: if number of values per feature is high when 'count' is chosen, running time goes up. '''\n",
    "    print(f'{len(features_to_plot)} plots:')\n",
    "    ncols = 3\n",
    "    nrows = int(len(features_to_plot)/ncols)+1\n",
    "    newplots = plt.figure(figsize=(ncols*5,nrows*5))\n",
    "    for ind, feature in enumerate(features_to_plot):\n",
    "        plt.subplot(nrows, ncols, ind+1)\n",
    "        if plottype=='violin':\n",
    "            sns.violinplot(x=\"TARGET_B\", y=feature, data=raw_data, fontsize=8)\n",
    "            plt.title(f'TARGET_B by {feature}', fontsize=8)\n",
    "        if plottype!='violin':\n",
    "            sns.countplot(x='TARGET_B', data=raw_data, hue=feature);\n",
    "            plt.title(f'{feature} in TARGET_B', fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Violin Plots for numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(pscontinuous_features, 'violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Countplots for categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(categorical_features, 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = raw_data['TARGET_B'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('TARGET_B classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violin plots for other features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plots(other_features, 'violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Result of the exploratory analysis: the error for this feature is that one value is a typo ( = \"A\"). That row can be deleted. \n",
    "\n",
    "----\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw_data[raw_data.DONOR_GENDER == \"A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.drop(14977, inplace = True )\n",
    "raw_data = raw_data.reset_index(drop=True)\n",
    "display(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = raw_data.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 14))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(250, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "heatmap = sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Result of the exploratory analysis: Highly correlated features (red = positive, blue = negative correlated) can be reduntant because they dont produce no additional information and can be useless for the model. \n",
    "\n",
    "TODO: maybe deleted redundant data. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming donation amount in classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transformed_data.drop(columns = [\"CONTROL_NUMBER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_donation_type(row):\n",
    "    if row['TARGET_D'] >= 50:\n",
    "        return 'A'\n",
    "    if row['TARGET_D'] >= 20 and row['TARGET_D'] < 50:\n",
    "        return 'B'\n",
    "    if row['TARGET_D'] >= 13 and row['TARGET_D'] < 20:\n",
    "        return 'C'\n",
    "    if row['TARGET_D'] >= 10 and row['TARGET_D'] < 13:\n",
    "        return 'D'\n",
    "    if row['TARGET_D'] < 10:\n",
    "        return 'E'\n",
    "    return '?'\n",
    "\n",
    "transformed_data['DONATION_TYPE'] = transformed_data.apply (lambda row: label_donation_type(row), axis=1)\n",
    "transformed_data = transformed_data.drop(columns = ('TARGET_D'))\n",
    "\n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['WEALTH_RATING'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 (Supervised Learning) - Predicting Donation and Donation Type\n",
    "\n",
    "In this task you should target 3 classification tasks:\n",
    "1. **Predicting  Donation (binary classification task)**; \n",
    "2. **Predicting Donation TYPE (multiclass classification)**; and\n",
    "3. **Train specialized models for SES (socioeconomic classification)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You should:**\n",
    "\n",
    "* Choose **one classifier in each category**: Tree models, Rule models, Linear models, Distance-based models, and Probabilistic models.\n",
    "* Use cross-validation to evaluate the results. \n",
    "* Present and discuss the results for different evaluation measures, present confusion matrices. Remember that not only overall results are important. Check what happens when learning to predict each class.\n",
    "* Describe the parameters used for each classifier and how their choice impacted or not the results.\n",
    "* Choose the best classifier and fundament you choice.\n",
    "* **Discuss critically your choices and the results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning numerical data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of Histogram Analysis: \n",
    "\n",
    "Attributes worth binning (because they have a high number of values): \n",
    "\n",
    "- DONOR_AGE\n",
    "- LIFETIME_CARD_FROM\n",
    "- LIFETIME_GIFT_COUNT\n",
    "- LIFETIME_PROM\n",
    "- MEDIAN_HOME_VALUE\n",
    "- MEDIAN HOUSEHOLD_INCOME\n",
    "- MONTHS_SINCE_LAST_GIFT\n",
    "- MONTHS_SINCE_FIRST_GIFT\n",
    "- PCT_ATTRIBUTE1\n",
    "- PCT_ATTRIBUTE2\n",
    "- PCT_ATTRIBUTE3\n",
    "- PCT_ATTRIBUTE4\n",
    "- PCT_OWNER_OCCUPIED\n",
    "- PER_CAPITA_INCOME\n",
    "- RECENT_RESPONSE_PROP\n",
    "- MONTHS_SINCE_LAST_PROM_RESP\n",
    "\n",
    "TODO: create bins \n",
    "\n",
    "- either quantile binning (our first approach)\n",
    "- or Log transform \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "features_for_binning =  [\"DONOR_AGE\", \"LIFETIME_CARD_PROM\", \"LIFETIME_GIFT_COUNT\", \"LIFETIME_PROM\", \"MEDIAN_HOME_VALUE\", \"MEDIAN_HOUSEHOLD_INCOME\", \"MONTHS_SINCE_FIRST_GIFT\", \"PCT_ATTRIBUTE2\", \"PCT_ATTRIBUTE3\", \"PCT_ATTRIBUTE4\", \"PCT_OWNER_OCCUPIED\", \"PER_CAPITA_INCOME\", \"RECENT_RESPONSE_PROP\"]\n",
    "quantile_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "quantile_labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for feature in features_for_binning:\n",
    "    quantiles = transformed_data[feature].quantile(quantile_list)\n",
    "\n",
    "    #binned_dataframe[f'{feature}_range'] = pd.qcut(binned_dataframe[feature],q=quantile_list)\n",
    "    transformed_data[f'{feature}_label'] = pd.qcut(transformed_data[feature],q=quantile_list,labels=quantile_labels, duplicates='drop')\n",
    "\n",
    "    \n",
    "transformed_data = transformed_data.drop(columns = features_for_binning)    \n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['DONATION_TYPE'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('DONATION_TYPE classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('WEALTH_RATING classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "The dataset contains NaN values in some columns. As the training of the models cant happen with NaN values there are two possibilities. Either drop the values which will lead to a very small dataset, or we try to replace NaN values with other values (with different techniques) in order to maintain a big dataset and dont loose information.\n",
    "\n",
    "Features with missing values, that need to be replaced are: \n",
    "\n",
    "- 'WEALTH_RATING': 8810\n",
    "- 'DONOR_AGE_label': 4795\n",
    "- 'INCOME_GROUP': 4392\n",
    "- 'MONTHS_SINCE_LAST_PROM_RESP': 246\n",
    "\n",
    "- 'URBANICITY'\n",
    "- 'SES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('WEALTH_RATING classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = transformed_data['DONOR_AGE_label'].value_counts().sort_index().plot(kind = 'barh')\n",
    "#plot.set_title('DONOR_AGE_label classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['INCOME_GROUP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('INCOME_GROUP classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['MONTHS_SINCE_LAST_PROM_RESP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('MONTHS_SINCE_LAST_PROM_RESP classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['INCOME_GROUP'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('URBANICITY classes counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = transformed_data['SES'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('SES classes counts')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace false values (outliers) with mean of column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO : How did we recognize the outliers ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.MOR_HIT_RATE.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Result: MOR_HIT_RATE : time of answers on other mailings. Seem to high in some cases, will be replaced by column mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Result: MONTHS_SINCE_LAST_PROM_RESP : months since last answer. This value cant be negative and will be replaced by column mean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOR_HIT_RATE : time of answers on other mailings. seems to high, will be replaced by column mean. \n",
    "transformed_data.MOR_HIT_RATE = transformed_data.MOR_HIT_RATE.apply(lambda x: (transformed_data.MOR_HIT_RATE.mode()[0]) if x > 100 else x)\n",
    "\n",
    "# MONTHS_SINCE_LAST_PROM_RESP : months since last answer cant be negative,will be replaced by column mean. \n",
    "transformed_data.MONTHS_SINCE_LAST_PROM_RESP = transformed_data.MONTHS_SINCE_LAST_PROM_RESP.apply(lambda x: (transformed_data.MONTHS_SINCE_LAST_PROM_RESP.mode()[0]) if x < 0.0 else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show Columns that are of the type \"object\" and need to be transformed to numerical values\n",
    "\n",
    "obj_df = transformed_data.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_make = LabelEncoder()\n",
    "\n",
    "\n",
    "transformed_data[\"URBANICITY\"] = lb_make.fit_transform(transformed_data[\"URBANICITY\"])\n",
    "transformed_data[\"SES\"] = lb_make.fit_transform(transformed_data[\"SES\"])\n",
    "transformed_data[\"CLUSTER_CODE\"] = lb_make.fit_transform(transformed_data[\"CLUSTER_CODE\"])\n",
    "transformed_data[\"HOME_OWNER\"] = lb_make.fit_transform(transformed_data[\"HOME_OWNER\"])\n",
    "transformed_data[\"DONOR_GENDER\"] = lb_make.fit_transform(transformed_data[\"DONOR_GENDER\"])\n",
    "transformed_data[\"OVERLAY_SOURCE\"] = lb_make.fit_transform(transformed_data[\"OVERLAY_SOURCE\"])\n",
    "transformed_data[\"RECENCY_STATUS_96NK\"] = lb_make.fit_transform(transformed_data[\"RECENCY_STATUS_96NK\"])\n",
    "transformed_data[\"DONATION_TYPE\"] = lb_make.fit_transform(transformed_data[\"DONATION_TYPE\"])\n",
    "\n",
    "DT_LaEnc = lb_make #For unsupervized learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot = transformed_data['URBANICITY'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('URBANICITY classes counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Data Cleaning\n",
    "\n",
    "0. **knn for NaN Replacing**\n",
    "1. **add rule based model**\n",
    "2. **oneHot Encoding Feature for all categorical features ? (?)**\n",
    "\n",
    "\n",
    "model training : \n",
    "\n",
    "3. **redo multiclass classification with onehot encoded data**\n",
    "\n",
    "4. **Train 1 model for each SES class (5) to predict donation/donation type. (use best model from experiement 1 (target_B))**\n",
    "\n",
    "5. **Importance analysis of features = package ?**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- todo: (optional)\n",
    "    * Outlier Detection with Standard Deviation\n",
    "    * https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "- todo: feature engineering:  (parallel zum model training)\n",
    "    * You might also decide to eliminate instances/features with high percentages of missing values. \n",
    "    * Not all features are necessarily important for the analysis.\n",
    "    * Depending on the analysis, some features might have to be excluded\n",
    "    \n",
    "\n",
    "----\n",
    "\n",
    "### Model Training: \n",
    "\n",
    "- Tree Models (luki)\n",
    "    * ~~Predicting Donation (binary classification task);~~\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "    * class significance ? \n",
    "- rule based (?)\n",
    "    * Predicting Donation (binary classification task);\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "- linear based (rob)\n",
    "    * ~~Predicting Donation (binary classification task);~~\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "- dist (luki)\n",
    "    * ~~Predicting Donation (binary classification task);~~\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "- probabilistic (luki)\n",
    "    * ~~Predicting Donation (binary classification task);~~\n",
    "    * Predicting Donation TYPE (multiclass classification);\n",
    "  \n",
    "  \n",
    "---\n",
    "\n",
    "### Unsupervised learning: \n",
    "\n",
    "- Association rule mining to find associations between the features and the target Donation/DonationTYPE. (Flo)\n",
    "- Clustering algorithms to find similar groups of donors. Is it possible to find groups of donors with the same/similar DonationTYPE? (Flo)\n",
    "\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "As stated in the forum from the professors: \n",
    "\n",
    "1. balance the data before training / evaluation.\n",
    "\n",
    "4. Class balancing, Binning, can be important in supervised learning but not so much in unsupervised\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing Data (NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n",
    "raw_data.MOR_HIT_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.loc[transformed_data['URBANICITY'] == 0,'URBANICITY'] = np.nan\n",
    "transformed_data.loc[transformed_data['SES'] == 0,'SES'] = np.nan\n",
    "transformed_data.loc[transformed_data['CLUSTER_CODE'] == 0,'CLUSTER_CODE'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_mode = ['URBANICITY', 'SES', 'CLUSTER_CODE', 'INCOME_GROUP', 'WEALTH_RATING']\n",
    "impute_mean = ['MONTHS_SINCE_LAST_PROM_RESP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in impute_mode:\n",
    "    print(transformed_data[feature].mode()[0])\n",
    "    transformed_data[feature].fillna(transformed_data[feature].mode()[0], inplace=True)\n",
    "\n",
    "for feature in impute_mean:\n",
    "    print(transformed_data[feature].mean())\n",
    "    transformed_data[feature].fillna(transformed_data[feature].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=20)\n",
    "transformed_data = pd.DataFrame(imputer.fit_transform(transformed_data), columns=transformed_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.isna().sum()\n",
    "display(transformed_data['URBANICITY'])\n",
    "\n",
    "# if KNN\n",
    "#display(df_filled[30:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot = df_filled['URBANICITY'].value_counts().sort_index().plot(kind = 'barh')\n",
    "x = dict(transformed_data.isna().sum())\n",
    "{k: v for k, v in sorted(x.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data['MOR_HIT_RATE'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_data = transformed_data.copy() #This data should not be binned, but encoded --> clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CL_data = transformed_data.copy() # This data should not be binned, but encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_for_binning =  [\"DONOR_AGE\", \"LIFETIME_CARD_PROM\", \"LIFETIME_GIFT_COUNT\", \"LIFETIME_PROM\", \"MONTHS_SINCE_ORIGIN\", \"MEDIAN_HOME_VALUE\", \"MEDIAN_HOUSEHOLD_INCOME\", \"MONTHS_SINCE_FIRST_GIFT\", \"PCT_ATTRIBUTE2\", \"PCT_ATTRIBUTE3\", \"PCT_ATTRIBUTE4\", \"PCT_OWNER_OCCUPIED\", \"PER_CAPITA_INCOME\", \"RECENT_RESPONSE_PROP\"]\n",
    "quantile_list = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "quantile_labels = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for feature in features_for_binning:\n",
    "    print(feature)\n",
    "    if feature==\"MONTHS_SINCE_ORIGIN\": # less bins for this features because of high number of zeros\n",
    "        quantile_list = np.linspace(0, 1.0, 7)\n",
    "        quantile_labels = np.arange(0,len(quantile_list)-1)\n",
    "        \n",
    "    quantiles = transformed_data[feature].quantile(quantile_list)\n",
    "    \n",
    "    \n",
    "    #binned_dataframe[f'{feature}_range'] = pd.qcut(binned_dataframe[feature],q=quantile_list)\n",
    "    transformed_data[f'{feature}_label'] = pd.qcut(transformed_data[feature],q=quantile_list,labels=quantile_labels, duplicates='drop')\n",
    "\n",
    "    \n",
    "transformed_data = transformed_data.drop(columns = features_for_binning)    \n",
    "display(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data will be used in Rule Mining\n",
    "RM_data = transformed_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert float64 to int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting for better performance\n",
    "no difference to float values, because decimal number is not used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transformed_data.select_dtypes(include=['float64'])\n",
    "#tf.drop(columns=['RECENT_CARD_RESPONSE_PROP','RECENT_AVG_GIFT_AMT', 'RECENT_AVG_CARD_GIFT_AMT', \n",
    "#                 'LIFETIME_AVG_GIFT_AMT', 'LIFETIME_GIFT_RANGE', 'LIFETIME_MAX_GIFT_AMT', 'LIFETIME_MIN_GIFT_AMT', 'FILE_AVG_GIFT'])\n",
    "transformed_data[tf.columns] = transformed_data[tf.columns].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data will be used in Rule Mining\n",
    "#RM_data = transformed_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from fancyimpute import KNN\n",
    "#instantiate both packages to use\n",
    "encoder = OrdinalEncoder()\n",
    "imputer = KNN()\n",
    "# create a list of categorical columns to iterate over\n",
    "to_encode = ['WEALTH_RATING','DONOR_AGE_label','INCOME_GROUP', 'URBANICITY','SES' ]\n",
    "\n",
    "\n",
    "def encode(data):\n",
    "    pd.set_option('mode.chained_assignment', None)\n",
    "    '''function to encode non-null data and replace it in the original data'''\n",
    "    #retains only non-null values\n",
    "    nonulls = np.array(data.dropna())\n",
    "    #reshapes the data for encoding\n",
    "    impute_reshape = nonulls.reshape(-1,1)\n",
    "    #encode date\n",
    "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
    "    #Assign back encoded values to non-null values\n",
    "    tdata = data.copy()\n",
    "    tdata.is_copy = None\n",
    "    tdata.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
    "  \n",
    "    return tdata\n",
    "\n",
    "#create a for loop to iterate through each column in the data\n",
    "for columns in to_encode:\n",
    "    encode(transformed_data[columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot = transformed_data['WEALTH_RATING'].value_counts().sort_index().plot(kind = 'barh')\n",
    "plot.set_title('URBANICITY classes counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the Data: Resampling the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = transformed_data.copy()\n",
    "count_class_0, count_class_1 = resampled_data['TARGET_B'].value_counts()\n",
    "print(count_class_0,count_class_1)\n",
    "\n",
    "#Divide\n",
    "td_class_0 = resampled_data[resampled_data['TARGET_B'] == 0]\n",
    "td_class_1 = resampled_data[resampled_data['TARGET_B'] == 1]\n",
    "\n",
    "td_class_0_under = td_class_0.sample(count_class_1)\n",
    "td_under = pd.concat([td_class_0_under, td_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(td_under['TARGET_B'].value_counts())\n",
    "\n",
    "td_under['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_class_1_over = td_class_1.sample(count_class_0, replace=True)\n",
    "td_over = pd.concat([td_class_0, td_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(td_over['TARGET_B'].value_counts())\n",
    "\n",
    "td_over['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python imbalanced learn module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!pip3 install imblearn\n",
    "import imblearn\n",
    "\n",
    "def plot_2d_space(X, y, label='Classes'):   \n",
    "    colors = ['#1F77B4', '#FF7F0E']\n",
    "    markers = ['o', 's']\n",
    "    for l, c, m in zip(np.unique(y), colors, markers):\n",
    "        plt.scatter(\n",
    "            X[y==l, 0],\n",
    "            X[y==l, 1],\n",
    "            c=c, label=l, marker=m\n",
    "        )\n",
    "    plt.title(label)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(return_indices=True)\n",
    "X_rus, y_rus, id_rus = rus.fit_sample(resampled_data.['TARGET_B'])\n",
    "\n",
    "print('Removed indexes:', id_rus)\n",
    "\n",
    "plot_2d_space(X_rus, y_rus, 'Random under-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resampling the training set pushed the accurency to 0.51\n",
    "Conclusion: no resampling of the trainingset\n",
    "\n",
    "Code: <br>\n",
    "count_class_0, count_class_1 = train_dataset['TARGET_B'].value_counts()\n",
    "print(count_class_0,count_class_1)\n",
    "\n",
    "#Divide\n",
    "td_class_0 = train_dataset[train_dataset['TARGET_B'] == 0]\n",
    "td_class_1 = train_dataset[train_dataset['TARGET_B'] == 1]\n",
    "\n",
    "td_class_0_under = td_class_0.sample(count_class_1)\n",
    "td_under = pd.concat([td_class_0_under, td_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(td_under['TARGET_B'].value_counts())\n",
    "\n",
    "td_under['TARGET_B'].value_counts().plot(kind='bar', title='Count (TARGET_B)');\n",
    "\n",
    "train_dataset = td_under\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training and Test data (Splitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for normal classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy data choices:\n",
    "- transformed_data (no resampling)\n",
    "- td_under (random under sampling)\n",
    "- td_over (random over sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_data = transformed_data.copy()\n",
    "#transformed_data = td_under.copy()\n",
    "transformed_data = td_over.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = transformed_data.sample(frac=0.8,random_state=87)\n",
    "test_dataset = transformed_data.drop(train_dataset.index)\n",
    "\n",
    "X_train = train_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "X_test = test_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\"])\n",
    "\n",
    "y_train_target_b = train_dataset.pop(\"TARGET_B\")\n",
    "y_test_target_b = test_dataset.pop('TARGET_B')\n",
    "\n",
    "#y_train_donation_type = train_dataset[\"DONATION_TYPE\"].values\n",
    "#y_test_donation_type = test_dataset[\"DONATION_TYPE\"].values\n",
    "\n",
    "y_train_donation_type = train_dataset.pop(\"DONATION_TYPE\")\n",
    "y_test_donation_type = test_dataset.pop('DONATION_TYPE')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for classification task for the specific SES classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SES_1 = transformed_data[transformed_data.SES == 0]\n",
    "SES_2 = transformed_data[transformed_data.SES == 1]\n",
    "SES_3 = transformed_data[transformed_data.SES == 2]\n",
    "SES_4 = transformed_data[transformed_data.SES == 3]\n",
    "SES_nan = transformed_data[transformed_data.SES == 4]\n",
    "\n",
    "def split_sets(df):\n",
    "\n",
    "    train_dataset = df.sample(frac=0.8,random_state=0)\n",
    "    test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "    X_train = train_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\", \"CONTROL_NUMBER\"])\n",
    "    X_test = test_dataset.drop(columns = [\"TARGET_B\", \"DONATION_TYPE\", \"CONTROL_NUMBER\"])\n",
    "\n",
    "    y_train_target_b = train_dataset.pop(\"TARGET_B\")\n",
    "    y_test_target_b = test_dataset.pop('TARGET_B')\n",
    "\n",
    "    #y_train_donation_type = train_dataset[\"DONATION_TYPE\"].values\n",
    "    #y_test_donation_type = test_dataset[\"DONATION_TYPE\"].values\n",
    "\n",
    "    y_train_donation_type = train_dataset.pop(\"DONATION_TYPE\")\n",
    "    y_test_donation_type = test_dataset.pop('DONATION_TYPE')\n",
    "    \n",
    "    return X_train, X_test, y_train_target_b, y_test_target_b, y_train_donation_type, y_test_donation_type\n",
    "\n",
    "\n",
    "X_train_SES_1, X_test_SES_1, y_train_target_b_SES_1, y_test_target_b_SES_1, y_train_donation_type_SES_1, y_test_donation_type_SES_1 = split_sets(SES_1)\n",
    "X_train_SES_2, X_test_SES_2, y_train_target_b_SES_2, y_test_target_b_SES_2, y_train_donation_type_SES_2, y_test_donation_type_SES_2 = split_sets(SES_2)\n",
    "X_train_SES_3, X_test_SES_3, y_train_target_b_SES_3, y_test_target_b_SES_3, y_train_donation_type_SES_3, y_test_donation_type_SES_3 = split_sets(SES_3)\n",
    "X_train_SES_4, X_test_SES_4, y_train_target_b_SES_4, y_test_target_b_SES_4, y_train_donation_type_SES_4, y_test_donation_type_SES_4 = split_sets(SES_4)\n",
    "X_train_SES_nan, X_test_SES_nan, y_train_target_b_SES_nan, y_test_target_b_SES_nan, y_train_donation_type_SES_nan, y_test_donation_type_SES_nan = split_sets(SES_4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_names ) -> pd.DataFrame:\n",
    "    '''\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    models = [\n",
    "        ('Tree based Model: RF', RandomForestClassifier()),\n",
    "        ('Distance Based Model: KNN', KNeighborsClassifier()),\n",
    "        ('Probabilistic Model: GNB', GaussianNB()),\n",
    "        ('Linear Model: SVM', SVC())\n",
    "        # Rule Based model: \n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']#, 'roc_auc']\n",
    "    target_names = target_names\n",
    "    \n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        #print(y_pred)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        # Generate confusion matrix\n",
    "        matrix = plot_confusion_matrix(model, X_test, y_test)#, normalize='true')\n",
    "        matrix.plot()\n",
    "        plt.rcParams[\"axes.grid\"] = False\n",
    "        \n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "\n",
    "        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final = run_exps(X_train, y_train_target_b, X_test, y_test_target_b, ['wont donate', 'donates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "sns.set(font_scale=1)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparametertuning for all binary classification models  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 7 min \n",
    "\n",
    "rand_forest = RandomForestClassifier(n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_target_b)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': [40, 50, 60],\n",
    "          'max_features': ['auto'],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'n_estimators': [400, 600, 800]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    rand_forest,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_target_b)\n",
    "\n",
    "print(\"Best params for Rand Forest : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for Rand Forest : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for Rand Forest : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=100,n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_target_b)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn = knn.fit(X_train, y_train_target_b)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n",
    "\n",
    "params = {'n_neighbors':[50,60,70],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    knn,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_target_b)\n",
    "\n",
    "print(\"Best params for knn : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for knn : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for knn : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=50)\n",
    "knn = knn.fit(X_train, y_train_target_b)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_target_b, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_target_b) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "print(classification_report(y_test_target_b, svm_predictions))\n",
    "\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train_target_b)\n",
    "\n",
    "\n",
    "print(\"Best params for SVM : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for SVM : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for SVM : \" + str(grid_search_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian NB needs no tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rand_forest.feature_importances_\n",
    "std = np.std([rand_forest.feature_importances_ for tree in rand_forest.estimators_],\n",
    "             axis=0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d : %s (%f)\" % (f + 1, indices[f] ,X_train.columns[indices[f]] ,importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure( figsize=(20,5))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparametertuning for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes 7 min \n",
    "\n",
    "rand_forest = RandomForestClassifier(n_jobs=-1)\n",
    "rand_forest = rand_forest.fit(X_train, y_train_donation_type)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n",
    "\n",
    "params = {'bootstrap': [True, False],\n",
    "          'max_depth': [10, 20, 30],\n",
    "          'max_features': ['auto'],\n",
    "          'min_samples_leaf': [1, 2, 4],\n",
    "          'min_samples_split': [2, 5],\n",
    "          'n_estimators': [200, 400, 600]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    rand_forest,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_donation_type)\n",
    "\n",
    "print(\"Best params for Rand Forest : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for Rand Forest : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for Rand Forest : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "knn = knn.fit(X_train, y_train_donation_type)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test_donation_type, y_pred))\n",
    "\n",
    "params = {'n_neighbors':[50,60,70],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    knn,\n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3,\n",
    "    n_jobs= -1\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train_donation_type)\n",
    "\n",
    "print(\"Best params for knn : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for knn : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for knn : \" + str(grid_search_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_donation_type) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "print(classification_report(y_test_donation_type, svm_predictions))\n",
    "\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train_donation_type)\n",
    "\n",
    "\n",
    "print(\"Best params for SVM : \" +  str(grid_search_cv.best_params_))\n",
    "\n",
    "print(\"Best estimator for SVM : \" + str(grid_search_cv.best_estimator_))\n",
    "\n",
    "print(\"Best score for SVM : \" + str(grid_search_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Classifiers: \n",
    "\n",
    "## Binary Classification \n",
    "\n",
    "### Without Sampling\n",
    "- RF : RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=400,n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=60)\n",
    "- SVM : \n",
    "### Oversampling \n",
    "- RF : RandomForestClassifier(bootstrap=False, max_depth=50, n_estimators=100,n_jobs=-1)\n",
    "- kNN : KNeighborsClassifier(leaf_size=3, n_jobs=-1, n_neighbors=50)\n",
    "- SVM : \n",
    "### Undersampling \n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n",
    "\n",
    "\n",
    "## Multiclass Classification \n",
    "\n",
    "### Without Sampling\n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n",
    "### Oversampling \n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n",
    "### Undersampling \n",
    "- RF : \n",
    "- kNN : \n",
    "- SVM : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models for binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_exps(X_train: pd.DataFrame , y_train: pd.DataFrame, X_test: pd.DataFrame, y_test: pd.DataFrame, target_names ) -> pd.DataFrame:\n",
    "    '''\n",
    "    Lightweight script to test many models and find winners\n",
    "    :param X_train: training split\n",
    "    :param y_train: training target vector\n",
    "    :param X_test: test split\n",
    "    :param y_test: test target vector\n",
    "    :return: DataFrame of predictions\n",
    "    '''\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    models = [\n",
    "        ('Tree based Model: RF', RandomForestClassifier()),\n",
    "        ('Distance Based Model: KNN', KNeighborsClassifier()),\n",
    "        ('Probabilistic Model: GNB', GaussianNB()),\n",
    "        ('Linear Model: SVM', SVC())\n",
    "        # Rule Based model: \n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']#, 'roc_auc']\n",
    "    target_names = target_names\n",
    "    \n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=90210)\n",
    "        cv_results = model_selection.cross_validate(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(name)\n",
    "        #print(y_pred)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        # Generate confusion matrix\n",
    "        matrix = plot_confusion_matrix(model, X_test, y_test)#, normalize='true')\n",
    "        matrix.plot()\n",
    "        plt.rcParams[\"axes.grid\"] = False\n",
    "        \n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        this_df = pd.DataFrame(cv_results)\n",
    "        this_df['model'] = name\n",
    "        dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        \n",
    "\n",
    "        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = run_exps(X_train, y_train_donation_type, X_test, y_test_donation_type, ['wont donate', 'A', 'B', 'C', 'D', 'E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=30, replace=True)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.set(font_scale=1)\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit, palette=\"Set3\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.savefig('./benchmark_models_performance.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models for each SES class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "TODO: we just have to train the best classifier (ONE !!!) from the previous experiments to predict donation and donation type for each SES class = 2 models for 5 SES = experiments \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final = run_exps(X_train_SES_1, y_train_target_b_SES_1, X_test_SES_1 , y_test_target_b_SES_1, ['wont donate', 'donates'])\n",
    "#final = run_exps(X_train_SES_2, y_train_target_b_SES_2, X_test_SES_2 , y_test_target_b_SES_2, ['wont donate', 'donates'])\n",
    "#final = run_exps(X_train_SES_3, y_train_target_b_SES_3, X_test_SES_3 , y_test_target_b_SES_3, ['wont donate', 'donates'])\n",
    "#final = run_exps(X_train_SES_4, y_train_target_b_SES_4, X_test_SES_4 , y_test_target_b_SES_4, ['wont donate', 'donates'])\n",
    "#final = run_exps(X_train_SES_nan, y_train_target_b_SES_nan,X_test_SES_nan , y_test_target_b_SES_nan, ['wont donate', 'donates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final = run_exps(X_train_SES_1, y_train_donation_type_SES_1, X_test_SES_1 , y_test_donation_type_SES_1, ['wont donate', 'A', 'B', 'C', 'D', 'E'])\n",
    "#final = run_exps(X_train_SES_2, y_train_donation_type_SES_2, X_test_SES_2 , y_test_donation_type_SES_2, ['wont donate', 'A', 'B', 'C', 'D', 'E'])\n",
    "#final = run_exps(X_train_SES_3, y_train_donation_type_SES_3, X_test_SES_3 , y_test_donation_type_SES_3, ['wont donate', 'A', 'B', 'C', 'D', 'E'])\n",
    "#final = run_exps(X_train_SES_4, y_train_donation_type_SES_4, X_test_SES_4 , y_test_donation_type_SES_4, ['wont donate', 'A', 'B', 'C', 'D', 'E'])\n",
    "#final = run_exps(X_train_SES_nan, y_train_donation_type_SES_nan, X_test_SES_nan , y_test_donation_type_SES_nan, ['wont donate', 'A', 'B', 'C', 'D', 'E'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logical Models: Rule models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: http://rasbt.github.io/mlxtend/ (apriori algorithm)\n",
    "\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "\n",
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Models: Linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting Donation (binary classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: linear regression or SVM ? \n",
    "# first we try SVM classifier\n",
    "  \n",
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_target_b) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test, y_test_target_b) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test_target_b, svm_predictions) \n",
    "matrix = plot_confusion_matrix(svm_model_linear, X_test, y_test_target_b)#, normalize='true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: linear regression or SVM ? \n",
    "# first we try SVM classifier\n",
    "  \n",
    "# training a linear SVM classifier \n",
    "\n",
    "svm_model_linear = SVC().fit(X_train, y_train_target_b) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "  \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test, y_test_target_b) \n",
    "  \n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test_target_b, svm_predictions) \n",
    "matrix = plot_confusion_matrix(svm_model_linear, X_test, y_test_target_b)#, normalize='true')\n",
    "# Tuning the SVM with \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear', 'rbf']}  \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs = -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "#grid.fit(X_train, y_train_target_b)\n",
    "\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(grid.best_estimator_) \n",
    "\n",
    "grid_predictions = grid.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Models: Distance-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: knn\n",
    "\n",
    "# training a KNN classifier \n",
    "\n",
    "knn = KNeighborsClassifier(leaf_size=1, n_jobs=-1, n_neighbors=4).fit(X_train, y_train_target_b) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test, y_test_target_b) \n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test)  \n",
    "cm = confusion_matrix(y_test_target_b, knn_predictions) \n",
    "\n",
    "matrix = plot_confusion_matrix(knn, X_test, y_test_target_b, normalize='true')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning\n",
    "\n",
    "#define the model and parameters\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':[4,5,6,7],\n",
    "              'leaf_size':[1,3,5],\n",
    "              'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]}\n",
    "\n",
    "#Fit the model\n",
    "model = GridSearchCV(knn, param_grid=parameters)\n",
    "model.fit(X_train,y_train_target_b)\n",
    "\n",
    "#predictions on test data\n",
    "prediction=model.predict(X_test)\n",
    "\n",
    "# print best parameter after tuning \n",
    "print(model.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(model.best_estimator_) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test, y_test_target_b) \n",
    "print(accuracy)\n",
    "  \n",
    "cm = confusion_matrix(y_test_target_b, knn_predictions) \n",
    "\n",
    "\n",
    "\n",
    "grid_predictions = model.predict(X_test) \n",
    "  \n",
    "# print classification report \n",
    "print(classification_report(y_test_target_b, grid_predictions)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(as_rules[as_rules['consequents']==frozenset({'DONATION_TYPE:High'})].head)# example: naive bayes \n",
    "\n",
    "# see above. \n",
    "\n",
    "# no grid search needed for naive bayes, because no parameters to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 (Unsupervised Learning) - Characterizing Donors and Donation Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you should **use unsupervised learning algorithms and try to characterize donors (people who really did a donation) and their donation type**. You can use:\n",
    "* **Association rule mining** to find **associations between the features and the target Donation/DonationTYPE**.\n",
    "* **Clustering algorithms to find similar groups of donors**. Is it possible to find groups of donors with the same/similar DonationTYPE?\n",
    "* **Be creative and define your own unsupervised analysis!** What would it be interesting to find out ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Association Rule Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data used here should have no labels encoded, but binning, no NaNs, no balancing:\n",
    "RM_transformed_data = RM_data.copy()\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interesting features: \n",
    "# only use features, that are not correlated to another already included features. See heatmap above\n",
    "# (running time and memory-spaceissues):\n",
    "features_to_bin = ['INCOME_GROUP', 'RECENT_AVG_GIFT_AMT', 'LIFETIME_GIFT_AMOUNT',  \\\n",
    "                   'NUMBER_PROM_12', 'DONOR_AGE_label','LIFETIME_PROM_label', \\\n",
    "                   'MONTHS_SINCE_ORIGIN_label', 'MEDIAN_HOME_VALUE_label', 'MEDIAN_HOUSEHOLD_INCOME_label', \\\n",
    "                   'PCT_ATTRIBUTE2_label', 'URBANICITY']#, 'LAST_GIFT_AMT', 'MONTHS_SINCE_LAST_GIFT', 'PER_CAPITA_INCOME_label',]\n",
    "other_features = ['TARGET_B', 'DONATION_TYPE', 'HOME_OWNER', 'DONOR_GENDER']#, 'PEP_STAR']\n",
    "                  #'MOR_HIT_RATE', 'PCT_ATTRIBUTE1', 'IN_HOUSE']\n",
    "interesting_features = other_features + features_to_bin\n",
    "\n",
    "RM_transformed_data = RM_transformed_data[interesting_features]\n",
    "\n",
    "# Backtransform DONATION_TYPE and create new compressed target:\n",
    "RM_transformed_data[\"DONATION_TYPE\"] = DT_LaEnc.inverse_transform(RM_transformed_data[\"DONATION_TYPE\"] \\\n",
    "                                                                  .astype('int32'))\n",
    "\n",
    "def convert_DT(x):\n",
    "    if x=='?':\n",
    "        return 'None'\n",
    "    if x=='A' or x=='B':\n",
    "        return 'High'\n",
    "    else:\n",
    "        return 'Low'\n",
    "RM_transformed_data.DONATION_TYPE = RM_transformed_data[\"DONATION_TYPE\"].apply(convert_DT)\n",
    "\n",
    "# Deal with two extraordinaly features with lots of zeros:\n",
    "#RM_transformed_data[\"MOR_HIT_RATE_RM\"] = RM_transformed_data[\"MOR_HIT_RATE\"].apply(lambda x: 0 if x==0 else 1)\n",
    "#RM_transformed_data[\"PCT_ATTRIBUTE1_RM\"] = RM_transformed_data[\"PCT_ATTRIBUTE1\"].apply(lambda x: 0 if x==0 else 1)\n",
    "#RM_transformed_data = RM_transformed_data.drop([\"MOR_HIT_RATE\", \"PCT_ATTRIBUTE1\"], axis=1)\n",
    "\n",
    "RM_transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RM_quantiles_list = [0, 1./3., 2./3., 1.0]\n",
    "RM_quantile_labels = [0, 1, 2]\n",
    "for feature in features_to_bin:\n",
    "    quantiles = RM_transformed_data[feature].quantile(RM_quantiles_list)\n",
    "    RM_transformed_data[f'{feature}_RM'] = pd.qcut(RM_transformed_data[feature],q=RM_quantiles_list, \\\n",
    "                                                   labels=RM_quantile_labels, duplicates='drop')\n",
    "\n",
    "RM_transformed_data = RM_transformed_data.drop(columns = features_to_bin)    \n",
    "display(RM_transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sources:\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html  -   6.3.4. Encoding categorical features\n",
    "# TP05: 2.2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "def ohe_encode(col_names, X=RM_transformed_data):\n",
    "    '''Takes columns to encode (format: ['colum1', 'column2', ...]) and DataFrame X with all columns. \n",
    "    The features in X should not be encoded yet.\n",
    "    Encodes features and replaces old columns in X. Returns updated X.'''\n",
    "    enc = OneHotEncoder()\n",
    "    matrix = X[col_names].to_numpy()\n",
    "    enc.fit(matrix)\n",
    "    matrix = enc.transform(matrix).toarray()\n",
    "    \n",
    "    categories_new = np.array(enc.categories_)\n",
    "    features_new = np.array([])\n",
    "    for ind1, cat in enumerate(categories_new):\n",
    "        for ind2, cat_new in enumerate(cat):\n",
    "            if ind2==1 and (col_names[ind1][-2:]=='RM'): # We do not need these Categories here and will drop them\n",
    "                features_new = np.append(features_new, 'Drop')\n",
    "            else:\n",
    "                features_new = np.append(features_new, col_names[ind1]+':'+str(cat_new))\n",
    "                \n",
    "    new_df = pd.DataFrame(matrix)\n",
    "    new_df.columns = features_new.tolist()\n",
    "\n",
    "    updated_df = pd.concat([X, new_df], axis=1)\n",
    "    updated_df = updated_df.drop(col_names, axis=1)\n",
    "    updated_df = updated_df.drop('Drop', axis=1)\n",
    "    \n",
    "    return(updated_df)\n",
    "\n",
    "columns_to_ohenc = list(RM_transformed_data.columns)\n",
    "columns_to_ohenc.remove('TARGET_B')\n",
    "RM_binary_data = ohe_encode(columns_to_ohenc)\n",
    "RM_binary_data = RM_binary_data.drop('DONATION_TYPE:Low', axis=1)\n",
    "RM_binary_data = RM_binary_data.rename(columns={'HOME_OWNER:1.0': 'HOME_OWNER:0', 'HOME_OWNER:0.0': 'HOME_OWNER:1'})\n",
    "RM_binary_data = RM_binary_data.rename(columns={'PEP_STAR:1.0': 'PEP_STAR:0', 'PEP_STAR:0.0': 'PEP_STAR:1'})\n",
    "\n",
    "drop_rows = np.arange(0, 15000, 1)\n",
    "RM_binary_data = RM_binary_data.drop(drop_rows)\n",
    "RM_binary_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Associations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How high does the min_support have to be? It has to be significantly smaller than the smallest class-support:\n",
    "lowest_class_support = RM_transformed_data[\"DONATION_TYPE\"].value_counts()[2] \\\n",
    "                       / RM_transformed_data[\"DONATION_TYPE\"].value_counts().sum()\n",
    "minimum_support = lowest_class_support / 5\n",
    "minimum_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# calculate frequent patterns:\n",
    "# shoud use \"minimum_support\"\n",
    "freq_patterns = apriori(RM_binary_data, min_support=minimum_support, use_colnames=True) \n",
    "freq_patterns['length'] = freq_patterns['itemsets'].apply(lambda x: len(x))\n",
    "freq_patterns = freq_patterns[ freq_patterns['length'] < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "def check_if_interesting(x):\n",
    "    # Interesting (maybe different criteria..):\n",
    "    # - consequents==(TARGET_B or DONATION_TYPE)\n",
    "    # - TARGET_B, B, D, E not in antecedents\n",
    "    \n",
    "    targets = ['TARGET_B', 'DONATION_TYPE:High', 'DONATION_TYPE:Low', 'DONATION_TYPE:None']\n",
    "    target_is_only_consequents = any(item in targets for item in x[1]) and len(x[1])==1\n",
    "    target_not_in_ancedents = not any(item in targets for item in x[0])\n",
    "    return target_is_only_consequents and target_not_in_ancedents\n",
    "\n",
    "# generate assiciation rules:\n",
    "metric = \"confidence\"\n",
    "\n",
    "# itemsets not larger than 2:\n",
    "\n",
    "as_rules_raw = association_rules(freq_patterns, metric=metric, min_threshold=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_rules = as_rules_raw.copy()\n",
    "# filter out uninteresting rules:\n",
    "as_rules['interesting?'] = as_rules[['antecedents', 'consequents']].apply(check_if_interesting, axis=1)\n",
    "as_rules = as_rules[ as_rules['interesting?']==True]\n",
    "as_rules = as_rules.sort_values(by=[metric], ascending=False)\n",
    "#as_rules = as_rules.drop(['confidence', 'lift', 'conviction', 'interesting?'], axis=1)\n",
    "as_rules = as_rules[as_rules['consequents'] != frozenset({'DONATION_TYPE:Low'})]\n",
    "as_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = as_rules[as_rules['consequents']==frozenset({'TARGET_B'})].head(n=10)\n",
    "df2 = as_rules[as_rules['consequents']==frozenset({'DONATION_TYPE:High'})].head(n=10)\n",
    "df3 = as_rules[as_rules['consequents']==frozenset({'DONATION_TYPE:None'})].head(n=10)\n",
    "for df in [df1, df2, df3]:\n",
    "    display(df)\n",
    "    #for index in df.index:\n",
    "    #    print(list(df.loc[index, 'antecedents']), '\\t', list(df.loc[index, 'consequents']),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- evaluate which metric is the most reasonable (confidence, lift, etc..); leverage looks the best right now.\n",
    "    http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/\n",
    "- min-support checken / metric-threshold\n",
    "- wie viele daten rausschmeißen??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data used here should be encoded, not necessarily binned.\n",
    "CL_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "clustering_interesting_features = CL_data.columns # take all columns for now\n",
    "# just like in Rule Mining, all features should be used here eventually:\n",
    "#clustering_interesting_features = ['TARGET_B', 'DONATION_TYPE', 'INCOME_GROUP']\n",
    "clustering_data = CL_data[clustering_interesting_features] #CL_data[clustering_interesting_features].copy()\n",
    "\n",
    "# The data will be standardized (otherwise features with higher values will have higher weights in clustering):\n",
    "clustering_data_X = clustering_data.drop(['TARGET_B', 'DONATION_TYPE'], axis=1)\n",
    "scaler = preprocessing.StandardScaler().fit(clustering_data_X)\n",
    "clustering_data_X = scaler.transform(clustering_data_X)\n",
    "\n",
    "clustering_data_y = RM_transformed_data[\"DONATION_TYPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kmean-Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most of the commands are from TP08:\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "nClusters = 12 # Find accurate value for this!\n",
    "kmeans_classifier = KMeans(n_clusters=nClusters, random_state=0) # Weights for the different features? \n",
    "kmeans_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit clusters:\n",
    "kmeans_classifier = kmeans_classifier.fit(clustering_data_X)\n",
    "clustering_data['kmeans_Cluster'] = kmeans_classifier.predict(clustering_data_X)\n",
    "clustering_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# linkage choices: “ward”, “complete”, “average”, “single”\n",
    "# average, single und complete funktioniert nicht, ward ist ganz gut, \n",
    "Agg_classifier = AgglomerativeClustering(linkage =\"ward\", n_clusters=nClusters)\n",
    "Agg_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Grow the cluster hierarchy until K = 7 (dendogram)\n",
    "Agg_classifier = Agg_classifier.fit(clustering_data_X)\n",
    "\n",
    "clustering_data['Agg_Cluster'] = Agg_classifier.labels_\n",
    "clustering_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Agglomerative and kmeans Clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "def make_contingency_matrix(targets, classifier_labels):\n",
    "    '''targets: list with targets. E.g. 'clustering_data_y'. \n",
    "    classifier_labels: list with targets determined by classifier. E.g. kmeans_classifier.labels_\n",
    "    Returns contingency matrix.\n",
    "    '''\n",
    "    contmat = contingency_matrix(targets, classifier_labels)\n",
    "    df_contmat = pd.DataFrame(contmat)\n",
    "    targets_list = list(set(targets))\n",
    "    targets_list.sort()\n",
    "    df_contmat.index = targets_list\n",
    "    return df_contmat\n",
    "\n",
    "cm = make_contingency_matrix(clustering_data.Agg_Cluster, clustering_data.kmeans_Cluster)\n",
    "cm = pd.DataFrame(cm)\n",
    "\n",
    "for ind in cm.columns:\n",
    "    cm = cm.rename(columns={ind: 'km_'+str(ind)}, index={ind: 'agg_'+str(ind)})\n",
    "\n",
    "\n",
    "cm['agreement'] = cm.max(axis=1) / cm.sum(axis=1)\n",
    "cm.loc['agreement'] = cm.max(axis=0) / cm.sum(axis=0)\n",
    "cm['most similar'] = cm.idxmax(axis=1)\n",
    "#cm.loc['most similiar'] = list(cm.idxmax(axis=0))\n",
    "cm = cm.round(2)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the agg-clusters that have high agreement with a kmeans-cluster:\n",
    "# merge the other ones into\n",
    "agreement_threshold = 0.5\n",
    "\n",
    "def organize_clusters(x):\n",
    "    #if x[]\n",
    "    return x[0]\n",
    "\n",
    "#clustering_data['CL_combined'] = clustering_data[ ['kmeans_Cluster', 'Agg_Cluster']] \\\n",
    "                                 .apply(organize_clusters, axis=1)\n",
    "#clustering_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyzing the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hier müssen die cluster erst verglichen werden und dann die neuen clusters aus agg-clustering reingemergt werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agg:\n",
    "\n",
    "# Use the unstandardized data for further analysis:\n",
    "cluster_attributes_Agg = clustering_data.groupby(['Agg_Cluster']).mean()\n",
    "cluster_attributes_Agg['Cluster size'] = clustering_data['Agg_Cluster'].value_counts()\n",
    "\n",
    "# DONATION_TYPE is here strongly biased as there are so many with value 0! is repleaced by new column here!\n",
    "# Use conditional probability here:\n",
    "cluster_attributes_Agg['DONATION_TYPE if TB=1'] = cluster_attributes_Agg['DONATION_TYPE'] / cluster_attributes_Agg['TARGET_B']\n",
    "cluster_attributes_Agg = cluster_attributes_Agg.drop('DONATION_TYPE', axis=1)\n",
    "\n",
    "# Divide in attributes (Target, size of Cluster) and features:\n",
    "attributes_Agg = ['TARGET_B', 'DONATION_TYPE if TB=1', 'Cluster size']\n",
    "cluster_features_Agg = cluster_attributes_Agg[cluster_attributes_Agg.columns.difference(attributes_Agg)]\n",
    "cluster_features_Agg = cluster_features_Agg.drop('kmeans_Cluster', axis=1)\n",
    "cluster_attributes_Agg = cluster_attributes_Agg.drop(cluster_attributes_Agg.columns.difference(attributes_Agg), axis=1)\n",
    "\n",
    "# give proper cluster_names:\n",
    "for ind in cluster_attributes_Agg.index:\n",
    "    cluster_attributes_Agg = cluster_attributes_Agg.rename(index={ind: 'agg_'+str(ind)})\n",
    "    cluster_features_Agg = cluster_features_Agg.rename(index={ind: 'agg_'+str(ind)})\n",
    "cluster_attributes_Agg.index.name = 'Cluster'\n",
    "cluster_features_Agg.index.name = 'Cluster'\n",
    "    \n",
    "#display(cluster_attributes_Agg)\n",
    "#display(cluster_features_Agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans:\n",
    "\n",
    "#Use the unstandardized data for further analysis:\n",
    "cluster_attributes = clustering_data.groupby(['kmeans_Cluster']).mean()\n",
    "cluster_attributes['Cluster size'] = clustering_data['kmeans_Cluster'].value_counts()\n",
    "\n",
    "# DONATION_TYPE is here strongly biased as there are so many with value 0! is repleaced by new column here!\n",
    "# Use conditional probability here:\n",
    "cluster_attributes['DONATION_TYPE if TB=1'] = cluster_attributes['DONATION_TYPE'] / cluster_attributes['TARGET_B']\n",
    "cluster_attributes = cluster_attributes.drop('DONATION_TYPE', axis=1)\n",
    "\n",
    "# Divide in attributes (Target, size of Cluster) and features:\n",
    "attributes = ['TARGET_B', 'DONATION_TYPE if TB=1', 'Cluster size']\n",
    "cluster_features = cluster_attributes[cluster_attributes.columns.difference(attributes)]\n",
    "cluster_features = cluster_features.drop('Agg_Cluster', axis=1)\n",
    "cluster_attributes = cluster_attributes.drop(cluster_attributes.columns.difference(attributes), axis=1)\n",
    "\n",
    "# give proper cluster_names:\n",
    "for ind in cluster_attributes.index:\n",
    "    cluster_attributes = cluster_attributes.rename(index={ind: 'kms_'+str(ind)})\n",
    "    cluster_features = cluster_features.rename(index={ind: 'kms_'+str(ind)})\n",
    "cluster_attributes.index.name = 'Cluster'\n",
    "cluster_features.index.name = 'Cluster'\n",
    "    \n",
    "display(cluster_attributes)\n",
    "display(cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes attributes and features for Agg and kmeans:\n",
    "cluster_attributes = cluster_attributes.append(cluster_attributes_Agg)\n",
    "cluster_features = cluster_features.append(cluster_features_Agg)\n",
    "display(cluster_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average value of TARGET_B and DONATION_TYPE in the whole dataset:\n",
    "# (important, to check if a cluster differs)\n",
    "avg_TB = (cluster_attributes['TARGET_B']*cluster_attributes['Cluster size']).sum() \\\n",
    "         /cluster_attributes['Cluster size'].sum()\n",
    "avg_DT_ifTB1 = (cluster_attributes['DONATION_TYPE if TB=1']*cluster_attributes['DONATION_TYPE if TB=1']).sum() \\\n",
    "         /cluster_attributes['DONATION_TYPE if TB=1'].sum()\n",
    "print('avg_TB=', avg_TB)\n",
    "print('avg_DT_ifTB1=', avg_DT_ifTB1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_interesting_clusters(attributes):\n",
    "    '''Chooses interesting clusters. '''\n",
    "    # These conditions should be optimized: high/low TB/DT \n",
    "    differing_TB = False\n",
    "    differing_DT = False\n",
    "    if abs(attributes[0]-avg_TB)>0.06: # TARGET_B\n",
    "        differing_TB = True\n",
    "    if abs(attributes[2]-avg_DT_ifTB1)>0.7: # DONATION_TYPE\n",
    "        differing_DT = True\n",
    "    return differing_TB or differing_DT\n",
    "\n",
    "cluster_attributes['interesting?'] = cluster_attributes[['TARGET_B', 'Cluster size', 'DONATION_TYPE if TB=1']] \\\n",
    "                                    .apply(find_interesting_clusters, axis=1)\n",
    "\n",
    "# drop uninteresting columns and transpose for better visualization:\n",
    "cluster_features = cluster_features[cluster_attributes['interesting?']==True] \n",
    "cluster_attributes = cluster_attributes[cluster_attributes['interesting?']==True]\n",
    "cluster_attributes = cluster_attributes.transpose()\n",
    "cluster_features = cluster_features.transpose()\n",
    "\n",
    "print(f'Interesting clusters: {cluster_attributes.shape[1]}/{nClusters}')\n",
    "display(cluster_attributes)\n",
    "#display(cluster_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we can filter out the clusters we are not interested in. \n",
    "# Now, we can check, which features characterize the clusters. \n",
    "\n",
    "# Calculate Dataset-averages of all features:\n",
    "cluster_features[\"Dataset AVG\"] = 1\n",
    "for feature in cluster_features.index:\n",
    "    cluster_features.loc[feature, 'Dataset AVG'] = CL_data[feature].mean()\n",
    "\n",
    "\n",
    "for cluster in cluster_attributes.columns:\n",
    "    cluster_features['deviation '+str(cluster)] = (cluster_features[cluster]-cluster_features['Dataset AVG']) \\\n",
    "                                                            / cluster_features['Dataset AVG']\n",
    "cluster_feature_dev = cluster_features.drop(cluster_attributes.columns, axis=1)\n",
    "cluster_feature_dev = cluster_feature_dev.drop('Dataset AVG', axis=1)\n",
    "#cluster_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_dev_threshold = 0.8\n",
    "deviations_styler = cluster_feature_dev.style.applymap(lambda x: \"background-color: red\" if abs(x)>high_dev_threshold else \"background-color: white\")\n",
    "#display(deviations_styler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_feature_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cluster_attributes)\n",
    "for cluster in cluster_feature_dev:\n",
    "    no = cluster[10:]\n",
    "    print('Cluster: ', no)\n",
    "    deviating_features = cluster_features[ abs(cluster_feature_dev[cluster]) > high_dev_threshold ]\n",
    "    display(deviating_features[ [no, 'Dataset AVG']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- check which number of clusters works best\n",
    "- get rid of the plots and maybe look for a better way to vizualize the distribution of the classes in the cluster? \n",
    "\n",
    "- do the same for agglomerative clustering and compare the classes in a contingency matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I actually do not think we need the following part. But the contingency matrix and the plots might be nice to understand and validate... Especially when you change the normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create contigency_matrix to compare clusters with DONATION_TYPE:\n",
    "df_contmat_kmeans = make_contingency_matrix(clustering_data_y, kmeans_classifier.labels_) \n",
    "# normalize the matrix with respect to the size of the target size of the classes:\n",
    "df_contmat_kmeans_normalized = pd.DataFrame(preprocessing.normalize(df_contmat_kmeans, axis=1))\n",
    "df_contmat_kmeans_normalized.index = df_contmat_kmeans.index\n",
    "df_contmat_kmeans_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See, which DONATION_TYPES are common in which classes...\n",
    "def make_cluster_plots(cm):\n",
    "    '''cm is contingency matrix'''\n",
    "    ncols = 3\n",
    "    nrows = int(nClusters/ncols)+1\n",
    "    contingency_plots = plt.figure(figsize=(ncols*6,nrows*6))\n",
    "    i=0\n",
    "    for ind, col in enumerate(cm.columns):\n",
    "        plt.subplot(nrows, ncols, i+1)\n",
    "        plt.bar(cm.index, cm[col].values)\n",
    "        plt.ylim(0,1)\n",
    "        plt.grid()\n",
    "        plt.title(f'Relative frequency of the donation types in Cluster {ind}.')\n",
    "        i += 1\n",
    "make_cluster_plots(df_contmat_kmeans_normalized)\n",
    "# Look in these plots for a cluster in which a class is more frequent than the others.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering - Results and Discussion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comments and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
